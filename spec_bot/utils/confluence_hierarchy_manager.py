"""
Confluenceéšå±¤ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

JSONéšå±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½ä»•æ§˜æ›¸ v1.0ã«åŸºã¥ãå®Ÿè£…
- JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®éšå±¤ãƒ‡ãƒ¼ã‚¿ç®¡ç†
- é€±1å›ã®è‡ªå‹•æ›´æ–° + æ‰‹å‹•æ›´æ–°æ©Ÿèƒ½
- å‰Šé™¤ãƒ»å»ƒæ­¢ãƒšãƒ¼ã‚¸ã®è‡ªå‹•é™¤å¤–æ©Ÿèƒ½
- 30-100å€ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’å®Ÿç¾
"""

import json
import os
import shutil
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import logging
from pathlib import Path

try:
    from ..tools.confluence_tool import get_confluence_page_hierarchy
    from ..config.settings import settings
except ImportError:
    # ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œæ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
    from src.spec_bot_mvp.tools.confluence_tool import get_confluence_page_hierarchy
    from src.spec_bot_mvp.config.settings import settings


class ConfluenceHierarchyManager:
    """
    Confluenceéšå±¤ãƒ‡ãƒ¼ã‚¿ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ã‚¯ãƒ©ã‚¹
    
    ä¸»ãªæ©Ÿèƒ½:
    - JSONéšå±¤ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆãƒ»æ›´æ–°ãƒ»èª­ã¿è¾¼ã¿
    - å‰Šé™¤ãƒ»å»ƒæ­¢ãƒšãƒ¼ã‚¸ã®è‡ªå‹•é™¤å¤–
    - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½
    - å·®åˆ†æ¤œçŸ¥ã«ã‚ˆã‚‹åŠ¹ç‡çš„æ›´æ–°
    """
    
    def __init__(self):
        self.settings = settings
        self.logger = logging.getLogger(__name__)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®šï¼ˆä»•æ§˜æ›¸æº–æ‹ ï¼‰
        self.data_dir = Path("data")
        self.data_dir.mkdir(exist_ok=True)
        
        self.hierarchy_file = self.data_dir / "confluence_hierarchy.json"
        self.backup_file = self.data_dir / "confluence_hierarchy_backup.json"
        self.metadata_file = self.data_dir / "cache_metadata.json"
        
        # å‰Šé™¤ãƒ»å»ƒæ­¢ãƒšãƒ¼ã‚¸ã®æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³
        self.deleted_patterns = ["ã€%%å‰Šé™¤%%ã€‘", "ã€%%å»ƒæ­¢%%ã€‘"]
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
        self.version = "1.0"
        
    def should_update(self) -> Tuple[bool, str]:
        """
        æ›´æ–°ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        
        Returns:
            Tuple[bool, str]: (æ›´æ–°è¦å¦, ç†ç”±)
        """
        try:
            if not self.hierarchy_file.exists():
                return True, "éšå±¤ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
            
            if not self.metadata_file.exists():
                return True, "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’å–å¾—
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            last_update = datetime.fromisoformat(metadata.get('last_update', '1970-01-01T00:00:00'))
            
            # é€±1å›ã®è‡ªå‹•æ›´æ–°ãƒã‚§ãƒƒã‚¯ï¼ˆæœˆæ›œæ—¥ AM 3:00ï¼‰
            now = datetime.now()
            week_ago = now - timedelta(days=7)
            
            if last_update < week_ago:
                return True, f"æœ€çµ‚æ›´æ–°ã‹ã‚‰7æ—¥çµŒéï¼ˆæœ€çµ‚æ›´æ–°: {last_update.strftime('%Y-%m-%d %H:%M')}ï¼‰"
            
            return False, f"æ›´æ–°ä¸è¦ï¼ˆæœ€çµ‚æ›´æ–°: {last_update.strftime('%Y-%m-%d %H:%M')}ï¼‰"
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return True, f"ã‚¨ãƒ©ãƒ¼ã®ãŸã‚æ›´æ–°å®Ÿè¡Œ: {str(e)}"
    
    def create_backup(self) -> bool:
        """
        ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        
        Returns:
            bool: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆåŠŸå¯å¦
        """
        try:
            if self.hierarchy_file.exists():
                shutil.copy2(self.hierarchy_file, self.backup_file)
                self.logger.info(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ: {self.backup_file}")
                return True
            return False
        except Exception as e:
            self.logger.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def is_deleted_page(self, title: str) -> bool:
        """
        å‰Šé™¤ãƒ»å»ƒæ­¢ãƒšãƒ¼ã‚¸ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        
        Args:
            title: ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«
            
        Returns:
            bool: å‰Šé™¤ãƒ»å»ƒæ­¢ãƒšãƒ¼ã‚¸ã®å ´åˆTrue
        """
        return any(pattern in title for pattern in self.deleted_patterns)
    
    def count_deleted_pages(self, folders: List[Dict]) -> int:
        """
        å‰Šé™¤ãƒ»å»ƒæ­¢ãƒšãƒ¼ã‚¸æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        
        Args:
            folders: ãƒ•ã‚©ãƒ«ãƒ€éšå±¤ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            int: å‰Šé™¤ãƒ»å»ƒæ­¢ãƒšãƒ¼ã‚¸æ•°
        """
        count = 0
        
        def count_recursive(items: List[Dict]) -> None:
            nonlocal count
            if not items:  # None ã¾ãŸã¯ç©ºã®å ´åˆã‚’ãƒã‚§ãƒƒã‚¯
                return
                
            for item in items:
                if item.get('type') == 'page' and self.is_deleted_page(item.get('name', '')):
                    count += 1
                
                # children ãŒå­˜åœ¨ã—ã€None ã§ãªã„å ´åˆã®ã¿å†å¸°å‡¦ç†
                children = item.get('children')
                if children is not None:
                    count_recursive(children)
        
        count_recursive(folders)
        return count
    
    def filter_deleted_pages(self, folders: List[Dict], include_deleted: bool = False) -> List[Dict]:
        """
        å‰Šé™¤ãƒ»å»ƒæ­¢ãƒšãƒ¼ã‚¸ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        Args:
            folders: ãƒ•ã‚©ãƒ«ãƒ€éšå±¤ãƒ‡ãƒ¼ã‚¿
            include_deleted: å‰Šé™¤ãƒšãƒ¼ã‚¸ã‚’å«ã‚€ã‹ã©ã†ã‹
            
        Returns:
            List[Dict]: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿
        """
        def filter_recursive(items: List[Dict]) -> List[Dict]:
            if not items:  # None ã¾ãŸã¯ç©ºã®å ´åˆã‚’ãƒã‚§ãƒƒã‚¯
                return []
                
            filtered = []
            for item in items:
                item_copy = item.copy()
                
                # å‰Šé™¤ãƒšãƒ¼ã‚¸ã®å‡¦ç†
                if item.get('type') == 'page' and self.is_deleted_page(item.get('name', '')):
                    if include_deleted:
                        # å‰Šé™¤ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚¯ã‚’è¿½åŠ 
                        item_copy['is_deleted'] = True
                        item_copy['name'] = f"ğŸ—‘ï¸ {item_copy['name']}"
                        filtered.append(item_copy)
                    # include_deleted=Falseã®å ´åˆã¯é™¤å¤–ï¼ˆä½•ã‚‚ã—ãªã„ï¼‰
                else:
                    # é€šå¸¸ãƒšãƒ¼ã‚¸ãƒ»ãƒ•ã‚©ãƒ«ãƒ€ã®å‡¦ç†
                    children = item.get('children')
                    if children is not None:
                        item_copy['children'] = filter_recursive(children)
                    else:
                        item_copy['children'] = []  # null ã‚’ç©ºãƒªã‚¹ãƒˆã«å¤‰æ›
                    filtered.append(item_copy)
            
            return filtered
        
        return filter_recursive(folders)
    
    def generate_hierarchy_data(self, space_key: str = "CLIENTTOMO") -> Dict[str, Any]:
        """
        Confluenceéšå±¤ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            space_key: Confluenceã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼
            
        Returns:
            Dict: éšå±¤ãƒ‡ãƒ¼ã‚¿
        """
        try:
            self.logger.info("Confluenceéšå±¤ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹...")
            
            # éšå±¤ãƒ‡ãƒ¼ã‚¿ã®è§£æï¼ˆæ—¢å­˜ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’åŸºã«æ§‹ç¯‰ï¼‰
            if self.hierarchy_file.exists():
                with open(self.hierarchy_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                    folders = existing_data.get('folders', [])
            else:
                # Confluenceã‚¹ãƒšãƒ¼ã‚¹æ§‹é€ ã‚’å–å¾—
                try:
                    result = get_confluence_page_hierarchy(space_key)
                    if result and 'folders' in result:
                        folders = result['folders']
                    else:
                        # ç°¡æ˜“çš„ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ§‹é€ ã‚’ä½œæˆ
                        folders = self._create_default_structure()
                except Exception as e:
                    self.logger.warning(f"Confluenceãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ§‹é€ ã‚’ä½¿ç”¨")
                    folders = self._create_default_structure()
            
            # å‰Šé™¤ãƒšãƒ¼ã‚¸æ•°ã‚’è¨ˆç®—
            deleted_count = self.count_deleted_pages(folders)
            
            # éšå±¤ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
            hierarchy_data = {
                "space_name": getattr(self.settings, 'confluence_space', None) or "client-tomonokai-juku",
                "space_key": space_key,
                "generated_at": datetime.now().isoformat(),
                "total_pages": len(self._count_all_pages(folders)),
                "deleted_pages_count": deleted_count,
                "version": self.version,
                "folders": folders
            }
            
            self.logger.info(f"éšå±¤ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº† - ç·ãƒšãƒ¼ã‚¸æ•°: {hierarchy_data['total_pages']}, å‰Šé™¤ãƒšãƒ¼ã‚¸æ•°: {deleted_count}")
            return hierarchy_data
            
        except Exception as e:
            self.logger.error(f"éšå±¤ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _create_default_structure(self) -> List[Dict]:
        """
        ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®éšå±¤æ§‹é€ ã‚’ä½œæˆ
        
        Returns:
            List[Dict]: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéšå±¤æ§‹é€ ãƒ‡ãƒ¼ã‚¿
        """
        return [
            {
                "name": "client-tomonokai-juku Home",
                "type": "folder",
                "updated": datetime.now().strftime("%Y-%m-%d %H:%M"),
                "children": [
                    {
                        "name": "â– è¦ä»¶å®šç¾©",
                        "type": "folder",
                        "updated": datetime.now().strftime("%Y-%m-%d %H:%M"),
                        "children": []
                    },
                    {
                        "name": "â– è¨­è¨ˆæ›¸",
                        "type": "folder", 
                        "updated": datetime.now().strftime("%Y-%m-%d %H:%M"),
                        "children": []
                    }
                ]
            }
        ]
    
    def _count_all_pages(self, folders: List[Dict]) -> List[str]:
        """
        å…¨ãƒšãƒ¼ã‚¸ã‚’å†å¸°çš„ã«ã‚«ã‚¦ãƒ³ãƒˆ
        
        Args:
            folders: ãƒ•ã‚©ãƒ«ãƒ€éšå±¤ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            List[str]: ãƒšãƒ¼ã‚¸IDä¸€è¦§
        """
        pages = []
        
        def count_recursive(items: List[Dict]) -> None:
            if not items:  # None ã¾ãŸã¯ç©ºã®å ´åˆã‚’ãƒã‚§ãƒƒã‚¯
                return
                
            for item in items:
                if item.get('type') == 'page':
                    # IDãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯IDã‚’ã€å­˜åœ¨ã—ãªã„å ´åˆã¯åå‰ã‚’ä½¿ç”¨
                    page_id = item.get('id') or item.get('name', 'unknown')
                    pages.append(str(page_id))
                
                # children ãŒå­˜åœ¨ã—ã€None ã§ãªã„å ´åˆã®ã¿å†å¸°å‡¦ç†
                children = item.get('children')
                if children is not None:
                    count_recursive(children)
        
        count_recursive(folders)
        return pages
    
    def save_hierarchy_data(self, data: Dict[str, Any]) -> bool:
        """
        éšå±¤ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            data: éšå±¤ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            bool: ä¿å­˜æˆåŠŸå¯å¦
        """
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            self.create_backup()
            
            # ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(self.hierarchy_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
            metadata = {
                "last_update": datetime.now().isoformat(),
                "version": self.version,
                "total_pages": data.get('total_pages', 0),
                "deleted_pages_count": data.get('deleted_pages_count', 0)
            }
            
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"éšå±¤ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {self.hierarchy_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"éšå±¤ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def load_hierarchy_data(self, include_deleted: bool = False) -> Optional[Dict[str, Any]]:
        """
        éšå±¤ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        
        Args:
            include_deleted: å‰Šé™¤ãƒšãƒ¼ã‚¸ã‚’å«ã‚€ã‹ã©ã†ã‹
            
        Returns:
            Optional[Dict]: éšå±¤ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã¯Noneï¼‰
        """
        try:
            if not self.hierarchy_file.exists():
                self.logger.warning("éšå±¤ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return None
            
            with open(self.hierarchy_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # å‰Šé™¤ãƒšãƒ¼ã‚¸ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if 'folders' in data:
                data['folders'] = self.filter_deleted_pages(data['folders'], include_deleted)
            
            self.logger.info(f"éšå±¤ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº† - include_deleted: {include_deleted}")
            return data
            
        except Exception as e:
            self.logger.error(f"éšå±¤ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def update_hierarchy(self, space_key: str = "CLIENTTOMO", force: bool = False) -> Tuple[bool, str]:
        """
        éšå±¤ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        
        Args:
            space_key: Confluenceã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼
            force: å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°
            
        Returns:
            Tuple[bool, str]: (æˆåŠŸå¯å¦, ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
        """
        try:
            # æ›´æ–°è¦å¦ãƒã‚§ãƒƒã‚¯
            if not force:
                should_update, reason = self.should_update()
                if not should_update:
                    return True, f"æ›´æ–°ä¸è¦: {reason}"
            
            self.logger.info("éšå±¤ãƒ‡ãƒ¼ã‚¿æ›´æ–°é–‹å§‹...")
            
            # éšå±¤ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            data = self.generate_hierarchy_data(space_key)
            
            # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            if self.save_hierarchy_data(data):
                message = f"éšå±¤ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº† - ç·ãƒšãƒ¼ã‚¸æ•°: {data['total_pages']}, å‰Šé™¤ãƒšãƒ¼ã‚¸æ•°: {data['deleted_pages_count']}"
                self.logger.info(message)
                return True, message
            else:
                return False, "éšå±¤ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"
                
        except Exception as e:
            error_msg = f"éšå±¤ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg
    
    def get_hierarchy_stats(self) -> Dict[str, Any]:
        """
        éšå±¤ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        
        Returns:
            Dict: çµ±è¨ˆæƒ…å ±
        """
        try:
            if not self.metadata_file.exists():
                return {"error": "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“"}
            
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            return {
                "last_update": metadata.get('last_update'),
                "version": metadata.get('version'),
                "total_pages": metadata.get('total_pages', 0),
                "deleted_pages_count": metadata.get('deleted_pages_count', 0),
                "file_size": self.hierarchy_file.stat().st_size if self.hierarchy_file.exists() else 0,
                "backup_exists": self.backup_file.exists()
            }
            
        except Exception as e:
            return {"error": f"çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"} 