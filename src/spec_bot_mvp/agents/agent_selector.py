"""
Agenté¸æŠãƒ­ã‚¸ãƒƒã‚¯

å“è³ªè©•ä¾¡çµæœã«åŸºã¥ã„ã¦ã€é©åˆ‡ãªAgentã‚’é¸æŠã™ã‚‹åˆ¶å¾¡ãƒ­ã‚¸ãƒƒã‚¯ã€‚
ä»•æ§˜æ›¸æº–æ‹ ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ä¸­æ ¸éƒ¨åˆ†ã€‚

å‚ç…§ä»•æ§˜æ›¸: SPEC-DS-001 4.3. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­è¨ˆ
"""

import logging
from typing import Dict, List, Any, Tuple
from pathlib import Path
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

logger = logging.getLogger(__name__)

# å“è³ªè©•ä¾¡ã—ãã„å€¤ï¼ˆä»•æ§˜æ›¸æº–æ‹ ï¼‰
HIGH_QUALITY_THRESHOLD = 0.75
MEDIUM_QUALITY_THRESHOLD = 0.5

class AgentSelector:
    """
    Agenté¸æŠãƒ­ã‚¸ãƒƒã‚¯
    
    å›ºå®šæ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®çµæœã‚’è©•ä¾¡ã—ã€æ¬¡ã«å®Ÿè¡Œã™ã¹ãAgentã‚’é¸æŠã™ã‚‹ã€‚
    - é«˜å“è³ªçµæœ: å›ç­”ç”ŸæˆAgent
    - ä½å“è³ªçµæœ: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢Agent â†’ å›ç­”ç”ŸæˆAgent
    """
    
    def __init__(self):
        """AgentSelectoråˆæœŸåŒ–"""
        self.selection_history = []  # é¸æŠå±¥æ­´ï¼ˆåˆ†æç”¨ï¼‰
        logger.info("âœ… AgentSelectoråˆæœŸåŒ–å®Œäº†")
    
    def select_agent_strategy(self, 
                            search_results: List[Dict], 
                            quality_score: float,
                            user_query: str,
                            filters: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """
        æ¤œç´¢çµæœã®å“è³ªã«åŸºã¥ã„ã¦Agentæˆ¦ç•¥ã‚’é¸æŠ
        
        Args:
            search_results: å›ºå®šãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¤œç´¢çµæœ
            quality_score: å“è³ªè©•ä¾¡ã‚¹ã‚³ã‚¢
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
            filters: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶
            
        Returns:
            Tuple[é¸æŠæˆ¦ç•¥, æˆ¦ç•¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿]
        """
        # é¸æŠåŸºæº–ã®è©•ä¾¡
        decision_factors = self._analyze_decision_factors(
            search_results, quality_score, user_query, filters
        )
        
        # æˆ¦ç•¥é¸æŠ
        strategy, params = self._decide_strategy(decision_factors)
        
        # é¸æŠå±¥æ­´è¨˜éŒ²
        self._record_selection(strategy, decision_factors, params)
        
        logger.info("ğŸ¯ Agentæˆ¦ç•¥é¸æŠ: %s (å“è³ªã‚¹ã‚³ã‚¢=%.2f)", strategy, quality_score)
        return strategy, params
    
    def _analyze_decision_factors(self,
                                search_results: List[Dict],
                                quality_score: float, 
                                user_query: str,
                                filters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Agenté¸æŠã®åˆ¤æ–­è¦ç´ ã‚’åˆ†æ
        
        Args:
            search_results: æ¤œç´¢çµæœ
            quality_score: å“è³ªã‚¹ã‚³ã‚¢
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
            filters: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶
            
        Returns:
            åˆ¤æ–­è¦ç´ è¾æ›¸
        """
        factors = {
            # åŸºæœ¬å“è³ªè©•ä¾¡
            "quality_score": quality_score,
            "result_count": len(search_results),
            
            # å“è³ªåˆ†é¡
            "is_high_quality": quality_score >= HIGH_QUALITY_THRESHOLD,
            "is_medium_quality": MEDIUM_QUALITY_THRESHOLD <= quality_score < HIGH_QUALITY_THRESHOLD,
            "is_low_quality": quality_score < MEDIUM_QUALITY_THRESHOLD,
            
            # çµæœå†…å®¹åˆ†æ
            "has_results": len(search_results) > 0,
            "result_diversity": self._calculate_result_diversity(search_results),
            "avg_relevance": self._calculate_avg_relevance(search_results),
            
            # ã‚¯ã‚¨ãƒªç‰¹æ€§åˆ†æ
            "query_length": len(user_query),
            "query_complexity": self._estimate_query_complexity(user_query),
            "has_specific_filters": self._has_specific_filters(filters),
            
            # æ–‡è„ˆè¦ç´ 
            "query_type": self._classify_query_type(user_query),
            "expected_answer_type": self._estimate_answer_type(user_query)
        }
        
        return factors
    
    def _decide_strategy(self, factors: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """
        åˆ¤æ–­è¦ç´ ã«åŸºã¥ã„ã¦æœ€é©æˆ¦ç•¥ã‚’æ±ºå®š
        
        Args:
            factors: åˆ¤æ–­è¦ç´ è¾æ›¸
            
        Returns:
            Tuple[æˆ¦ç•¥å, æˆ¦ç•¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿]
        """
        # æˆ¦ç•¥æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯
        if factors["is_high_quality"] and factors["has_results"]:
            # é«˜å“è³ªçµæœ â†’ ç›´æ¥å›ç­”ç”Ÿæˆ
            return "direct_response_generation", {
                "confidence": "high",
                "use_fallback": False,
                "response_style": "comprehensive",
                "quality_context": factors
            }
        
        elif factors["is_medium_quality"] and factors["result_count"] >= 2:
            # ä¸­å“è³ªçµæœ â†’ çµæœæ”¹å–„å¾Œã«å›ç­”ç”Ÿæˆ
            return "enhanced_response_generation", {
                "confidence": "medium", 
                "use_fallback": False,
                "response_style": "cautious",
                "enhancement_needed": True,
                "quality_context": factors
            }
        
        elif factors["is_low_quality"] or not factors["has_results"]:
            # ä½å“è³ª/çµæœãªã— â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢
            return "fallback_then_response", {
                "confidence": "low",
                "use_fallback": True,
                "fallback_strategy": self._select_fallback_strategy(factors),
                "response_style": "exploratory",
                "quality_context": factors
            }
        
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä¿å®ˆçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
            return "conservative_response", {
                "confidence": "unknown",
                "use_fallback": True,
                "response_style": "minimal",
                "quality_context": factors
            }
    
    def _select_fallback_strategy(self, factors: Dict[str, Any]) -> str:
        """
        ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ã®è©³ç´°é¸æŠ
        
        Args:
            factors: åˆ¤æ–­è¦ç´ è¾æ›¸
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥å
        """
        if factors["query_complexity"] == "high":
            return "creative_search"  # å‰µé€ çš„æ¤œç´¢
        elif factors["query_type"] == "specific":
            return "targeted_search"  # æ¨™çš„å‹æ¤œç´¢
        elif not factors["has_results"]:
            return "expansive_search"  # æ‹¡å¼µæ¤œç´¢
        else:
            return "standard_search"  # æ¨™æº–æ¤œç´¢
    
    def _calculate_result_diversity(self, search_results: List[Dict]) -> float:
        """
        æ¤œç´¢çµæœã®å¤šæ§˜æ€§ã‚’è¨ˆç®—
        
        Args:
            search_results: æ¤œç´¢çµæœ
            
        Returns:
            å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢ (0.0-1.0)
        """
        if not search_results:
            return 0.0
        
        # ã‚½ãƒ¼ã‚¹ã®å¤šæ§˜æ€§
        sources = set(result.get('source', '') for result in search_results)
        source_diversity = len(sources) / max(len(search_results), 1)
        
        # å˜ç´”åŒ–ã—ãŸå¤šæ§˜æ€§æŒ‡æ¨™
        return min(source_diversity, 1.0)
    
    def _calculate_avg_relevance(self, search_results: List[Dict]) -> float:
        """
        å¹³å‡é–¢é€£åº¦ã‚’è¨ˆç®—
        
        Args:
            search_results: æ¤œç´¢çµæœ
            
        Returns:
            å¹³å‡é–¢é€£åº¦ã‚¹ã‚³ã‚¢
        """
        if not search_results:
            return 0.0
        
        relevance_scores = [
            result.get('relevance_score', 0.0) 
            for result in search_results
        ]
        
        return sum(relevance_scores) / len(relevance_scores) if relevance_scores else 0.0
    
    def _estimate_query_complexity(self, user_query: str) -> str:
        """
        ã‚¯ã‚¨ãƒªã®è¤‡é›‘ã•ã‚’æ¨å®š
        
        Args:
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
            
        Returns:
            è¤‡é›‘ã•ãƒ¬ãƒ™ãƒ« (low/medium/high)
        """
        query_length = len(user_query)
        
        # è¤‡é›‘ã•æŒ‡æ¨™
        complexity_indicators = [
            "ã©ã®ã‚ˆã†ã«" in user_query,
            "ãªãœ" in user_query, 
            "æ¯”è¼ƒ" in user_query,
            "é•ã„" in user_query,
            "é–¢ä¿‚" in user_query,
            "AND" in user_query.upper() or "OR" in user_query.upper()
        ]
        
        complexity_score = sum(complexity_indicators)
        
        if query_length > 50 or complexity_score >= 3:
            return "high"
        elif query_length > 20 or complexity_score >= 1:
            return "medium"
        else:
            return "low"
    
    def _has_specific_filters(self, filters: Dict[str, Any]) -> bool:
        """
        å…·ä½“çš„ãªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        
        Args:
            filters: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶
            
        Returns:
            å…·ä½“çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šã®æœ‰ç„¡
        """
        # None, ç©ºæ–‡å­—, Falseä»¥å¤–ã®å€¤ã‚’æŒã¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        active_filters = [
            k for k, v in filters.items() 
            if v and v != "" and v is not False
        ]
        
        return len(active_filters) > 2  # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠä»¥å¤–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    
    def _classify_query_type(self, user_query: str) -> str:
        """
        è³ªå•ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡
        
        Args:
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
            
        Returns:
            è³ªå•ã‚¿ã‚¤ãƒ— (specific/general/procedural/troubleshooting)
        """
        if any(word in user_query for word in ["ã‚¨ãƒ©ãƒ¼", "å•é¡Œ", "ä¸å…·åˆ", "ã†ã¾ãã„ã‹ãªã„"]):
            return "troubleshooting"
        elif any(word in user_query for word in ["æ‰‹é †", "æ–¹æ³•", "ã‚„ã‚Šæ–¹", "ã©ã†ã‚„ã£ã¦"]):
            return "procedural"
        elif any(word in user_query for word in ["ä»•æ§˜", "è©³ç´°", "å…·ä½“çš„", "æ­£ç¢º"]):
            return "specific"
        else:
            return "general"
    
    def _estimate_answer_type(self, user_query: str) -> str:
        """
        æœŸå¾…ã•ã‚Œã‚‹å›ç­”ã‚¿ã‚¤ãƒ—ã‚’æ¨å®š
        
        Args:
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
            
        Returns:
            å›ç­”ã‚¿ã‚¤ãƒ— (factual/explanatory/procedural/comparative)
        """
        if "?" in user_query or any(word in user_query for word in ["ä½•", "ã„ã¤", "ã©ã“", "èª°"]):
            return "factual"
        elif any(word in user_query for word in ["ãªãœ", "ç†ç”±", "èƒŒæ™¯"]):
            return "explanatory"
        elif any(word in user_query for word in ["æ‰‹é †", "ã‚¹ãƒ†ãƒƒãƒ—", "æ–¹æ³•"]):
            return "procedural"
        elif any(word in user_query for word in ["æ¯”è¼ƒ", "é•ã„", "å·®"]):
            return "comparative"
        else:
            return "general"
    
    def _record_selection(self, strategy: str, factors: Dict[str, Any], params: Dict[str, Any]):
        """
        é¸æŠå±¥æ­´ã‚’è¨˜éŒ²ï¼ˆåˆ†æãƒ»æ”¹å–„ç”¨ï¼‰
        
        Args:
            strategy: é¸æŠã•ã‚ŒãŸæˆ¦ç•¥
            factors: åˆ¤æ–­è¦ç´ 
            params: æˆ¦ç•¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        selection_record = {
            "timestamp": __import__("datetime").datetime.now().isoformat(),
            "strategy": strategy,
            "quality_score": factors.get("quality_score", 0.0),
            "result_count": factors.get("result_count", 0),
            "confidence": params.get("confidence", "unknown"),
            "factors": factors
        }
        
        self.selection_history.append(selection_record)
        
        # å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆãƒ¡ãƒ¢ãƒªç®¡ç†ï¼‰
        if len(self.selection_history) > 100:
            self.selection_history = self.selection_history[-50:]  # æœ€æ–°50ä»¶ã‚’ä¿æŒ
    
    def get_selection_statistics(self) -> Dict[str, Any]:
        """
        é¸æŠçµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        
        Returns:
            é¸æŠçµ±è¨ˆè¾æ›¸
        """
        if not self.selection_history:
            return {"message": "é¸æŠå±¥æ­´ãªã—"}
        
        strategies = [record["strategy"] for record in self.selection_history]
        confidences = [record["confidence"] for record in self.selection_history]
        
        return {
            "total_selections": len(self.selection_history),
            "strategy_distribution": {
                strategy: strategies.count(strategy) 
                for strategy in set(strategies)
            },
            "confidence_distribution": {
                confidence: confidences.count(confidence)
                for confidence in set(confidences)
            },
            "avg_quality_score": sum(
                record["quality_score"] for record in self.selection_history
            ) / len(self.selection_history)
        } 