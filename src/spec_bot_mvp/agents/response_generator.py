"""
å›ç­”ç”ŸæˆAgent

ä»•æ§˜æ›¸å®šç¾© (SPEC-DS-001 4.1):
- å½¹å‰²: æ¤œç´¢çµæœã‚’çµ±åˆãƒ»è¦ç´„ã—ã¦æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆ
- ã‚¿ã‚¤ãƒ—: LLMChainï¼ˆå¤–éƒ¨ãƒ„ãƒ¼ãƒ«ç„¡ã—ï¼‰
- å…¥åŠ›: æ¤œç´¢çµæœ + ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
- å‡ºåŠ›: çµ±åˆã•ã‚ŒãŸæœ€çµ‚å›ç­”
"""

import logging
from typing import Dict, List, Any
from pathlib import Path
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from langchain.chains import LLMChain
    from langchain.prompts import PromptTemplate
    from langchain_google_genai import ChatGoogleGenerativeAI
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False

from src.spec_bot_mvp.config.settings import Settings

logger = logging.getLogger(__name__)

class ResponseGenerationAgent:
    """
    å›ç­”ç”ŸæˆAgent
    
    æ¤œç´¢çµæœã‚’çµ±åˆãƒ»è¦ç´„ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åˆ†ã‹ã‚Šã‚„ã™ã„æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã›ãšã€LLMChainã«ã‚ˆã‚‹ç´”ç²‹ãªæ–‡ç« ç”Ÿæˆã«ç‰¹åŒ–ã€‚
    """
    
    def __init__(self):
        """AgentåˆæœŸåŒ–"""
        if not LANGCHAIN_AVAILABLE:
            raise ImportError("LangChainé–¢é€£ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒå¿…è¦ã§ã™: pip install langchain langchain-google-genai")
        
        self.settings = Settings()
        self._init_llm_chain()
        logger.info("âœ… ResponseGenerationAgentåˆæœŸåŒ–å®Œäº†")
    
    def _init_llm_chain(self):
        """LLMChainåˆæœŸåŒ–"""
        # Gemini LLMè¨­å®šï¼ˆå®‰å®šæ€§é‡è¦–ï¼‰
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            google_api_key=self.settings.google_api_key,
            temperature=0.3,  # å®‰å®šæ€§é‡è¦–
            max_output_tokens=2048
        )
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.prompt = PromptTemplate(
            input_variables=["search_results", "user_query"],
            template=self._get_response_prompt_template()
        )
        
        # LLMChainæ§‹ç¯‰
        self.chain = LLMChain(
            llm=self.llm,
            prompt=self.prompt,
            verbose=True
        )
    
    def _get_response_prompt_template(self) -> str:
        """å›ç­”ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"""
        return """ã‚ãªãŸã¯ä»•æ§˜æ›¸ä½œæˆæ”¯æ´ã®å°‚é–€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€æä¾›ã•ã‚ŒãŸæ¤œç´¢çµæœã‚’å…ƒã«åŒ…æ‹¬çš„ã§å®Ÿç”¨çš„ãªå›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•ã€‘
{user_query}

ã€æ¤œç´¢çµæœã€‘
{search_results}

ã€å›ç­”ç”Ÿæˆã®æŒ‡é‡ã€‘
1. **å®Œå…¨æ€§**: æ¤œç´¢çµæœã®é‡è¦ãªæƒ…å ±ã‚’ã‚‚ã‚Œãªãçµ±åˆã™ã‚‹
2. **æ§‹é€ åŒ–**: è¦‹å‡ºã—ã€ç®‡æ¡æ›¸ãã‚’æ´»ç”¨ã—ã¦èª­ã¿ã‚„ã™ãæ•´ç†ã™ã‚‹  
3. **å®Ÿç”¨æ€§**: é–‹ç™ºè€…ãŒå…·ä½“çš„ã«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–ã‚Œã‚‹æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹
4. **æ–‡è„ˆç†è§£**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•æ„å›³ã‚’æ­£ç¢ºã«ç†è§£ã—ã¦å›ç­”ã™ã‚‹
5. **ä¿¡é ¼æ€§**: æ¤œç´¢çµæœã«åŸºã¥ã‹ãªã„æ¨æ¸¬ã‚„æ†¶æ¸¬ã¯é¿ã‘ã‚‹

ã€å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
## ğŸ“‹ è³ªå•ã¸ã®å›ç­”

[ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•ã«å¯¾ã™ã‚‹ç›´æ¥çš„ãªå›ç­”]

## ğŸ” è©³ç´°æƒ…å ±

[æ¤œç´¢çµæœã‹ã‚‰å¾—ã‚‰ã‚ŒãŸå…·ä½“çš„ãªè©³ç´°]

## ğŸ“š é–¢é€£æƒ…å ±ãƒ»å‚è€ƒè³‡æ–™

[é–¢é€£ã™ã‚‹ãƒã‚±ãƒƒãƒˆã€ãƒšãƒ¼ã‚¸ã€ä»•æ§˜æ›¸ç­‰ã®æƒ…å ±]

## ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

[ã“ã®æƒ…å ±ã‚’åŸºã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå–ã‚‹ã¹ãæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—]

å›ç­”:"""

    def generate_response(self, search_results: List[Dict], user_query: str) -> str:
        """
        æ¤œç´¢çµæœã‚’çµ±åˆã—ã¦æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆ
        
        Args:
            search_results: æ¤œç´¢çµæœãƒªã‚¹ãƒˆ
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
            
        Returns:
            çµ±åˆã•ã‚ŒãŸæœ€çµ‚å›ç­”
        """
        try:
            # æ¤œç´¢çµæœã‚’æ§‹é€ åŒ–æ–‡å­—åˆ—ã«å¤‰æ›
            formatted_results = self._format_search_results(search_results)
            
            logger.info("ğŸ’¡ å›ç­”ç”Ÿæˆé–‹å§‹: ã‚¯ã‚¨ãƒª='%s', çµæœæ•°=%d", user_query, len(search_results))
            
            # LLMChainã§å›ç­”ç”Ÿæˆ
            response = self.chain.run(
                search_results=formatted_results,
                user_query=user_query
            )
            
            logger.info("âœ… å›ç­”ç”Ÿæˆå®Œäº†: æ–‡å­—æ•°=%d", len(response))
            return response
            
        except Exception as e:
            logger.error("âŒ å›ç­”ç”Ÿæˆå¤±æ•—: %s", str(e))
            return self._generate_error_response(user_query, str(e))
    
    def _format_search_results(self, search_results: List[Dict]) -> str:
        """
        æ¤œç´¢çµæœã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        
        Args:
            search_results: æ¤œç´¢çµæœãƒªã‚¹ãƒˆ
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸçµæœæ–‡å­—åˆ—
        """
        if not search_results:
            return "æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        formatted_sections = []
        
        for i, result in enumerate(search_results, 1):
            source = result.get('source', 'Unknown')
            title = result.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
            content = result.get('content', result.get('summary', ''))
            url = result.get('url', '')
            relevance_score = result.get('relevance_score', 0)
            
            section = f"""
=== æ¤œç´¢çµæœ {i} ===
ã‚½ãƒ¼ã‚¹: {source}
ã‚¿ã‚¤ãƒˆãƒ«: {title}
é–¢é€£åº¦: {relevance_score:.2f}
URL: {url}
å†…å®¹:
{content}
"""
            formatted_sections.append(section)
        
        return "\n".join(formatted_sections)
    
    def _generate_error_response(self, user_query: str, error_message: str) -> str:
        """
        ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ç”Ÿæˆ
        
        Args:
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
            error_message: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            
        Returns:
            ã‚¨ãƒ©ãƒ¼å¿œç­”æ–‡å­—åˆ—
        """
        return f"""ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

## âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°
**è³ªå•**: {user_query}
**ã‚¨ãƒ©ãƒ¼**: {error_message}

## ğŸ”§ å¯¾å‡¦æ–¹æ³•
1. **å†è©¦è¡Œ**: ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„
2. **è³ªå•ã®è¦‹ç›´ã—**: ã‚ˆã‚Šå…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§è³ªå•ã‚’è¨€ã„æ›ãˆã¦ã¿ã¦ãã ã•ã„
3. **ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼èª¿æ•´**: æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å¤‰æ›´ã—ã¦å¯¾è±¡ç¯„å›²ã‚’åºƒã’ã¦ã¿ã¦ãã ã•ã„

## ğŸ’¬ ã‚µãƒãƒ¼ãƒˆ
å•é¡ŒãŒç¶™ç¶šã™ã‚‹å ´åˆã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚
ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å«ã‚ã¦ã”é€£çµ¡ã„ãŸã ã‘ã‚‹ã¨ã€ã‚ˆã‚Šè¿…é€Ÿãªå¯¾å¿œãŒå¯èƒ½ã§ã™ã€‚"""

    def validate_llm_connection(self) -> bool:
        """
        LLMæ¥ç¶šã®æ¤œè¨¼
        
        Returns:
            æ¥ç¶šæˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
        """
        try:
            test_response = self.llm.invoke("ãƒ†ã‚¹ãƒˆ")
            logger.info("âœ… LLMæ¥ç¶šæ¤œè¨¼æˆåŠŸ")
            return True
        except Exception as e:
            logger.error("âŒ LLMæ¥ç¶šæ¤œè¨¼å¤±æ•—: %s", str(e))
            return False 