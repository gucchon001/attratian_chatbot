"""
å›ç­”ç”ŸæˆAgent

ä»•æ§˜æ›¸å®šç¾© (SPEC-DS-001 4.1):
- å½¹å‰²: æ¤œç´¢çµæœã‚’çµ±åˆãƒ»è¦ç´„ã—ã¦æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆ
- ã‚¿ã‚¤ãƒ—: LLMChainï¼ˆå¤–éƒ¨ãƒ„ãƒ¼ãƒ«ç„¡ã—ï¼‰
- å…¥åŠ›: æ¤œç´¢çµæœ + ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
- å‡ºåŠ›: çµ±åˆã•ã‚ŒãŸæœ€çµ‚å›ç­”
"""

import logging
from typing import Dict, List, Any
from pathlib import Path
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from langchain.prompts import PromptTemplate
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain_core.runnables import RunnableSequence
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False

from src.spec_bot_mvp.config.settings import Settings

logger = logging.getLogger(__name__)

class ResponseGenerationAgent:
    """
    å›ç­”ç”ŸæˆAgent
    
    æ¤œç´¢çµæœã‚’çµ±åˆãƒ»è¦ç´„ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åˆ†ã‹ã‚Šã‚„ã™ã„æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã›ãšã€LLMChainã«ã‚ˆã‚‹ç´”ç²‹ãªæ–‡ç« ç”Ÿæˆã«ç‰¹åŒ–ã€‚
    """
    
    def __init__(self):
        """AgentåˆæœŸåŒ–"""
        if not LANGCHAIN_AVAILABLE:
            raise ImportError("LangChainé–¢é€£ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒå¿…è¦ã§ã™: pip install langchain langchain-google-genai")
        
        self.settings = Settings()
        self._init_llm_chain()
        logger.info("âœ… ResponseGenerationAgentåˆæœŸåŒ–å®Œäº†")
    
    def _init_llm_chain(self):
        """LLMChainåˆæœŸåŒ–"""
        # Gemini LLMè¨­å®šï¼ˆsettings.iniæº–æ‹ ï¼‰
        try:
            self.llm = ChatGoogleGenerativeAI(
                model=self.settings.gemini_model,  # settings.iniã‹ã‚‰èª­ã¿è¾¼ã¿
                google_api_key=self.settings.google_api_key,
                temperature=self.settings.gemini_temperature,  # settings.iniã‹ã‚‰èª­ã¿è¾¼ã¿
                max_output_tokens=self.settings.gemini_max_tokens  # settings.iniã‹ã‚‰èª­ã¿è¾¼ã¿
            )
            logger.info(f"âœ… Gemini LLMåˆæœŸåŒ–æˆåŠŸ: {self.settings.gemini_model}")
        except Exception as e:
            logger.error(f"âŒ Gemini LLMåˆæœŸåŒ–å¤±æ•—: {e}")
            raise
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.prompt = PromptTemplate(
            input_variables=["search_results", "user_query"],
            template=self._get_response_prompt_template()
        )
        
        # RunnableSequenceæ§‹ç¯‰ (æœ€æ–°LangChain API)
        self.chain = self.prompt | self.llm
    
    def _get_response_prompt_template(self) -> str:
        """CLIENTTOMOä»•æ§˜æ›¸ç‰¹åŒ– å›ç­”ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆv2.1 - ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜å¼·åŒ–ç‰ˆï¼‰"""
        return """ã‚ãªãŸã¯CLIENTTOMOãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå°‚ç”¨ã®ä¸Šç´šä»•æ§˜æ›¸ä½œæˆæ”¯æ´AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
é–‹ç™ºè€…ãƒ»PMãƒ»CSãƒãƒ¼ãƒ ãŒã€è¤‡é›‘ãªæ©Ÿèƒ½ä»•æ§˜ã‚’ç´ æ—©ãç†è§£ã—ã€å®Ÿè£…ã‚„ã‚µãƒãƒ¼ãƒˆã«æ´»ç”¨ã§ãã‚‹å®Ÿç”¨çš„ãªå›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€CLIENTTOMOãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè©³ç´°æƒ…å ±ã€‘
â–  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦: ä¼æ¥­å‘ã‘ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
â–  å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼: 
  - ä¼šå“¡ï¼ˆä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰
  - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¼æ¥­ï¼ˆæ³•äººãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰  
  - å…¨ä½“ç®¡ç†è€…ï¼ˆã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ï¼‰
â–  ä¸»è¦æ©Ÿèƒ½é ˜åŸŸ:
  - ãƒ­ã‚°ã‚¤ãƒ³ãƒ»èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¤šå±¤èªè¨¼ã€3ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¤ãƒ—å¯¾å¿œï¼‰
  - UI/UXï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ã€ãƒ¢ãƒ¼ãƒ€ãƒ«ã€å‹•çš„æŒ™å‹•ï¼‰
  - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†ã€æ¨©é™åˆ¶å¾¡ï¼‰
  - APIè¨­è¨ˆï¼ˆRESTfulã€èªè¨¼ã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰
  - æ¥­å‹™ãƒ•ãƒ­ãƒ¼ï¼ˆPMãƒ»CSãƒ»ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°é€£æºï¼‰
â–  æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯:
  - UI: Streamlitï¼ˆPythonï¼‰
  - AI: LangChain + Gemini 2.0-flash
  - æ¤œç´¢: 3æ®µéšCQLæ¤œç´¢æˆ¦ç•¥
  - ã‚¤ãƒ³ãƒ•ãƒ©: Confluence (CLIENTTOMOã‚¹ãƒšãƒ¼ã‚¹), Jira
  - ã‚­ãƒ£ãƒƒã‚·ãƒ¥: SQLiteï¼ˆæ€§èƒ½å‘ä¸Šï¼‰

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•ã€‘
{user_query}

ã€æ¤œç´¢çµæœï¼ˆ80%é–¢é€£åº¦é”æˆã®3æ®µéšCQLæ¤œç´¢çµæœï¼‰ã€‘
{search_results}

ã€CLIENTTOMOå°‚ç”¨å›ç­”ç”Ÿæˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼ˆv2.1å¼·åŒ–ç‰ˆï¼‰ã€‘
1. **æ©Ÿèƒ½ç†è§£é‡è¦–**: ã€Œãªãœãã®ä»•æ§˜ã«ãªã£ãŸã®ã‹ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèƒŒæ™¯ãƒ»æ„å›³ã‚’èª¬æ˜
2. **å®Ÿè£…æŒ‡å‘**: é–‹ç™ºè€…ãŒå³åº§ã«ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ç€æ‰‹ã§ãã‚‹å…·ä½“æ€§ï¼ˆAPIä»•æ§˜ã€ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç­‰ï¼‰
3. **æ¥­å‹™é€£æº**: PMãƒ»CSãƒ»ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã¨ã®é€£æºãƒã‚¤ãƒ³ãƒˆã‚’æ˜ç¤º
4. **å‹•çš„ä»•æ§˜**: UIæŒ™å‹•ãƒ»ãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ»ãƒ•ãƒ­ãƒ¼ç­‰ã®å‹•çš„ãªä»•æ§˜ã‚’é‡è¦–
5. **é–¢é€£æ€§å¯è¦–åŒ–**: ä»–æ©Ÿèƒ½ãƒ»ç”»é¢ãƒ»ãƒ‡ãƒ¼ã‚¿ã¨ã®é–¢é€£æ€§ã‚’æ˜ç¢ºåŒ–
6. **å“è³ªåŸºæº–**: CLIENTTOMOã®å“è³ªåŸºæº–ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶æº–æ‹ 
7. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¤ãƒ—è€ƒæ…®**: ä¼šå“¡ãƒ»ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¼æ¥­ãƒ»ç®¡ç†è€…åˆ¥ã®ä»•æ§˜å·®ç•°ã‚’æ˜è¨˜
8. **æŠ€è¡“çš„å®Ÿè£…**: é¸å®šæŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ï¼ˆStreamlit, LangChain, Geminiç­‰ï¼‰ã«æº–æ‹ ã—ãŸå®Ÿè£…æ–¹é‡

ã€å›ç­”å“è³ªå‘ä¸ŠæŒ‡é‡ã€‘
â–  å…·ä½“æ€§: æŠ½è±¡çš„è¡¨ç¾ã‚’é¿ã‘ã€å®Ÿè£…å¯èƒ½ãªå…·ä½“çš„ä»•æ§˜ã‚’è¨˜è¼‰
â–  å®Œå…¨æ€§: é–¢é€£ã™ã‚‹å‘¨è¾ºæ©Ÿèƒ½ãƒ»ä¾å­˜é–¢ä¿‚ãƒ»åˆ¶ç´„æ¡ä»¶ã‚’æ¼ã‚Œãªãèª¬æ˜
â–  å®Ÿç”¨æ€§: ãƒãƒ¼ãƒ ï¼ˆé–‹ç™ºãƒ»PMãƒ»CSï¼‰ãŒå®Ÿéš›ã®æ¥­å‹™ã§å³æ´»ç”¨ã§ãã‚‹æƒ…å ±æä¾›
â–  ä¸€è²«æ€§: CLIENTTOMOãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å‘½åè¦å‰‡ãƒ»è¨­è¨ˆæ–¹é‡ã«æº–æ‹ 

ã€å°‚ç”¨å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆv2.1æ‹¡å¼µç‰ˆï¼‰ã€‘
## ğŸ¯ æ©Ÿèƒ½æ¦‚è¦
[è©²å½“æ©Ÿèƒ½ã®ç›®çš„ãƒ»å½¹å‰²ãƒ»CLIENTTOMOã«ãŠã‘ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¾¡å€¤ã‚’ç°¡æ½”ã«èª¬æ˜]

## ğŸ‘¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥ä»•æ§˜
[ä¼šå“¡ãƒ»ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¼æ¥­ãƒ»ç®¡ç†è€…ãã‚Œãã‚Œã®åˆ©ç”¨æ–¹æ³•ãƒ»æ¨©é™ãƒ»ç”»é¢å·®ç•°]

## ğŸ”§ å®Ÿè£…ä»•æ§˜
[é–‹ç™ºè€…å‘ã‘æŠ€è¡“è©³ç´°ï¼šAPIä»•æ§˜ã€ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã€ç”»é¢é·ç§»ã€ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã€é¸å®šæŠ€è¡“æ´»ç”¨æ–¹æ³•]

## ğŸ’¼ æ¥­å‹™ãƒ•ãƒ­ãƒ¼
[PMãƒ»CSå‘ã‘æ¥­å‹™è¦³ç‚¹ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œæ‰‹é †ã€ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã€ã‚µãƒãƒ¼ãƒˆæ™‚ã®æ³¨æ„ç‚¹]

## ğŸ”— é–¢é€£æ©Ÿèƒ½ãƒ»ä¾å­˜é–¢ä¿‚
[ã“ã®æ©Ÿèƒ½ã«é–¢é€£ã™ã‚‹ä»–ã®CLIENTTOMOæ©Ÿèƒ½ãƒ»ç”»é¢ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®é€£æºãƒã‚¤ãƒ³ãƒˆ]

## âš ï¸ æ³¨æ„äº‹é …ãƒ»åˆ¶ç´„
[å®Ÿè£…æ™‚ã®åˆ¶ç´„ã€æ—¢çŸ¥ã®èª²é¡Œã€å°†æ¥ã®æ”¹å–„äºˆå®šã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶]

## ğŸ“š å‚è€ƒæ–‡çŒ®ãƒ»æƒ…å ±æº
[ä»¥ä¸‹ã®å½¢å¼ã§ã€å›ç­”ã®æ ¹æ‹ ã¨ãªã£ãŸå…·ä½“çš„ãªãƒšãƒ¼ã‚¸ã‚’æ˜è¨˜:]
ğŸ“„ **[ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«]**
ğŸ”— [å®Œå…¨ãªURL]

[æ¤œç´¢çµæœã‹ã‚‰å¾—ã‚‰ã‚ŒãŸå„ãƒšãƒ¼ã‚¸ã«ã¤ã„ã¦ã€ä¸Šè¨˜å½¢å¼ã§åˆ—æŒ™]

## ğŸ¯ ã•ã‚‰ãªã‚‹æ·±æ˜ã‚Šãƒ»é–¢é€£æƒ…å ±
[ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¬¡ã«çŸ¥ã‚ŠãŸãã†ãªCLIENTTOMOé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»è³ªå•ã‚’ææ¡ˆ:]
- ã€Œ[é–¢é€£æ©Ÿèƒ½1]ã«ã¤ã„ã¦è©³ã—ãçŸ¥ã‚ŠãŸã„ã€
- ã€Œ[é–¢é€£æŠ€è¡“2]ã®å®Ÿè£…æ–¹æ³•ã‚’ç¢ºèªã—ãŸã„ã€  
- ã€Œ[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¤ãƒ—3]å‘ã‘ã®ä»•æ§˜ã‚’è¦‹ãŸã„ã€

---
**ä¿¡é ¼åº¦**: [é«˜/ä¸­/ä½] - [80%é–¢é€£åº¦CQLæ¤œç´¢çµæœã®å“è³ªã¨é–¢é€£æ€§ã«åŸºã¥ãåˆ¤æ–­ç†ç”±]

å›ç­”:"""

    def generate_response(self, search_results: List[Dict], user_query: str, memory_context: str = "") -> str:
        """
        æ¤œç´¢çµæœã‚’çµ±åˆã—ã¦æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆ
        
        Args:
            search_results: æ¤œç´¢çµæœãƒªã‚¹ãƒˆ
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
            memory_context: å‰å›ã®æ¤œç´¢ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            
        Returns:
            çµ±åˆã•ã‚ŒãŸæœ€çµ‚å›ç­”
        """
        try:
            # æ¤œç´¢çµæœã‚’æ§‹é€ åŒ–æ–‡å­—åˆ—ã«å¤‰æ›
            formatted_results = self._format_search_results(search_results)
            
            # ãƒ¡ãƒ¢ãƒªãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã¯è³ªå•ã‚’æ‹¡å¼µ
            enhanced_query = user_query
            if memory_context:
                enhanced_query = f"{user_query}\n\nã€å‰å›ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘{memory_context}"
            
            logger.info("ğŸ’¡ å›ç­”ç”Ÿæˆé–‹å§‹: ã‚¯ã‚¨ãƒª='%s', çµæœæ•°=%d, ãƒ¡ãƒ¢ãƒªãƒ¼=%s", user_query, len(search_results), bool(memory_context))
            
            # RunnableSequenceã§å›ç­”ç”Ÿæˆ (æœ€æ–°LangChain API)
            result = self.chain.invoke({
                "search_results": formatted_results,
                "user_query": enhanced_query
            })
            
            # AIMessageã‹ã‚‰æ–‡å­—åˆ—ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º
            response = result.content if hasattr(result, 'content') else str(result)
            
            # å‚ç…§å…ƒæƒ…å ±ã¨æ·±æ˜ã‚Šææ¡ˆã‚’è¿½åŠ 
            enhanced_response = self._enhance_response_with_sources(response, search_results, user_query)
            
            logger.info("âœ… å›ç­”ç”Ÿæˆå®Œäº†: æ–‡å­—æ•°=%d", len(enhanced_response))
            return enhanced_response
            
        except Exception as e:
            logger.error("âŒ å›ç­”ç”Ÿæˆå¤±æ•—: %s", str(e))
            return self._generate_error_response(user_query, str(e))
    
    def _enhance_response_with_sources(self, response: str, search_results: List[Dict], user_query: str) -> str:
        """
        å›ç­”ã«å‚ç…§å…ƒæƒ…å ±ã¨æ·±æ˜ã‚Šææ¡ˆã‚’è¿½åŠ 
        
        Args:
            response: ç”Ÿæˆã•ã‚ŒãŸå›ç­”
            search_results: æ¤œç´¢çµæœãƒªã‚¹ãƒˆ
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
            
        Returns:
            æ‹¡å¼µã•ã‚ŒãŸå›ç­”
        """
        # å‚ç…§å…ƒæƒ…å ±ã‚’ç”Ÿæˆ
        sources_section = self._generate_sources_section(search_results)
        
        # æ·±æ˜ã‚Šææ¡ˆã‚’ç”Ÿæˆ
        followup_section = self._generate_followup_suggestions(search_results, user_query)
        
        # å›ç­”ã«è¿½åŠ 
        if sources_section:
            response += f"\n\n{sources_section}"
        
        if followup_section:
            response += f"\n\n{followup_section}"
            
        return response
    
    def _generate_sources_section(self, search_results: List[Dict]) -> str:
        """
        å‚ç…§å…ƒæƒ…å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
        
        Args:
            search_results: æ¤œç´¢çµæœãƒªã‚¹ãƒˆ
            
        Returns:
            å‚ç…§å…ƒæƒ…å ±ã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³æ–‡å­—åˆ—
        """
        if not search_results:
            return ""
        
        sources_lines = ["## ğŸ“š å‚è€ƒæ–‡çŒ®ãƒ»æƒ…å ±æº"]
        
        for i, result in enumerate(search_results, 1):
            title = result.get('title', f'æ–‡æ›¸ {i}')
            url = result.get('url', result.get('link', ''))
            source = result.get('source', 'Unknown')
            
            if url:
                sources_lines.append(f"ğŸ“„ **{title}**")
                sources_lines.append(f"ğŸ”— {url}")
                sources_lines.append("")  # ç©ºè¡Œ
            else:
                # URLãŒãªã„å ´åˆã¯ã‚½ãƒ¼ã‚¹æƒ…å ±ã®ã¿
                sources_lines.append(f"ğŸ“„ **{title}** ({source})")
                sources_lines.append("")
        
        return "\n".join(sources_lines)
    
    def _generate_followup_suggestions(self, search_results: List[Dict], user_query: str) -> str:
        """
        ã•ã‚‰ãªã‚‹æ·±æ˜ã‚Šææ¡ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
        
        Args:
            search_results: æ¤œç´¢çµæœãƒªã‚¹ãƒˆ  
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
            
        Returns:
            æ·±æ˜ã‚Šææ¡ˆã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³æ–‡å­—åˆ—
        """
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•ã‹ã‚‰é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        query_keywords = self._extract_query_keywords(user_query)
        
        # æ¤œç´¢çµæœã‹ã‚‰é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        result_keywords = self._extract_result_keywords(search_results)
        
        # é–¢é€£ææ¡ˆã‚’ç”Ÿæˆ
        suggestions = []
        
        # åŸºæœ¬çš„ãªæ·±æ˜ã‚Šææ¡ˆ
        if "ãƒ­ã‚°ã‚¤ãƒ³" in user_query:
            suggestions.extend([
                "ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ã®ä¼šå“¡æ©Ÿèƒ½ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„",
                "ãƒ­ã‚°ã‚¤ãƒ³èªè¨¼ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä»•æ§˜ã‚’ç¢ºèªã—ãŸã„",
                "ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®ç”»é¢é·ç§»ãƒ•ãƒ­ãƒ¼ã‚’è¦‹ãŸã„"
            ])
        elif "API" in user_query:
            suggestions.extend([
                "APIèªè¨¼æ–¹å¼ã®è©³ç´°ä»•æ§˜ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„",
                "APIã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å®Ÿè£…æ–¹æ³•ã‚’ç¢ºèªã—ãŸã„",
                "APIåˆ©ç”¨åˆ¶é™ãƒ»ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã¤ã„ã¦ç¢ºèªã—ãŸã„"
            ])
        elif "UI" in user_query or "ç”»é¢" in user_query:
            suggestions.extend([
                "UIè¨­è¨ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„",
                "ç”»é¢é·ç§»ã®å…¨ä½“ãƒ•ãƒ­ãƒ¼ã‚’ç¢ºèªã—ãŸã„",
                "ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–å¯¾å¿œã®å®Ÿè£…ä»•æ§˜ã‚’è¦‹ãŸã„"
            ])
        else:
            # æ±ç”¨çš„ãªææ¡ˆ
            suggestions.extend([
                f"{query_keywords[0] if query_keywords else 'é–¢é€£æ©Ÿèƒ½'}ã®æŠ€è¡“ä»•æ§˜ã‚’è©³ã—ãçŸ¥ã‚ŠãŸã„",
                f"{query_keywords[0] if query_keywords else 'è©²å½“æ©Ÿèƒ½'}ã®é‹ç”¨æ‰‹é †ã‚’ç¢ºèªã—ãŸã„",
                f"{query_keywords[0] if query_keywords else 'é–¢é€£ã‚·ã‚¹ãƒ†ãƒ '}ã¨ã®é€£æºæ–¹æ³•ã‚’è¦‹ãŸã„"
            ])
        
        if not suggestions:
            return ""
        
        lines = ["## ğŸ¯ ã•ã‚‰ãªã‚‹æ·±æ˜ã‚Šãƒ»é–¢é€£æƒ…å ±"]
        for suggestion in suggestions[:3]:  # æœ€å¤§3ã¤ã«åˆ¶é™
            lines.append(f'- ã€Œ{suggestion}ã€')
        
        return "\n".join(lines)
    
    def _extract_query_keywords(self, user_query: str) -> List[str]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        keywords = []
        common_keywords = ["ãƒ­ã‚°ã‚¤ãƒ³", "èªè¨¼", "API", "UI", "ç”»é¢", "æ©Ÿèƒ½", "ä»•æ§˜", "è¨­è¨ˆ", "å®Ÿè£…"]
        
        for keyword in common_keywords:
            if keyword in user_query:
                keywords.append(keyword)
        
        return keywords
    
    def _extract_result_keywords(self, search_results: List[Dict]) -> List[str]:
        """æ¤œç´¢çµæœã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        keywords = set()
        
        for result in search_results:
            title = result.get('title', '')
            content = result.get('content', '')
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã¨å†…å®¹ã‹ã‚‰ç°¡å˜ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
            text = f"{title} {content}".lower()
            common_terms = ["èªè¨¼", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "ãƒ•ãƒ­ãƒ³ãƒˆ", "ãƒãƒƒã‚¯", "ãƒ†ã‚¹ãƒˆ"]
            
            for term in common_terms:
                if term in text:
                    keywords.add(term)
        
        return list(keywords)
    
    def _format_search_results(self, search_results: List[Dict]) -> str:
        """
        æ¤œç´¢çµæœã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        
        Args:
            search_results: æ¤œç´¢çµæœãƒªã‚¹ãƒˆ
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸçµæœæ–‡å­—åˆ—
        """
        if not search_results:
            return "æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        formatted_sections = []
        
        for i, result in enumerate(search_results, 1):
            source = result.get('source', 'Unknown')
            title = result.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
            content = result.get('content', result.get('summary', ''))
            url = result.get('url', '')
            relevance_score = result.get('relevance_score', 0)
            
            section = f"""
=== æ¤œç´¢çµæœ {i} ===
ã‚½ãƒ¼ã‚¹: {source}
ã‚¿ã‚¤ãƒˆãƒ«: {title}
é–¢é€£åº¦: {relevance_score:.2f}
URL: {url}
å†…å®¹:
{content}
"""
            formatted_sections.append(section)
        
        return "\n".join(formatted_sections)
    
    def _generate_error_response(self, user_query: str, error_message: str) -> str:
        """
        ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ç”Ÿæˆ
        
        Args:
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
            error_message: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            
        Returns:
            ã‚¨ãƒ©ãƒ¼å¿œç­”æ–‡å­—åˆ—
        """
        return f"""ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

## âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°
**è³ªå•**: {user_query}
**ã‚¨ãƒ©ãƒ¼**: {error_message}

## ğŸ”§ å¯¾å‡¦æ–¹æ³•
1. **å†è©¦è¡Œ**: ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„
2. **è³ªå•ã®è¦‹ç›´ã—**: ã‚ˆã‚Šå…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§è³ªå•ã‚’è¨€ã„æ›ãˆã¦ã¿ã¦ãã ã•ã„
3. **ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼èª¿æ•´**: æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å¤‰æ›´ã—ã¦å¯¾è±¡ç¯„å›²ã‚’åºƒã’ã¦ã¿ã¦ãã ã•ã„

## ğŸ’¬ ã‚µãƒãƒ¼ãƒˆ
å•é¡ŒãŒç¶™ç¶šã™ã‚‹å ´åˆã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚
ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å«ã‚ã¦ã”é€£çµ¡ã„ãŸã ã‘ã‚‹ã¨ã€ã‚ˆã‚Šè¿…é€Ÿãªå¯¾å¿œãŒå¯èƒ½ã§ã™ã€‚"""

    def validate_llm_connection(self) -> bool:
        """
        LLMæ¥ç¶šã®æ¤œè¨¼
        
        Returns:
            æ¥ç¶šæˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
        """
        try:
            test_response = self.llm.invoke("ãƒ†ã‚¹ãƒˆ")
            logger.info("âœ… LLMæ¥ç¶šæ¤œè¨¼æˆåŠŸ")
            return True
        except Exception as e:
            logger.error("âŒ LLMæ¥ç¶šæ¤œè¨¼å¤±æ•—: %s", str(e))
            return False 