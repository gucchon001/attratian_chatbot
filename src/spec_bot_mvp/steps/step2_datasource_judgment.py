"""
Step2: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¤å®šæ©Ÿèƒ½ï¼ˆä»•æ§˜æ›¸æº–æ‹ ï¼‰

ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨æ¤œç´¢æ„å›³ã«åŸºã¥ã„ã¦Jira/Confluenceã®æœ€é©ãªé¸æŠã‚’è¡Œã†
- ä»•æ§˜æ›¸æº–æ‹ ã®åˆ¤å®šå°‚ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
- é‡ã¿ä»˜ããƒãƒƒãƒè¨ˆç®—ï¼ˆç¢ºä¿¡åº¦30%ä»¥ä¸Šã§é¸æŠï¼‰
- Geminiã«ã‚ˆã‚‹æ¤œç´¢ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€é©åŒ–
- åˆ¤å®šå¾Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é™¤å»å‡¦ç†
"""

import logging
from typing import Dict, List, Any, Tuple
from pathlib import Path
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from langchain_google_genai import ChatGoogleGenerativeAI
except ImportError:
    ChatGoogleGenerativeAI = None

from src.spec_bot_mvp.config.settings import Settings
from src.spec_bot_mvp.utils.prompt_loader import load_prompt

logger = logging.getLogger(__name__)

class DataSourceJudge:
    """Step2: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¤å®šã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆä»•æ§˜æ›¸æº–æ‹ ï¼‰"""
    
    def __init__(self):
        self.settings = Settings()  # Settingsã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ
        self.gemini_available = self._init_gemini()
        self._init_judgment_rules()
    
    def _init_gemini(self) -> bool:
        """Gemini AIåˆæœŸåŒ–"""
        # Gemini APIè¨­å®šãƒã‚§ãƒƒã‚¯
        if not ChatGoogleGenerativeAI or not self.settings.gemini_api_key:
            raise ValueError("Gemini APIè¨­å®šã¾ãŸã¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        # GeminiåˆæœŸåŒ–
        self.llm = ChatGoogleGenerativeAI(
            api_key=self.settings.gemini_api_key,
            model=self.settings.gemini_model,  # settings.iniã‹ã‚‰èª­ã¿è¾¼ã¿
            temperature=self.settings.gemini_temperature  # settings.iniã‹ã‚‰èª­ã¿è¾¼ã¿
        )
        logger.info(f"Gemini AIåˆæœŸåŒ–æˆåŠŸï¼ˆStep2ï¼‰: {self.settings.gemini_model}")
        return True
    
    def _init_judgment_rules(self):
        """åˆ¤å®šãƒ«ãƒ¼ãƒ«ã®åˆæœŸåŒ–ï¼ˆä»•æ§˜æ›¸æº–æ‹ ï¼‰"""
        
        # ä»•æ§˜æ›¸æº–æ‹ ã®åˆ¤å®šå°‚ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé‡ã¿ä»˜ãï¼‰
        self.judgment_keywords = {
            # Confluenceåˆ¤å®šèªï¼ˆä»•æ§˜æ›¸2.2.2ï¼‰
            "confluence": {
                "ä»•æ§˜": 0.9, "è©³ç´°": 0.8, "è¨­è¨ˆæ›¸": 0.9, "API": 0.8, "è¦ä»¶": 0.8,
                "å®Ÿè£…": 0.7, "ãƒ•ãƒ­ãƒ¼": 0.7, "ç”»é¢": 0.6, "UI": 0.6, "UX": 0.6,
                "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹": 0.7, "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹": 0.7, "ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ": 0.8, "æ©Ÿèƒ½ä»•æ§˜": 0.9,
                "æ©Ÿèƒ½": 0.5, "æ©Ÿèƒ½è©³ç´°": 0.85, "æ©Ÿèƒ½ã®è©³ç´°": 0.85
            },
            
            # Jiraåˆ¤å®šèªï¼ˆä»•æ§˜æ›¸2.2.2ï¼‰
            "jira": {
                "ãƒã‚±ãƒƒãƒˆ": 0.9, "é€²æ—": 0.8, "ãƒã‚°": 0.9, "ä¸å…·åˆ": 0.9, "ä»•æ§˜å¤‰æ›´": 0.7,
                "ã‚¿ã‚¹ã‚¯": 0.8, "issue": 0.9, "å¯¾å¿œçŠ¶æ³": 0.8, "ä¿®æ­£": 0.7, "æ”¹ä¿®": 0.7,
                "ã‚¨ãƒ©ãƒ¼": 0.8, "å•é¡Œ": 0.7, "èª²é¡Œ": 0.7, "é–‹ç™ºé€²æ—": 0.8
            },
            
            # è­°äº‹éŒ²åˆ¤å®šèªï¼ˆä»•æ§˜æ›¸2.2.2ï¼‰  
            "confluence_meeting": {
                "è­°äº‹éŒ²": 0.9, "éå»ã®çµŒç·¯": 0.8, "ä¼šè­°": 0.8, "æ‰“ã¡åˆã‚ã›": 0.8,
                "æ±ºå®šäº‹é …": 0.8, "åˆæ„": 0.7, "å±¥æ­´": 0.7, "å¤‰æ›´å±¥æ­´": 0.8,
                "è­°è«–": 0.7, "MTG": 0.8, "ç›¸è«‡": 0.6, "æ¤œè¨": 0.6
            }
        }
        
        # é™¤å»å¯¾è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä»•æ§˜æ›¸2.2.3ï¼‰
        self.removal_keywords = {
            "åˆ¤å®šå°‚ç”¨èª": ["ä»•æ§˜", "è©³ç´°", "æ©Ÿèƒ½", "ãƒã‚±ãƒƒãƒˆ", "é€²æ—", "è­°äº‹éŒ²"],
            "å‹•è©": ["æ•™ãˆã¦", "èª¬æ˜ã—ã¦", "æ•´ç†ã—ã¦", "æŠ½å‡ºã—ã¦", "ç¢ºèªã—ã¦", "è¦‹ã¤ã‘ã¦"]
        }
    
    def judge_datasource(self, keyword_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¤å®šã‚’å®Ÿè¡Œï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ + Geminiï¼‰
        
        Args:
            keyword_result: Step1ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºçµæœ
            
        Returns:
            åˆ¤å®šçµæœè¾æ›¸ï¼ˆä»•æ§˜æ›¸æº–æ‹ ï¼‰
        """
        logger.info(f"ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¤å®šé–‹å§‹: {keyword_result.get('search_intent', 'unknown')}")
        
        # Step1çµæœã®æŠ½å‡º
        primary_keywords = keyword_result.get("primary_keywords", [])
        search_intent = keyword_result.get("search_intent", "ä¸€èˆ¬æ¤œç´¢")
        
        # Phase 1: é«˜é€Ÿãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ¤å®š
        rule_based_result = self._calculate_weighted_match(primary_keywords)
        rule_confidence = max(rule_based_result.values())
        
        logger.info(f"ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ¤å®š: Confluence={rule_based_result['confluence']:.2f}, Jira={rule_based_result['jira']:.2f}, æœ€é«˜ä¿¡é ¼åº¦={rule_confidence:.2f}")
        
        # Phase 2: ä¿¡é ¼åº¦ãƒã‚§ãƒƒã‚¯ã¨Geminiåˆ¤å®š
        if rule_confidence >= 0.8:
            # é«˜ä¿¡é ¼åº¦ï¼šãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹çµæœã‚’æ¡ç”¨ï¼ˆé«˜é€Ÿï¼‰
            datasource_scores = rule_based_result
            judgment_method = "rule_based_high_confidence"
            logger.info(f"âœ… é«˜ä¿¡é ¼åº¦ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ¤å®šæ¡ç”¨: {judgment_method}")
        else:
            # ä½ä¿¡é ¼åº¦ï¼šGeminiæ–‡è„ˆç†è§£åˆ¤å®š
            gemini_result = self._gemini_datasource_judgment(primary_keywords, search_intent)
            if gemini_result:
                datasource_scores = self._integrate_judgments(rule_based_result, gemini_result)
                judgment_method = "hybrid_gemini_enhanced"
                logger.info(f"ğŸ¤– Geminiå¼·åŒ–åˆ¤å®šæ¡ç”¨: {judgment_method}")
            else:
                # Geminiå¤±æ•—æ™‚ï¼šãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                datasource_scores = rule_based_result
                judgment_method = "rule_based_fallback"
                logger.warning(f"âš ï¸ Geminiåˆ¤å®šå¤±æ•—ã€ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æ¡ç”¨: {judgment_method}")
        
        # 3. é–¾å€¤åˆ¤å®šï¼ˆå‹•çš„èª¿æ•´ï¼‰
        keywords_str = " ".join(primary_keywords).lower()
        if any(pattern in keywords_str for pattern in ["æ©Ÿèƒ½.*è©³ç´°", "æ©Ÿèƒ½.*ä»•æ§˜", ".*ä»•æ§˜.*è©³ç´°"]):
            threshold = 0.7  # è¤‡åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯å³æ ¼
        elif any(keyword in keywords_str for keyword in ["æ©Ÿèƒ½", "è©³ç´°", "ä»•æ§˜"]):
            threshold = 0.5  # å˜ä½“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯ä¸­ç¨‹åº¦
        else:
            threshold = 0.4  # ä¸€èˆ¬ã‚¯ã‚¨ãƒª
        selected_datasources = self._apply_threshold_selection(datasource_scores, threshold=threshold)
        
        # 4. Geminiã«ã‚ˆã‚‹æ¤œç´¢ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€é©åŒ–ï¼ˆä»•æ§˜æ›¸2.2.3ï¼‰
        optimized_keywords = self._optimize_keywords_with_gemini(primary_keywords, selected_datasources)
        
        # 5. ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å„ªå…ˆé †åºæ±ºå®šï¼ˆé¸æŠã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ã¿ï¼‰
        datasource_priority = sorted(selected_datasources, key=lambda x: datasource_scores[x], reverse=True)
        
        # 6. åˆ¤å®šç†ç”±ç”Ÿæˆ
        reasoning = self._generate_reasoning_spec_compliant(
            primary_keywords, datasource_scores, selected_datasources, search_intent
        )
        
        result = {
            "datasource_priority": datasource_priority,
            "priority_scores": datasource_scores,
            "selected_datasources": selected_datasources,
            "judgment_reasoning": reasoning,
            "judgment_method": judgment_method,  # åˆ¤å®šæ‰‹æ³•ã‚’è¿½åŠ 
            "optimized_keywords": optimized_keywords,
            "original_keywords": primary_keywords,
            "keywords_removed": self._get_removed_keywords(primary_keywords, optimized_keywords)
        }
        
        logger.info(f"ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ¤å®šå®Œäº† [{judgment_method}]: {selected_datasources} (æœ€é«˜ã‚¹ã‚³ã‚¢: {max(datasource_scores.values()):.2f})")
        return result
    
    def _calculate_weighted_match(self, keywords: List[str]) -> Dict[str, float]:
        """é‡ã¿ä»˜ããƒãƒƒãƒè¨ˆç®—ï¼ˆä»•æ§˜æ›¸2.2.2ï¼‰"""
        scores = {"confluence": 0.0, "jira": 0.0}
        
        # è¤‡åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¤å®šï¼ˆå„ªå…ˆï¼‰
        keywords_str = " ".join(keywords).lower()
        
        # é«˜ç¢ºä¿¡åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆConfluenceå¼·ã‚ï¼‰
        high_confidence_confluence_patterns = [
            ("æ©Ÿèƒ½.*è©³ç´°", 0.9), ("æ©Ÿèƒ½.*ä»•æ§˜", 0.9), (".*è©³ç´°.*ä»•æ§˜", 0.85),
            ("[ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾¯]+.*æ©Ÿèƒ½.*è©³ç´°", 0.95), ("api.*ä»•æ§˜", 0.9), ("è¨­è¨ˆ.*è©³ç´°", 0.9)
        ]
        
        # é«˜ç¢ºä¿¡åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆJiraå¼·ã‚ï¼‰
        high_confidence_jira_patterns = [
            ("ãƒã‚±ãƒƒãƒˆ.*é€²æ—", 0.9), ("ãƒã‚°.*ä¿®æ­£", 0.95), ("ä¸å…·åˆ.*å¯¾å¿œ", 0.9),
            ("issue.*status", 0.9), ("ã‚¿ã‚¹ã‚¯.*é€²æ—", 0.85)
        ]
        
        import re
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        for pattern, weight in high_confidence_confluence_patterns:
            if re.search(pattern, keywords_str):
                scores["confluence"] += weight
                logger.debug(f"Confluenceè¤‡åˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ: '{pattern}' (é‡ã¿: {weight})")
        
        for pattern, weight in high_confidence_jira_patterns:
            if re.search(pattern, keywords_str):
                scores["jira"] += weight
                logger.debug(f"Jiraè¤‡åˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ: '{pattern}' (é‡ã¿: {weight})")
        
        # å€‹åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¤å®šï¼ˆå¾“æ¥é€šã‚Šï¼‰
        for keyword in keywords:
            keyword_lower = keyword.lower()
            
            # Confluenceåˆ¤å®šèªãƒãƒƒãƒ
            for conf_word, weight in self.judgment_keywords["confluence"].items():
                if conf_word in keyword_lower:
                    scores["confluence"] += weight
                    logger.debug(f"Confluenceåˆ¤å®šèªãƒãƒƒãƒ: '{keyword}' -> '{conf_word}' (é‡ã¿: {weight})")
            
            # è­°äº‹éŒ²åˆ¤å®šèªã‚‚Confluenceã«åŠ ç®—
            for meeting_word, weight in self.judgment_keywords["confluence_meeting"].items():
                if meeting_word in keyword_lower:
                    scores["confluence"] += weight
                    logger.debug(f"è­°äº‹éŒ²åˆ¤å®šèªãƒãƒƒãƒ: '{keyword}' -> '{meeting_word}' (é‡ã¿: {weight})")
            
            # Jiraåˆ¤å®šèªãƒãƒƒãƒ
            for jira_word, weight in self.judgment_keywords["jira"].items():
                if jira_word in keyword_lower:
                    scores["jira"] += weight
                    logger.debug(f"Jiraåˆ¤å®šèªãƒãƒƒãƒ: '{keyword}' -> '{jira_word}' (é‡ã¿: {weight})")
        
        # æ­£è¦åŒ–ï¼ˆ0-1ã®ç¯„å›²ï¼‰
        total_score = sum(scores.values())
        if total_score > 0:
            scores = {k: v / total_score for k, v in scores.items()}
        else:
            # æ©Ÿèƒ½ç³»ã‚¯ã‚¨ãƒªã®å ´åˆã¯Confluenceå„ªå…ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            has_function_keywords = any(keyword in str(keywords).lower() for keyword in ["æ©Ÿèƒ½", "è©³ç´°", "ä»•æ§˜"])
            if has_function_keywords:
                scores = {"confluence": 0.85, "jira": 0.15}  # æ©Ÿèƒ½ç³»ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            else:
                scores = {"confluence": 0.6, "jira": 0.4}  # ä¸€èˆ¬ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        return scores
    
    def _apply_threshold_selection(self, scores: Dict[str, float], threshold: float = 0.3) -> List[str]:
        """é–¾å€¤åˆ¤å®šï¼ˆç¢ºä¿¡åº¦30%ä»¥ä¸Šã§é¸æŠï¼‰"""
        selected = [datasource for datasource, score in scores.items() if score >= threshold]
        
        # æœ€ä½1ã¤ã¯é¸æŠå¿…é ˆ
        if not selected:
            selected = [max(scores.keys(), key=lambda k: scores[k])]
        
        return selected
    
    def _optimize_keywords_with_gemini(self, keywords: List[str], selected_datasources: List[str]) -> List[str]:
        """Geminiã«ã‚ˆã‚‹æ¤œç´¢ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€é©åŒ–ï¼ˆä»•æ§˜æ›¸2.2.3ï¼‰"""
        if not self.gemini_available:
            # Geminiåˆ©ç”¨ä¸å¯æ™‚ã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹é™¤å»
            return self._rule_based_keyword_optimization(keywords)
        
        try:
            prompt = load_prompt(
                "analysis_steps",
                "step2_datasource_judgment", 
                "keyword_optimization",
                keywords=keywords,
                selected_datasources=selected_datasources
            )
            
            response = self.llm.invoke(prompt)
            
            # JSONè§£æ
            import json
            json_start = response.content.find('{')
            json_end = response.content.rfind('}') + 1
            json_str = response.content[json_start:json_end]
            
            result = json.loads(json_str)
            optimized = result.get("optimized_keywords", keywords)
            
            logger.info(f"Geminiã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€é©åŒ–å®Œäº†: {keywords} -> {optimized}")
            return optimized
            
        except Exception as e:
            logger.warning(f"Geminiã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€é©åŒ–å¤±æ•—ã€ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã«åˆ‡æ›¿: {e}")
            return self._rule_based_keyword_optimization(keywords)
    
    def _rule_based_keyword_optimization(self, keywords: List[str]) -> List[str]:
        """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€é©åŒ–ï¼ˆGeminiãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        optimized = []
        
        for keyword in keywords:
            should_remove = False
            keyword_lower = keyword.lower()
            
            # åˆ¤å®šå°‚ç”¨èªã®é™¤å»
            for removal_word in self.removal_keywords["åˆ¤å®šå°‚ç”¨èª"]:
                if removal_word in keyword_lower and keyword_lower == removal_word:
                    should_remove = True
                    break
            
            # å‹•è©ã®é™¤å»
            for removal_word in self.removal_keywords["å‹•è©"]:
                if removal_word in keyword_lower:
                    should_remove = True
                    break
            
            if not should_remove:
                optimized.append(keyword)
        
        # æœ€ä½1ã¤ã¯ä¿æŒ
        if not optimized and keywords:
            optimized = [keywords[0]]
        
        logger.info(f"ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€é©åŒ–å®Œäº†: {keywords} -> {optimized}")
        return optimized
    
    def _get_removed_keywords(self, original: List[str], optimized: List[str]) -> List[str]:
        """é™¤å»ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ç‰¹å®š"""
        return [kw for kw in original if kw not in optimized]
    
    def _generate_reasoning_spec_compliant(self, keywords: List[str], scores: Dict[str, float], 
                                         selected: List[str], intent: str) -> str:
        """åˆ¤å®šç†ç”±ç”Ÿæˆï¼ˆä»•æ§˜æ›¸æº–æ‹ ï¼‰"""
        reasoning_parts = []
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        reasoning_parts.append(f"å…¥åŠ›ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keywords)}")
        
        # é‡ã¿ä»˜ããƒãƒƒãƒçµæœ
        for datasource, score in scores.items():
            reasoning_parts.append(f"{datasource.title()}ç¢ºä¿¡åº¦: {score:.2f}")
        
        # é¸æŠçµæœ
        reasoning_parts.append(f"é¸æŠãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {', '.join(selected)}")
        
        # æ¤œç´¢æ„å›³
        reasoning_parts.append(f"æ¤œç´¢æ„å›³: {intent}")
        
        return " | ".join(reasoning_parts)
    
    def _gemini_datasource_judgment(self, keywords: List[str], search_intent: str) -> Dict[str, float]:
        """
        Geminiã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¤å®šï¼ˆæ—¢å­˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ´»ç”¨ï¼‰
        
        Args:
            keywords: æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            search_intent: æ¤œç´¢æ„å›³
            
        Returns:
            Geminiåˆ¤å®šã‚¹ã‚³ã‚¢è¾æ›¸ or Noneï¼ˆå¤±æ•—æ™‚ï¼‰
        """
        if not self.gemini_available:
            logger.warning("Geminiåˆ©ç”¨ä¸å¯ã€Geminiåˆ¤å®šã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return None
        
        try:
            # æ—¢å­˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ´»ç”¨
            prompt = load_prompt(
                "analysis_steps",
                "step2_datasource_judgment", 
                "datasource_confidence_judgment",
                keywords=keywords,
                search_intent=search_intent
            )
            
            logger.info(f"ğŸ¤– Geminiæ–‡è„ˆåˆ¤å®šå®Ÿè¡Œ: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰={keywords}, æ„å›³={search_intent}")
            response = self.llm.invoke(prompt)
            
            # JSONè§£æ
            import json
            json_start = response.content.find('{')
            json_end = response.content.rfind('}') + 1
            json_str = response.content[json_start:json_end]
            
            result = json.loads(json_str)
            
            # çµæœã®æŠ½å‡ºã¨æ¤œè¨¼
            confluence_conf = float(result.get("confluence_confidence", 0.5))
            jira_conf = float(result.get("jira_confidence", 0.5))
            reasoning = result.get("reasoning", "Geminiåˆ¤å®š")
            
            # æ­£è¦åŒ–
            total = confluence_conf + jira_conf
            if total > 0:
                confluence_conf = confluence_conf / total
                jira_conf = jira_conf / total
            
            gemini_scores = {
                "confluence": confluence_conf,
                "jira": jira_conf
            }
            
            logger.info(f"âœ… Geminiåˆ¤å®šå®Œäº†: Confluence={confluence_conf:.2f}, Jira={jira_conf:.2f}")
            logger.info(f"ğŸ“ Geminiåˆ¤å®šç†ç”±: {reasoning}")
            
            return gemini_scores
            
        except Exception as e:
            logger.error(f"âŒ Geminiåˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _integrate_judgments(self, rule_scores: Dict[str, float], gemini_scores: Dict[str, float]) -> Dict[str, float]:
        """
        ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã¨Geminiåˆ¤å®šã®çµ±åˆ
        
        Args:
            rule_scores: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ¤å®šã‚¹ã‚³ã‚¢
            gemini_scores: Geminiåˆ¤å®šã‚¹ã‚³ã‚¢
            
        Returns:
            çµ±åˆåˆ¤å®šã‚¹ã‚³ã‚¢
        """
        # é‡ã¿ä»˜ãçµ±åˆï¼ˆGeminiå„ªå…ˆã ãŒã€ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚‚è€ƒæ…®ï¼‰
        rule_weight = 0.3  # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹é‡ã¿
        gemini_weight = 0.7  # Geminié‡ã¿
        
        integrated_scores = {}
        for datasource in ["confluence", "jira"]:
            integrated_score = (
                rule_scores[datasource] * rule_weight + 
                gemini_scores[datasource] * gemini_weight
            )
            integrated_scores[datasource] = integrated_score
        
        logger.info(f"ğŸ”— åˆ¤å®šçµ±åˆå®Œäº†: ãƒ«ãƒ¼ãƒ«é‡ã¿={rule_weight}, Geminié‡ã¿={gemini_weight}")
        logger.info(f"ğŸ“Š çµ±åˆçµæœ: Confluence={integrated_scores['confluence']:.2f}, Jira={integrated_scores['jira']:.2f}")
        
        return integrated_scores 