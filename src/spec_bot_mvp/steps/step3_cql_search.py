"""
Step3: CQLæ¤œç´¢å®Ÿè¡Œæ©Ÿèƒ½ï¼ˆCLIENTTOMOç‰¹åŒ–æœ€é©åŒ–ç‰ˆï¼‰

3æ®µéšæ¤œç´¢æˆ¦ç•¥ã«ã‚ˆã‚‹åŠ¹æœçš„ãªçµæœå–å¾—ï¼ˆç²¾åº¦å‘ä¸Šç‰ˆï¼‰
- Strategy1: å³å¯†æ¤œç´¢ï¼ˆANDçµåˆã€å®Œå…¨ä¸€è‡´é‡è¦–ï¼‰+ CLIENTTOMOç‰¹åŒ–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
- Strategy2: ç·©å’Œæ¤œç´¢ï¼ˆORçµåˆã€éƒ¨åˆ†ä¸€è‡´è¨±å¯ï¼‰+ ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜æ´»ç”¨
- Strategy3: æ‹¡å¼µæ¤œç´¢ï¼ˆé¡ç¾©èªå±•é–‹ã€é–¢é€£èªè¿½åŠ ï¼‰+ æ¥­å‹™æ–‡è„ˆè€ƒæ…®

88% â†’ 92%+ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®CLIENTTOMOç‰¹åŒ–æœ€é©åŒ–
å¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¨­è¨ˆæ›¸ã«åŸºã¥ãJQL/CQLã‚¯ã‚¨ãƒªç”Ÿæˆ
å®Ÿéš›ã®Atlassian APIæ¥ç¶šå¯¾å¿œ (è¨­å®šã«ã‚ˆã‚Šè‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ)
"""

import logging
import re
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

logger = logging.getLogger(__name__)

# å®Ÿéš›ã®APIæ¥ç¶šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
try:
    from ..utils.atlassian_api_client import AtlassianAPIClient
    from ..config.settings import Settings
    ATLASSIAN_CLIENT_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Atlassian APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
    ATLASSIAN_CLIENT_AVAILABLE = False

class CQLSearchEngine:
    """Step3: CQLæ¤œç´¢å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³ (å®Ÿéš›ã®APIæ¥ç¶šå¯¾å¿œ)"""
    
    def __init__(self):
        self._init_api_client()  # è¨­å®šã‚’å…ˆã«èª­ã¿è¾¼ã¿
        self._init_search_strategies()
        self._init_query_builders()
    
    def _init_api_client(self):
        """APIæ¥ç¶šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã¨æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        from ..config.settings import Settings
        
        self.settings = Settings()
        self.api_client = None
        
        # APIæ¥ç¶šãƒ†ã‚¹ãƒˆã¨å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰æ±ºå®š
        self.use_real_api = self._test_api_connection()
        
        mode = "æœ¬ç•ªAPI" if self.use_real_api else "æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿"
        logger.info(f"ğŸš€ CQLæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº† - ãƒ¢ãƒ¼ãƒ‰: {mode}")
    
    def _test_api_connection(self) -> bool:
        """
        Atlassian APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
        
        Returns:
            bool: æ¥ç¶šæˆåŠŸæ™‚ã¯Trueã€å¤±æ•—æ™‚ã¯False
        """
        logger.info("ğŸ” Atlassian APIæ¥ç¶šãƒ†ã‚¹ãƒˆé–‹å§‹...")
        
        try:
            # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
            from atlassian import Confluence
            logger.info("âœ… atlassian-python-api ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç¢ºèªå®Œäº†")
            
            # è¨­å®šå€¤ã®æ¤œè¨¼
            logger.info(f"ğŸ“‹ è¨­å®šå€¤ç¢ºèª: Domain={self.settings.atlassian_domain}, Email={self.settings.atlassian_email}")
            if not all([
                self.settings.atlassian_domain,
                self.settings.atlassian_email, 
                self.settings.atlassian_api_token
            ]):
                logger.error("âŒ Atlassian APIè¨­å®šãŒä¸å®Œå…¨ã§ã™")
                return False
            
            logger.info("âœ… è¨­å®šå€¤æ¤œè¨¼å®Œäº†")
            
            # å®Ÿéš›ã®æ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆè»½é‡ãªAPIã‚³ãƒ¼ãƒ«ï¼‰
            logger.info(f"ğŸ”— Confluenceæ¥ç¶šãƒ†ã‚¹ãƒˆ: https://{self.settings.atlassian_domain}")
            confluence = Confluence(
                url=f"https://{self.settings.atlassian_domain}",
                username=self.settings.atlassian_email,
                password=self.settings.atlassian_api_token
            )
            
            # ç°¡å˜ãªæ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆã‚¹ãƒšãƒ¼ã‚¹ä¸€è¦§å–å¾—ï¼‰
            logger.info("ğŸ“¡ ã‚¹ãƒšãƒ¼ã‚¹ä¸€è¦§å–å¾—ãƒ†ã‚¹ãƒˆ...")
            spaces = confluence.get_all_spaces(limit=1)
            
            if spaces and 'results' in spaces:
                space_count = len(spaces['results'])
                logger.info(f"âœ… Atlassian APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ: {self.settings.atlassian_domain} ({space_count}å€‹ã®ã‚¹ãƒšãƒ¼ã‚¹)")
                return True
            else:
                logger.warning(f"âš ï¸ Atlassian APIæ¥ç¶šãƒ†ã‚¹ãƒˆ: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæœŸå¾…ã¨ç•°ãªã‚Šã¾ã™ - {spaces}")
                return False
                
        except ImportError as e:
            logger.error(f"âŒ atlassian-python-apiãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ Atlassian APIæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            import traceback
            logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            return False

    def _init_search_strategies(self):
        """æ¤œç´¢æˆ¦ç•¥ã®åˆæœŸåŒ–"""
        
        # 4æ®µéšæ¤œç´¢æˆ¦ç•¥å®šç¾©ï¼ˆANDæ¤œç´¢å„ªå…ˆ + æ®µéšçš„ç·©å’Œï¼‰
        self.strategies = {
             "strategy1": {
                 "name": "ã‚¿ã‚¤ãƒˆãƒ«å³å¯†æ¤œç´¢",
                 "description": "ã‚¿ã‚¤ãƒˆãƒ«å†…ANDçµåˆã«ã‚ˆã‚‹æœ€é«˜ç²¾åº¦æ¤œç´¢",
                 "operator": "AND",  # â† ANDæ¤œç´¢ã«å¤‰æ›´
                 "match_type": "title",
                 "max_results": 20,
                 "weight": 3.0  # æœ€é«˜é‡ã¿
             },
             "strategy2": {
                 "name": "ã‚¿ã‚¤ãƒˆãƒ«è¿‘æ¥æ¤œç´¢", 
                 "description": "ã‚¿ã‚¤ãƒˆãƒ«å†…è¤‡åˆèªãƒ»è¿‘æ¥æ¤œç´¢",
                 "operator": "NEAR",  # è¿‘æ¥æ¤œç´¢
                 "match_type": "title_complex",
                 "max_results": 30,
                 "weight": 2.5
             },
             "strategy3": {
                 "name": "æœ¬æ–‡å³å¯†æ¤œç´¢",
                 "description": "æœ¬æ–‡ANDçµåˆã«ã‚ˆã‚‹é«˜ç²¾åº¦æ¤œç´¢",
                 "operator": "AND",
                 "match_type": "exact",
                 "max_results": 50,
                 "weight": 1.5
             },
             "strategy4": {
                 "name": "è£œå®ŒORæ¤œç´¢",
                 "description": "æ±ç”¨èªé™¤å¤–æ¸ˆã¿ORæ¤œç´¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰", 
                 "operator": "OR",
                 "match_type": "filtered",
                 "max_results": 30,  # çµæœæ•°ã‚’åˆ¶é™
                 "weight": 0.8  # é‡ã¿ã‚’ä¸‹ã’ã‚‹
             }
         }
        
        # é¡ç¾©èªãƒ»é–¢é€£èªè¾æ›¸
        self.synonym_dict = {
            "ãƒ­ã‚°ã‚¤ãƒ³": ["login", "èªè¨¼", "ã‚µã‚¤ãƒ³ã‚¤ãƒ³", "authentication"],
            "ãƒã‚°": ["bug", "ä¸å…·åˆ", "ã‚¨ãƒ©ãƒ¼", "issue", "å•é¡Œ"],
            "API": ["interface", "endpoint", "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"],
            "UI": ["ç”»é¢", "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹", "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰"],
            "DB": ["ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "database"],
            "ãƒ†ã‚¹ãƒˆ": ["test", "testing", "æ¤œè¨¼", "verification"],
            "ä»•æ§˜": ["spec", "specification", "è¦ä»¶"],
            "è¨­è¨ˆ": ["design", "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£", "architecture"]
        }
        
        # æ±ç”¨èªï¼ˆã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ï¼‰- ORæ¤œç´¢ã§é™¤å¤–ã™ã¹ãå˜èª
        self.stop_words = {
            "æ©Ÿèƒ½", "ã‚·ã‚¹ãƒ†ãƒ ", "ä»•æ§˜", "è¨­è¨ˆ", "å®Ÿè£…", "é–‹ç™º", "ç®¡ç†", 
            "å‡¦ç†", "ç”»é¢", "ãƒšãƒ¼ã‚¸", "ãƒ•ã‚©ãƒ¼ãƒ ", "ãƒœã‚¿ãƒ³", "ãƒ¡ãƒ‹ãƒ¥ãƒ¼",
            "ãƒ‡ãƒ¼ã‚¿", "æƒ…å ±", "å†…å®¹", "è©³ç´°", "èª¬æ˜", "è³‡æ–™", "æ–‡æ›¸",
            "è¦ä»¶", "é …ç›®", "ä¸€è¦§", "ãƒªã‚¹ãƒˆ", "ãƒ†ãƒ¼ãƒ–ãƒ«", "ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰",
            "ã‚³ãƒ¼ãƒ‰", "ãƒ—ãƒ­ã‚°ãƒ©ãƒ ", "ã‚¹ã‚¯ãƒªãƒ—ãƒˆ", "ãƒ•ã‚¡ã‚¤ãƒ«", "ãƒ•ã‚©ãƒ«ãƒ€"
        }
        
        # ã‚¿ã‚¤ãƒˆãƒ«é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆå‰Šé™¤ãƒ»å»ƒæ­¢ãƒ»çµ‚äº†æ¸ˆã¿ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
        self._init_exclusion_patterns()
        
                 # é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ã®æœ‰åŠ¹/ç„¡åŠ¹è¨­å®šï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
        self.enable_exclusion_filter = self.settings.enable_exclusion_filter
    
    def _init_exclusion_patterns(self):
        """é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆæœŸåŒ–ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ãƒ»ã€ã€‘å†…å«æœ‰æ¤œç´¢å¯¾å¿œï¼‰"""
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’èª­ã¿è¾¼ã¿
        self.exclusion_keywords = {
            "bracket_keywords": self.settings.bracket_exclusion_keywords,
            "percent_keywords": self.settings.percent_exclusion_keywords,
            "english_keywords": self.settings.english_exclusion_keywords,
            "temporary_keywords": self.settings.temporary_exclusion_keywords
        }
        
        # å…¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ã‚’ãƒ­ã‚°å‡ºåŠ›
        total_keywords = sum(len(keywords) for keywords in self.exclusion_keywords.values())
        logger.info(f"ğŸ—‘ï¸ é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆæœŸåŒ–å®Œäº†: {total_keywords}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã€ã€‘%%å†…å«æœ‰æ¤œç´¢å¯¾å¿œï¼‰")
    
    def _init_query_builders(self):
        """ã‚¯ã‚¨ãƒªãƒ“ãƒ«ãƒ€ãƒ¼ã®åˆæœŸåŒ–"""
        
        # JQLã‚¯ã‚¨ãƒªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.jql_templates = {
            "basic": "text ~ \"{keywords}\"",
            "with_project": "text ~ \"{keywords}\" AND project = \"{project}\"",
            "with_status": "text ~ \"{keywords}\" AND status IN ({status})",
            "with_type": "text ~ \"{keywords}\" AND issuetype IN ({issuetype})",
            "complex": "text ~ \"{keywords}\" AND project = \"{project}\" AND status IN ({status}) AND issuetype IN ({issuetype})"
        }
        
        # CQLã‚¯ã‚¨ãƒªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.cql_templates = {
            "basic": "text ~ \"{keywords}\"",
            "with_space": "text ~ \"{keywords}\" AND space = \"{space}\"",
            "with_type": "text ~ \"{keywords}\" AND type = \"{content_type}\"",
            "with_date": "text ~ \"{keywords}\" AND created >= \"{date}\"",
            "complex": "text ~ \"{keywords}\" AND space IN ({spaces}) AND type = \"{content_type}\""
        }
    
    def execute_search(self, step2_result: Dict[str, Any], step1_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        CQLæ¤œç´¢ã‚’å®Ÿè¡Œ
        
        Args:
            step2_result: Step2ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¤å®šçµæœ
            step1_result: Step1ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºçµæœ
            
        Returns:
            æ¤œç´¢çµæœè¾æ›¸ {
                "search_results": {ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥çµæœ},
                "strategies_executed": [å®Ÿè¡Œæˆ¦ç•¥ãƒªã‚¹ãƒˆ],
                "query_details": {ã‚¯ã‚¨ãƒªè©³ç´°},
                "total_results": ç·ä»¶æ•°,
                "execution_summary": "å®Ÿè¡Œã‚µãƒãƒªãƒ¼"
            }
        """
        logger.info("Step3: CQLæ¤œç´¢å®Ÿè¡Œé–‹å§‹")
        
        # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æº–å‚™
        datasource_priority = step2_result.get("datasource_priority", ["confluence", "jira"])
        search_strategy = step2_result.get("search_strategy", "parallel")
        recommended_filters = step2_result.get("recommended_filters", {})
        
        primary_keywords = step1_result.get("primary_keywords", [])
        secondary_keywords = step1_result.get("secondary_keywords", [])
        search_intent = step1_result.get("search_intent", "ä¸€èˆ¬æ¤œç´¢")
        
        # å®Ÿè¡Œæˆ¦ç•¥æ±ºå®š
        strategies_to_execute = self._determine_execution_strategies(search_strategy, step2_result)
        
        # UIã§ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠã‚’å–å¾—
        enabled_datasources = self._get_enabled_datasources()
        
        # UIã®é¸æŠã¨Step2ã®åˆ¤å®šçµæœã‚’çµ„ã¿åˆã‚ã›ã¦æœ€çµ‚çš„ãªæ¤œç´¢å¯¾è±¡ã‚’æ±ºå®š
        final_datasources = self._determine_final_datasources(datasource_priority, enabled_datasources)
        
        logger.info(f"ğŸ¯ æ¤œç´¢å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ±ºå®š: {final_datasources} (UIé¸æŠ: {enabled_datasources}, Step2å„ªå…ˆåº¦: {datasource_priority})")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥æ®µéšçš„æ¤œç´¢å®Ÿè¡Œ
        search_results = {}
        query_details = {}
        
        for datasource in final_datasources:
            if datasource in ["jira", "confluence"]:
                ds_results, ds_queries = self._execute_progressive_search(
                    datasource=datasource,
                    primary_keywords=primary_keywords,
                    secondary_keywords=secondary_keywords,
                    filters=recommended_filters.get(datasource, {}),
                    search_intent=search_intent
                )
                search_results[datasource] = ds_results
                query_details[datasource] = ds_queries
        
        # çµæœçµ±è¨ˆè¨ˆç®—
        total_results = sum(
            len(results.get("combined_results", []))
            for results in search_results.values()
        )
        
        # å®Ÿè¡Œã‚µãƒãƒªãƒ¼ç”Ÿæˆï¼ˆæ®µéšçš„æ¤œç´¢å¯¾å¿œï¼‰
        execution_summary = self._generate_progressive_summary(
            search_results, datasource_priority[0]
        )
        
        result = {
            "search_results": search_results,
            "strategies_executed": strategies_to_execute,
            "query_details": query_details,
            "total_results": total_results,
            "execution_summary": execution_summary
        }
        
        logger.info(f"Step3å®Œäº†: {total_results}ä»¶ã®çµæœã‚’å–å¾—")
        return result
    
    def _determine_execution_strategies(self, search_strategy: str, step2_result: Dict[str, Any]) -> List[str]:
        """å®Ÿè¡Œæˆ¦ç•¥æ±ºå®šï¼ˆç²¾åº¦å„ªå…ˆãƒ»æ®µéšçš„å®Ÿè¡Œï¼‰"""
        
        # ç²¾åº¦å„ªå…ˆæˆ¦ç•¥: ã¾ãšã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã®ã¿å®Ÿè¡Œ
        # çµæœãŒä¸ååˆ†ãªå ´åˆã®ã¿ã€æ®µéšçš„ã«æ‹¡å¼µ
        return ["strategy1"]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã®ã¿ï¼ˆæœ€é«˜ç²¾åº¦ï¼‰
    
    def _execute_datasource_search(self, datasource: str, strategies: List[str], 
                                 primary_keywords: List[str], secondary_keywords: List[str],
                                 filters: Dict[str, Any], search_intent: str) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥æ¤œç´¢å®Ÿè¡Œ"""
        
        results = {"strategy_results": {}, "combined_results": []}
        queries = {}
        
        for strategy_id in strategies:
            strategy = self.strategies[strategy_id]
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æº–å‚™
            keywords = self._prepare_keywords_for_strategy(
                strategy_id, primary_keywords, secondary_keywords
            )
            
            # ã‚¯ã‚¨ãƒªç”Ÿæˆ
            query = self._build_query(datasource, keywords, filters, strategy)
            queries[strategy_id] = {
                "query": query,
                "keywords": keywords,
                "strategy": strategy["name"]
            }
            
            # å®Ÿéš›ã®æ¤œç´¢å®Ÿè¡Œï¼ˆAPIè¨­å®šã«ã‚ˆã‚Šè‡ªå‹•åˆ‡ã‚Šæ›¿ãˆï¼‰
            if self.use_real_api:
                # å®Ÿéš›ã®Atlassian APIæ¤œç´¢
                api_results = self._execute_api_search(datasource, query, strategy)
                results["strategy_results"][strategy_id] = api_results
                results["combined_results"].extend(api_results)
                logger.info(f"âœ… å®Ÿéš›ã®APIæ¤œç´¢å®Œäº† ({strategy['name']}): {len(api_results)}ä»¶")
            else:
                # æ¨¡æ“¬æ¤œç´¢ï¼ˆãƒ†ã‚¹ãƒˆç”¨/ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                mock_results = self._execute_mock_search(datasource, query, strategy)
                results["strategy_results"][strategy_id] = mock_results
                results["combined_results"].extend(mock_results)
                logger.info(f"ğŸ­ æ¨¡æ“¬æ¤œç´¢å®Œäº† ({strategy['name']}): {len(mock_results)}ä»¶")
        
        # é‡è¤‡é™¤å»
        results["combined_results"] = self._deduplicate_results(results["combined_results"])
        
        # é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆæ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹å¾Œå‡¦ç†ï¼‰
        logger.info(f"ğŸ” é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šç¢ºèª: enable_exclusion_filter={self.enable_exclusion_filter}")
        if self.enable_exclusion_filter:
            logger.info("ğŸ” é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™")
            before_count = len(results["combined_results"])
            results["combined_results"] = self._filter_excluded_results(results["combined_results"])
            after_count = len(results["combined_results"])
            logger.info(f"ğŸ” é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å®Ÿè¡Œçµæœ: {before_count}ä»¶ â†’ {after_count}ä»¶")
        else:
            logger.info("ğŸ” é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼ˆè¨­å®šç„¡åŠ¹ï¼‰")
        
        return results, queries
    
    def _execute_progressive_search(self, datasource: str, primary_keywords: List[str], 
                                   secondary_keywords: List[str], filters: Dict[str, Any], 
                                   search_intent: str) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """æ®µéšçš„æ¤œç´¢å®Ÿè¡Œï¼ˆç²¾åº¦å„ªå…ˆãƒ»æ—©æœŸçµ‚äº†ï¼‰"""
        
        results = {"strategy_results": {}, "combined_results": []}
        queries = {}
        
        # æœ€å°ååˆ†ä»¶æ•°ã®è¨­å®š
        min_sufficient_count = 3  # ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã§3ä»¶ä»¥ä¸Šã‚ã‚Œã°ååˆ†
        max_total_count = 10      # ç·ä»¶æ•°ä¸Šé™
        
        # Stage 1: ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ï¼ˆæœ€é«˜ç²¾åº¦ï¼‰
        logger.info("ğŸ¯ Stage 1: ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢å®Ÿè¡Œï¼ˆæœ€é«˜ç²¾åº¦ï¼‰")
        strategy1 = self.strategies["strategy1"]
        keywords1 = self._prepare_keywords_for_strategy("strategy1", primary_keywords, secondary_keywords)
        query1 = self._build_query(datasource, keywords1, filters, strategy1)
        
        queries["strategy1"] = {
            "query": query1,
            "keywords": keywords1,
            "strategy": strategy1["name"]
        }
        
        # ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢å®Ÿè¡Œ
        if self.use_real_api:
            api_results1 = self._execute_api_search(datasource, query1, strategy1)
            results["strategy_results"]["strategy1"] = api_results1
            results["combined_results"].extend(api_results1)
            logger.info(f"âœ… ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢å®Œäº† ({strategy1['name']}): {len(api_results1)}ä»¶")
        else:
            mock_results1 = self._execute_mock_search(datasource, query1, strategy1)
            results["strategy_results"]["strategy1"] = mock_results1
            results["combined_results"].extend(mock_results1)
            logger.info(f"ğŸ­ ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢å®Œäº† ({strategy1['name']}): {len(mock_results1)}ä»¶")
        
        # æ—©æœŸçµ‚äº†åˆ¤å®š
        title_results_count = len(results["combined_results"])
        if title_results_count >= min_sufficient_count:
            logger.info(f"âœ… é«˜ç²¾åº¦çµæœååˆ†å–å¾—ï¼ˆ{title_results_count}ä»¶ï¼‰â†’ è¿½åŠ æ¤œç´¢ã‚¹ã‚­ãƒƒãƒ—")
            
            # æ—©æœŸçµ‚äº†ã§ã‚‚é‡è¤‡é™¤å»ã¨é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
            results["combined_results"] = self._deduplicate_results(results["combined_results"])
            
            # é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆæ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹å¾Œå‡¦ç†ï¼‰
            logger.info(f"ğŸ” [æ—©æœŸçµ‚äº†]é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šç¢ºèª: enable_exclusion_filter={self.enable_exclusion_filter}")
            if self.enable_exclusion_filter:
                logger.info("ğŸ” [æ—©æœŸçµ‚äº†]é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™")
                before_count = len(results["combined_results"])
                results["combined_results"] = self._filter_excluded_results(results["combined_results"])
                after_count = len(results["combined_results"])
                logger.info(f"ğŸ” [æ—©æœŸçµ‚äº†]é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å®Ÿè¡Œçµæœ: {before_count}ä»¶ â†’ {after_count}ä»¶")
            else:
                logger.info("ğŸ” [æ—©æœŸçµ‚äº†]é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼ˆè¨­å®šç„¡åŠ¹ï¼‰")
                
            return results, queries
        
        # Stage 2: ã‚¿ã‚¤ãƒˆãƒ«è¿‘æ¥æ¤œç´¢ï¼ˆä¸­ç²¾åº¦ï¼‰ - ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ãŒä¸ååˆ†ãªå ´åˆã®ã¿
        logger.info(f"âš ï¸ ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢çµæœä¸è¶³ï¼ˆ{title_results_count}ä»¶ï¼‰â†’ ã‚¿ã‚¤ãƒˆãƒ«è¿‘æ¥æ¤œç´¢å®Ÿè¡Œ")
        strategy2 = self.strategies["strategy2"]
        keywords2 = self._prepare_keywords_for_strategy("strategy2", primary_keywords, secondary_keywords)
        query2 = self._build_query(datasource, keywords2, filters, strategy2)
        
        queries["strategy2"] = {
            "query": query2,
            "keywords": keywords2,
            "strategy": strategy2["name"]
        }
        
        # ã‚¿ã‚¤ãƒˆãƒ«è¿‘æ¥æ¤œç´¢å®Ÿè¡Œï¼ˆä»¶æ•°åˆ¶é™ä»˜ãï¼‰
        limited_strategy2 = {**strategy2, "max_results": min(strategy2["max_results"], max_total_count - title_results_count)}
        
        if self.use_real_api:
            api_results2 = self._execute_api_search(datasource, query2, limited_strategy2)
            results["strategy_results"]["strategy2"] = api_results2
            results["combined_results"].extend(api_results2)
            logger.info(f"âœ… ã‚¿ã‚¤ãƒˆãƒ«è¿‘æ¥æ¤œç´¢å®Œäº† ({strategy2['name']}): {len(api_results2)}ä»¶")
        else:
            mock_results2 = self._execute_mock_search(datasource, query2, limited_strategy2)
            results["strategy_results"]["strategy2"] = mock_results2
            results["combined_results"].extend(mock_results2)
            logger.info(f"ğŸ­ ã‚¿ã‚¤ãƒˆãƒ«è¿‘æ¥æ¤œç´¢å®Œäº† ({strategy2['name']}): {len(mock_results2)}ä»¶")
        
        # é‡è¤‡é™¤å»
        results["combined_results"] = self._deduplicate_results(results["combined_results"])
        
        # é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆæ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹å¾Œå‡¦ç†ï¼‰
        logger.info(f"ğŸ” [æ®µéšçš„æ¤œç´¢]é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šç¢ºèª: enable_exclusion_filter={self.enable_exclusion_filter}")
        if self.enable_exclusion_filter:
            logger.info("ğŸ” [æ®µéšçš„æ¤œç´¢]é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™")
            before_count = len(results["combined_results"])
            results["combined_results"] = self._filter_excluded_results(results["combined_results"])
            after_count = len(results["combined_results"])
            logger.info(f"ğŸ” [æ®µéšçš„æ¤œç´¢]é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å®Ÿè¡Œçµæœ: {before_count}ä»¶ â†’ {after_count}ä»¶")
        else:
            logger.info("ğŸ” [æ®µéšçš„æ¤œç´¢]é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼ˆè¨­å®šç„¡åŠ¹ï¼‰")
        
        final_count = len(results["combined_results"])
        logger.info(f"ğŸ¯ æ®µéšçš„æ¤œç´¢å®Œäº†: {final_count}ä»¶ï¼ˆã‚¿ã‚¤ãƒˆãƒ«{title_results_count}ä»¶ + è¿‘æ¥{final_count-title_results_count}ä»¶ï¼‰")
        
        return results, queries
    
    def _prepare_keywords_for_strategy(self, strategy_id: str, primary_keywords: List[str], 
                                     secondary_keywords: List[str]) -> List[str]:
        """æˆ¦ç•¥åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æº–å‚™ï¼ˆæ±ç”¨èªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ãï¼‰"""
        
        if strategy_id == "strategy1":  # ã‚¿ã‚¤ãƒˆãƒ«å³å¯†æ¤œç´¢
            # ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã§ã¯æ±ç”¨èªã‚‚å«ã‚ã‚‹ï¼ˆå®Œå…¨ä¸€è‡´å‰æï¼‰
            return primary_keywords[:3]
        elif strategy_id == "strategy2":  # ã‚¿ã‚¤ãƒˆãƒ«è¿‘æ¥æ¤œç´¢
            # NEARæ¤œç´¢ã§ã¯æ±ç”¨èªã‚’å«ã‚ã¦ã‚‚å•é¡Œãªã„
            return primary_keywords + secondary_keywords[:2]
        elif strategy_id == "strategy3":  # æœ¬æ–‡å³å¯†æ¤œç´¢
            # ANDæ¤œç´¢ã§ã¯æ±ç”¨èªã‚’å«ã‚ã¦ã‚‚å•é¡Œãªã„
            return primary_keywords + secondary_keywords[:2]
        elif strategy_id == "strategy4":  # è£œå®ŒORæ¤œç´¢
            # ORæ¤œç´¢ã§ã¯æ±ç”¨èªã‚’é™¤å¤–ï¼ˆé‡è¦ï¼ï¼‰
            filtered_keywords = []
            
            # ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰æ±ç”¨èªã‚’é™¤å¤–
            for keyword in primary_keywords:
                if keyword not in self.stop_words:
                    filtered_keywords.append(keyword)
            
            # å‰¯æ¬¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã‚‚æ±ç”¨èªã‚’é™¤å¤–
            for keyword in secondary_keywords[:2]:
                if keyword not in self.stop_words:
                    filtered_keywords.append(keyword)
            
            # é¡ç¾©èªå±•é–‹ï¼ˆæ±ç”¨èªé™¤å¤–æ¸ˆã¿ï¼‰
            expanded = filtered_keywords.copy()
            for keyword in filtered_keywords:
                synonyms = self.synonym_dict.get(keyword, [])
                for synonym in synonyms[:1]:  # é¡ç¾©èª1ã¤ã¾ã§ï¼ˆç²¾åº¦é‡è¦–ï¼‰
                    if synonym not in self.stop_words:
                        expanded.append(synonym)
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå°‘ãªã™ãã‚‹å ´åˆã®å¯¾ç­–
            unique_keywords = list(set(expanded))
            if len(unique_keywords) < 2:
                # å®‰å…¨ãªä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿ä½¿ç”¨
                return [kw for kw in primary_keywords if kw not in self.stop_words][:2]
            
            return unique_keywords[:4]  # æœ€å¤§4ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åˆ¶é™
        else:
            return primary_keywords
    
    def _build_query(self, datasource: str, keywords: List[str], filters: Dict[str, Any], strategy: Dict[str, Any]) -> str:
        """ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—æ§‹ç¯‰"""
        
        # ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã®å ´åˆã¯å°‚ç”¨ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
        if strategy["match_type"] == "title":
            return self._build_title_query(datasource, keywords, filters)
        
        # ã‚¿ã‚¤ãƒˆãƒ«è¤‡åˆèªæ¤œç´¢ã®å ´åˆã‚‚å°‚ç”¨ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
        if strategy["match_type"] == "title_complex":
            return self._build_title_complex_query(datasource, keywords, filters)
        
        # é€šå¸¸ã®textæ¤œç´¢
        operator = strategy["operator"]
        if strategy["match_type"] == "exact":
            keyword_clause = f" {operator} ".join(f'"{kw}"' for kw in keywords)
        else:
            keyword_clause = f" {operator} ".join(f'"{kw}"' for kw in keywords)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥ã‚¯ã‚¨ãƒªæ§‹ç¯‰
        if datasource == "jira":
            return self._build_jql_query(keyword_clause, filters)
        else:
            return self._build_cql_query(keyword_clause, filters)
    
    def _build_title_query(self, datasource: str, keywords: List[str], filters: Dict[str, Any]) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«å°‚ç”¨æ¤œç´¢ã‚¯ã‚¨ãƒªæ§‹ç¯‰ï¼ˆANDæ¤œç´¢ã¨NEARæ¤œç´¢å¯¾å¿œï¼‰"""
        
        if datasource == "jira":
            # JQL: summaryï¼ˆã‚¿ã‚¤ãƒˆãƒ«ï¼‰æ¤œç´¢
            title_conditions = []
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ã«å¿œã˜ã¦æˆ¦ç•¥æ±ºå®š
            if len(keywords) >= 2:
                # è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ â†’ ANDæ¤œç´¢
                for keyword in keywords:
                    title_conditions.append(f'summary ~ "{keyword}"')
                base_query = f"({' AND '.join(title_conditions)})"
            else:
                # å˜ä¸€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ â†’ å˜ç´”æ¤œç´¢
                base_query = f'summary ~ "{keywords[0]}"'
            
            conditions = [base_query]
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
            if "project" in filters:
                conditions.append(f"project = \"{filters['project']}\"")
            
            if "status" in filters and filters["status"]:
                status_list = ", ".join(f'"{s}"' for s in filters["status"])
                conditions.append(f"status IN ({status_list})")
            
            if "issuetype" in filters and filters["issuetype"]:
                type_list = ", ".join(f'"{t}"' for t in filters["issuetype"])
                conditions.append(f"issuetype IN ({type_list})")
            
            # å‰Šé™¤ãƒ»å»ƒæ­¢ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ ï¼ˆJQLç”¨ï¼‰
            exclusion_conditions = self._build_jql_exclusion_conditions()
            conditions.extend(exclusion_conditions)
            
            return " AND ".join(conditions)
            
        else:  # Confluence
            # CQL: titleæ¤œç´¢ï¼ˆANDæ¤œç´¢ã¨NEARæ¤œç´¢å¯¾å¿œï¼‰
            title_conditions = []
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ã¨æˆ¦ç•¥ã«å¿œã˜ã¦ã‚¯ã‚¨ãƒªæ§‹ç¯‰
            if len(keywords) >= 2:
                # è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ â†’ ANDæ¤œç´¢ã‚’åŸºæœ¬ã¨ã™ã‚‹
                for keyword in keywords:
                    title_conditions.append(f'title ~ "{keyword}"')
                
                # ANDæ¤œç´¢
                base_query = f"({' AND '.join(title_conditions)})"
                
                # è¿‘æ¥æ¤œç´¢ã‚‚ä½µç”¨ï¼ˆè¤‡åˆèªæ¤œç´¢ï¼‰
                # "ä¼šå“¡.*ãƒ­ã‚°ã‚¤ãƒ³|ãƒ­ã‚°ã‚¤ãƒ³.*ä¼šå“¡" ã®ã‚ˆã†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚è¿½åŠ 
                if len(keywords) == 2:
                    kw1, kw2 = keywords[0], keywords[1]
                    near_patterns = [
                        f'title ~ "{kw1}.*{kw2}"',  # kw1ã®å¾Œã«kw2
                        f'title ~ "{kw2}.*{kw1}"',  # kw2ã®å¾Œã«kw1
                    ]
                    
                    # è¤‡åˆèªæ¤œç´¢ã‚’ORæ¡ä»¶ã¨ã—ã¦è¿½åŠ 
                    near_query = f"({' OR '.join(near_patterns)})"
                    base_query = f"({base_query} OR {near_query})"
                
            else:
                # å˜ä¸€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ â†’ å˜ç´”æ¤œç´¢
                base_query = f'title ~ "{keywords[0]}"'
            
            conditions = [base_query]
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
            if "space_keys" in filters and filters["space_keys"]:
                space_list = ", ".join(f'"{s}"' for s in filters["space_keys"])
                conditions.append(f"space IN ({space_list})")
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ãƒšãƒ¼ã‚¹è¨­å®šï¼ˆCLIENTTOMOï¼‰
                conditions.append(f'space = "{self.settings.confluence_space}"')
            
            if "content_type" in filters:
                conditions.append(f"type = \"{filters['content_type']}\"")
            
            # å‰Šé™¤ãƒ»å»ƒæ­¢ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
            exclusion_conditions = self._build_title_exclusion_conditions()
            conditions.extend(exclusion_conditions)
            
            return " AND ".join(conditions)

    def _build_title_complex_query(self, datasource: str, keywords: List[str], filters: Dict[str, Any]) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«è¤‡åˆèªæ¤œç´¢ã‚¯ã‚¨ãƒªæ§‹ç¯‰ï¼ˆè¿‘æ¥ãƒ»è¤‡åˆèªå°‚ç”¨ï¼‰"""
        
        if datasource == "jira":
            # JQL: summaryè¤‡åˆèªæ¤œç´¢
            if len(keywords) >= 2:
                # è¤‡åˆèªãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ
                complex_patterns = []
                for i in range(len(keywords)):
                    for j in range(len(keywords)):
                        if i != j:
                            complex_patterns.append(f'summary ~ "{keywords[i]}.*{keywords[j]}"')
                
                base_query = f"({' OR '.join(complex_patterns)})"
            else:
                # å˜ä¸€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å ´åˆã¯é€šå¸¸æ¤œç´¢
                base_query = f'summary ~ "{keywords[0]}"'
            
            conditions = [base_query]
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
            if "project" in filters:
                conditions.append(f"project = \"{filters['project']}\"")
            
            # å‰Šé™¤ãƒ»å»ƒæ­¢ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ ï¼ˆJQLç”¨ï¼‰
            exclusion_conditions = self._build_jql_exclusion_conditions()
            conditions.extend(exclusion_conditions)
            
            return " AND ".join(conditions)
            
        else:  # Confluence
            # CQL: titleè¤‡åˆèªæ¤œç´¢
            if len(keywords) >= 2:
                # è¤‡åˆèªãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆï¼ˆã‚ˆã‚ŠæŸ”è»Ÿãªæ¤œç´¢ï¼‰
                complex_patterns = []
                
                # å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒšã‚¢ã§è¤‡åˆèªæ¤œç´¢
                for i in range(len(keywords)):
                    for j in range(len(keywords)):
                        if i != j:
                            # å‰å¾Œé †åºã®è¤‡åˆèª
                            complex_patterns.append(f'title ~ "{keywords[i]}.*{keywords[j]}"')
                            # ã‚ˆã‚Šåºƒç¯„å›²ãªè¤‡åˆèªï¼ˆå˜èªé–“ã«ä»–ã®èªãŒå…¥ã‚‹ã“ã¨ã‚’è¨±å¯ï¼‰
                            complex_patterns.append(f'title ~ "{keywords[i]}.*\\b.*{keywords[j]}"')
                
                # å®Œå…¨ä¸€è‡´ã®è¤‡åˆèªã‚‚è¿½åŠ 
                combined_keywords = "".join(keywords)
                complex_patterns.append(f'title ~ "{combined_keywords}"')
                
                base_query = f"({' OR '.join(complex_patterns)})"
            else:
                # å˜ä¸€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å ´åˆã¯é€šå¸¸æ¤œç´¢
                base_query = f'title ~ "{keywords[0]}"'
            
            conditions = [base_query]
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
            if "space_keys" in filters and filters["space_keys"]:
                space_list = ", ".join(f'"{s}"' for s in filters["space_keys"])
                conditions.append(f"space IN ({space_list})")
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ãƒšãƒ¼ã‚¹è¨­å®šï¼ˆCLIENTTOMOï¼‰
                conditions.append(f'space = "{self.settings.confluence_space}"')
            
            if "content_type" in filters:
                conditions.append(f"type = \"{filters['content_type']}\"")
            
            # å‰Šé™¤ãƒ»å»ƒæ­¢ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
            exclusion_conditions = self._build_title_exclusion_conditions()
            conditions.extend(exclusion_conditions)
            
            return " AND ".join(conditions)
    
    def _build_jql_query(self, keyword_clause: str, filters: Dict[str, Any]) -> str:
        """JQLã‚¯ã‚¨ãƒªæ§‹ç¯‰"""
        
        # JQLã§ã¯æ­£ã—ã„æ§‹æ–‡ã‚’ä½¿ç”¨: (text ~ "keyword1" OR text ~ "keyword2") ã¾ãŸã¯ (text ~ "keyword1" AND text ~ "keyword2")
        # keyword_clauseã¯æ—¢ã«AND/ORã§çµåˆã•ã‚ŒãŸå½¢å¼ãªã®ã§ã€é©åˆ‡ã«JQLå½¢å¼ã«å¤‰æ›
        
        # keyword_clauseã‚’è§£æã—ã¦JQLå½¢å¼ã«å¤‰æ›
        if " AND " in keyword_clause:
            # ANDçµåˆã®å ´åˆ
            keywords = [kw.strip().strip('"') for kw in keyword_clause.split(" AND ")]
            base_query = " AND ".join(f'text ~ "{kw}"' for kw in keywords if kw)
        elif " OR " in keyword_clause:
            # ORçµåˆã®å ´åˆ
            keywords = [kw.strip().strip('"') for kw in keyword_clause.split(" OR ")]
            base_query = " OR ".join(f'text ~ "{kw}"' for kw in keywords if kw)
        else:
            # å˜ä¸€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å ´åˆ
            keyword = keyword_clause.strip().strip('"')
            base_query = f'text ~ "{keyword}"'
        
        # è¤‡æ•°æ¡ä»¶ã®å ´åˆã¯æ‹¬å¼§ã§å›²ã‚€
        if " AND " in base_query or " OR " in base_query:
            base_query = f"({base_query})"
        
        conditions = [base_query]
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
        if "project" in filters:
            conditions.append(f"project = \"{filters['project']}\"")
        
        if "status" in filters and filters["status"]:
            status_list = ", ".join(f'"{s}"' for s in filters["status"])
            conditions.append(f"status IN ({status_list})")
        
        if "issuetype" in filters and filters["issuetype"]:
            type_list = ", ".join(f'"{t}"' for t in filters["issuetype"])
            conditions.append(f"issuetype IN ({type_list})")
        
        # å‰Šé™¤ãƒ»å»ƒæ­¢ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ ï¼ˆJQLç”¨ï¼‰
        exclusion_conditions = self._build_jql_exclusion_conditions()
        conditions.extend(exclusion_conditions)
        
        return " AND ".join(conditions)
    
    def _build_cql_query(self, keyword_clause: str, filters: Dict[str, Any]) -> str:
        """CQLã‚¯ã‚¨ãƒªæ§‹ç¯‰"""
        
        # CQLã§ã¯æ­£ã—ã„æ§‹æ–‡ã‚’ä½¿ç”¨: (text ~ "keyword1" OR text ~ "keyword2") ã¾ãŸã¯ (text ~ "keyword1" AND text ~ "keyword2")
        # keyword_clauseã¯æ—¢ã«AND/ORã§çµåˆã•ã‚ŒãŸå½¢å¼ãªã®ã§ã€é©åˆ‡ã«CQLå½¢å¼ã«å¤‰æ›
        
        # keyword_clauseã‚’è§£æã—ã¦CQLå½¢å¼ã«å¤‰æ›
        if " AND " in keyword_clause:
            # ANDçµåˆã®å ´åˆ
            keywords = [kw.strip().strip('"') for kw in keyword_clause.split(" AND ")]
            base_query = " AND ".join(f'text ~ "{kw}"' for kw in keywords if kw)
        elif " OR " in keyword_clause:
            # ORçµåˆã®å ´åˆ
            keywords = [kw.strip().strip('"') for kw in keyword_clause.split(" OR ")]
            base_query = " OR ".join(f'text ~ "{kw}"' for kw in keywords if kw)
        else:
            # å˜ä¸€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å ´åˆ
            keyword = keyword_clause.strip().strip('"')
            base_query = f'text ~ "{keyword}"'
        
        # è¤‡æ•°æ¡ä»¶ã®å ´åˆã¯æ‹¬å¼§ã§å›²ã‚€
        if " AND " in base_query or " OR " in base_query:
            base_query = f"({base_query})"
        
        conditions = [base_query]
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
        if "space_keys" in filters and filters["space_keys"]:
            space_list = ", ".join(f'"{s}"' for s in filters["space_keys"])
            conditions.append(f"space IN ({space_list})")
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ãƒšãƒ¼ã‚¹è¨­å®šï¼ˆCLIENTTOMOï¼‰
            conditions.append(f'space = "{self.settings.confluence_space}"')
        
        if "content_type" in filters:
            conditions.append(f"type = \"{filters['content_type']}\"")
        
        # å‰Šé™¤ãƒ»å»ƒæ­¢ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
        exclusion_conditions = self._build_title_exclusion_conditions()
        conditions.extend(exclusion_conditions)
        
        return " AND ".join(conditions)
    
    def _execute_api_search(self, datasource: str, query: str, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        å®Ÿéš›ã®APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢å®Ÿè¡Œï¼ˆæœ¬ç•ªå®Ÿè£…ï¼‰
        
        Args:
            datasource: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ ('confluence' or 'jira')
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            strategy: æ¤œç´¢æˆ¦ç•¥
            
        Returns:
            List[Dict[str, Any]]: æ¤œç´¢çµæœ
        """
        try:
            if datasource == "confluence":
                return self._execute_confluence_search(query, strategy)
            elif datasource == "jira":
                return self._execute_jira_search(query, strategy)
            else:
                logger.warning(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {datasource}")
                return []
                
        except Exception as e:
            logger.error(f"{datasource.title()}APIæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            # APIå¤±æ•—æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
            logger.info(f"{datasource.title()}æ¤œç´¢ã‚’ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            return self._execute_mock_search(datasource, query, strategy)
    
    def _execute_confluence_search(self, query: str, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Confluence APIæ¤œç´¢å®Ÿè¡Œ
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            strategy: æ¤œç´¢æˆ¦ç•¥
            
        Returns:
            List[Dict[str, Any]]: Confluenceæ¤œç´¢çµæœ
        """
        from atlassian import Confluence
        
        # Confluenceæ¥ç¶šã®åˆæœŸåŒ–
        confluence = Confluence(
            url=f"https://{self.settings.atlassian_domain}",
            username=self.settings.atlassian_email,
            password=self.settings.atlassian_api_token
        )
        
        # CQLã‚¯ã‚¨ãƒªã®æ§‹ç¯‰ï¼ˆæˆ¦ç•¥ã«å¿œã˜ãŸæ¤œç´¢ï¼‰
        # queryã¯æ—¢ã«æ§‹ç¯‰æ¸ˆã¿ã®ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—ãªã®ã§ã€ã‚¹ãƒšãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ã¿è¿½åŠ 
        if self.settings.confluence_space:
            cql_query = f'{query} and space = "{self.settings.confluence_space}"'
        else:
            cql_query = query
        
        logger.info(f"Confluence CQLå®Ÿè¡Œ: {cql_query}")
        
        # æ¤œç´¢å®Ÿè¡Œ
        search_result = confluence.cql(cql_query, limit=strategy.get("max_results", 10))
        
        if not search_result or 'results' not in search_result:
            logger.warning(f"Confluenceæ¤œç´¢çµæœãªã—: ã‚¯ã‚¨ãƒª='{query}'")
            return []
        
        results = search_result['results']
        logger.info(f"Confluenceæ¤œç´¢çµæœ: {len(results)}ä»¶")
        
        # çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, dict):
                formatted_result = {
                    "id": result.get("content", {}).get("id", f"confluence_{i}"),
                    "title": result.get("title", "ç„¡é¡Œ"),
                    "space": result.get("space", {}).get("key", ""),
                    "type": "page",
                    "url": result.get("url", ""),
                    "excerpt": result.get("excerpt", "")[:200],
                    "created": result.get("content", {}).get("history", {}).get("createdDate", ""),
                    "strategy": strategy["name"],
                    "weight": strategy["weight"],
                    "datasource": "confluence"
                }
                formatted_results.append(formatted_result)
        
        return formatted_results
    
    def _execute_jira_search(self, query: str, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Jira APIæ¤œç´¢å®Ÿè¡Œ
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            strategy: æ¤œç´¢æˆ¦ç•¥
            
        Returns:
            List[Dict[str, Any]]: Jiraæ¤œç´¢çµæœ
        """
        from atlassian import Jira
        
        # Jiraæ¥ç¶šã®åˆæœŸåŒ–
        jira = Jira(
            url=f"https://{self.settings.atlassian_domain}",
            username=self.settings.atlassian_email,
            password=self.settings.atlassian_api_token
        )
        
        # JQLã‚¯ã‚¨ãƒªã®æ§‹ç¯‰ï¼ˆæˆ¦ç•¥ã«å¿œã˜ãŸæ¤œç´¢ï¼‰
        # queryã¯æ—¢ã«æ§‹ç¯‰æ¸ˆã¿ã®ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—ãªã®ã§ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ã¿è¿½åŠ 
        jql_query = f'{query} AND project = "CTJ"'
        
        logger.info(f"Jira JQLå®Ÿè¡Œ: {jql_query}")
        
        # æ¤œç´¢å®Ÿè¡Œ
        search_result = jira.jql(jql_query, limit=strategy.get("max_results", 10))
        
        if not search_result or 'issues' not in search_result:
            logger.warning(f"Jiraæ¤œç´¢çµæœãªã—: ã‚¯ã‚¨ãƒª='{query}'")
            return []
        
        issues = search_result['issues']
        logger.info(f"Jiraæ¤œç´¢çµæœ: {len(issues)}ä»¶")
        
        # çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted_results = []
        for issue in issues:
            if isinstance(issue, dict):
                fields = issue.get("fields", {})
                formatted_result = {
                    "id": issue.get("key", ""),
                    "title": fields.get("summary", "ç„¡é¡Œ"),
                    "type": fields.get("issuetype", {}).get("name", ""),
                    "status": fields.get("status", {}).get("name", ""),
                    "priority": fields.get("priority", {}).get("name", ""),
                    "assignee": fields.get("assignee", {}).get("displayName", "æœªå‰²ã‚Šå½“ã¦") if fields.get("assignee") else "æœªå‰²ã‚Šå½“ã¦",
                    "reporter": fields.get("reporter", {}).get("displayName", ""),
                    "description": (fields.get("description", "") or "")[:200],
                    "created": fields.get("created", ""),
                    "updated": fields.get("updated", ""),
                    "strategy": strategy["name"],
                    "weight": strategy["weight"],
                    "datasource": "jira"
                }
                formatted_results.append(formatted_result)
        
        return formatted_results
    
    def _execute_mock_search(self, datasource: str, query: str, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ¨¡æ“¬æ¤œç´¢å®Ÿè¡Œï¼ˆç¾å®Ÿçš„ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰"""
        
        # æ¤œç´¢ã‚¯ã‚¨ãƒªã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        query_lower = query.lower()
        is_login_related = any(keyword in query_lower for keyword in ["ãƒ­ã‚°ã‚¤ãƒ³", "login", "èªè¨¼", "auth"])
        
        # æˆ¦ç•¥åˆ¥çµæœæ•°èª¿æ•´
        mock_count = min(strategy["max_results"] // 10, 5) if strategy["name"] == "å³å¯†æ¤œç´¢" else min(strategy["max_results"] // 10, 3)
        
        mock_results = []
        
        if is_login_related:
            # ãƒ­ã‚°ã‚¤ãƒ³é–¢é€£ã‚¯ã‚¨ãƒªç”¨ã®å‹•çš„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            query_keywords = self._extract_mock_keywords_from_query(query)
            login_context = self._determine_login_context(query_keywords, query_lower)
            
            if datasource == "jira":
                # ãƒ­ã‚°ã‚¤ãƒ³é–¢é€£ã®å‹•çš„Jiraã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
                jira_templates = self._generate_login_jira_templates(login_context, query_keywords)
                for i in range(mock_count):
                    template_idx = i % len(jira_templates)
                    mock_results.append({
                        "id": f"AUTH-{100 + i}",
                        "title": f"{jira_templates[template_idx]} ({strategy['name']})",
                        "type": "Story" if i % 2 == 0 else "Bug",
                        "status": ["Open", "In Progress", "Done"][i % 3],
                        "assignee": "dev.team@company.com",
                        "created": "2024-01-15",
                        "strategy": strategy["name"],
                        "weight": strategy["weight"],
                        "datasource": "jira"
                    })
            else:  # confluence
                # ãƒ­ã‚°ã‚¤ãƒ³é–¢é€£ã®å‹•çš„Confluenceã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
                confluence_templates = self._generate_login_confluence_templates(login_context, query_keywords)
                for i in range(mock_count):
                    template_idx = i % len(confluence_templates)
                    mock_results.append({
                        "id": f"page_auth_{100 + i}",
                        "title": f"{confluence_templates[template_idx]} ({strategy['name']})",
                        "space": ["SYSTEM", "API", "SECURITY"][i % 3],
                        "type": "page",
                        "created": "2024-01-10",
                        "strategy": strategy["name"],
                        "weight": strategy["weight"],
                        "datasource": "confluence"
                    })
        else:
            # ãã®ä»–ã®ã‚¯ã‚¨ãƒªç”¨ã®é–¢é€£æ€§ã®ã‚ã‚‹ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            query_keywords = self._extract_mock_keywords_from_query(query)
            base_keyword = self._determine_base_keyword_from_query(query_keywords, query)
            
            # ã€Œæ©Ÿèƒ½ã€é‡è¤‡ã‚’å›é¿ã™ã‚‹ãŸã‚ã€æœ«å°¾ã®ã€Œæ©Ÿèƒ½ã€ã‚’é™¤å»
            base_keyword_clean = base_keyword.replace("æ©Ÿèƒ½", "") if base_keyword.endswith("æ©Ÿèƒ½") else base_keyword
            
            if datasource == "jira":
                jira_templates = [
                    f"{base_keyword}ã®å®Ÿè£…",
                    f"{base_keyword}ã«é–¢ã™ã‚‹ãƒã‚°ä¿®æ­£", 
                    f"{base_keyword}ã®æ”¹å–„è¦æ±‚",
                    f"{base_keyword_clean}æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ",
                    f"{base_keyword}ã®ä»•æ§˜å¤‰æ›´"
                ]
                for i in range(mock_count):
                    template_idx = i % len(jira_templates)
                    mock_results.append({
                        "id": f"PROJ-{200 + i}",
                        "title": f"{jira_templates[template_idx]} ({strategy['name']})",
                        "type": "Story",
                        "status": "Open",
                        "assignee": "team.member@company.com",
                        "created": "2024-01-01",
                        "strategy": strategy["name"],
                        "weight": strategy["weight"],
                        "datasource": "jira"
                    })
            else:  # confluence
                confluence_templates = [
                    f"{base_keyword_clean}æ©Ÿèƒ½ä»•æ§˜æ›¸",
                    f"{base_keyword}è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
                    f"{base_keyword}ã«é–¢ã™ã‚‹è¦ä»¶å®šç¾©",
                    f"{base_keyword_clean}æ©Ÿèƒ½ã®ä½¿ç”¨æ‰‹é †",
                    f"{base_keyword}ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦"
                ]
                for i in range(mock_count):
                    template_idx = i % len(confluence_templates)
                    mock_results.append({
                        "id": f"page_{300 + i}",
                        "title": f"{confluence_templates[template_idx]} ({strategy['name']})",
                        "space": "TECH",
                        "type": "page",
                        "created": "2024-01-01",
                        "strategy": strategy["name"],
                        "weight": strategy["weight"],
                        "datasource": "confluence"
                    })
        
        return mock_results
    
    def _extract_mock_keywords_from_query(self, query: str) -> List[str]:
        """æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆç”¨ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
        import re
        
        # ã‚¯ã‚¨ãƒªã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        query_clean = query.replace('"', '').replace("'", "").replace("(", "").replace(")", "")
        
        # é™¤å¤–ã™ã‚‹æ±ç”¨èªï¼ˆè¨­å®šã‹ã‚‰å‹•çš„ã«å–å¾—ï¼‰
        config_exclusions = getattr(self.settings, 'mock_exclude_terms', [])
        exclude_terms = ["AND", "OR", "space", "title", "text", "=", "~"] + config_exclusions
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å€™è£œã‚’æŠ½å‡º
        candidates = []
        
        # æ—¥æœ¬èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ï¼‰
        japanese_words = re.findall(r'[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾¯]+', query_clean)
        candidates.extend(japanese_words)
        
        # è‹±èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ3æ–‡å­—ä»¥ä¸Šï¼‰
        english_words = re.findall(r'[a-zA-Z]{3,}', query_clean)
        candidates.extend(english_words)
        
        # é™¤å¤–èªã‚’é™¤å»
        filtered_keywords = []
        for word in candidates:
            if word not in exclude_terms and len(word) >= 2:
                filtered_keywords.append(word)
        
        # é‡è¤‡é™¤å»ãƒ»å„ªå…ˆé †ä½ä»˜ã‘
        unique_keywords = []
        for keyword in filtered_keywords:
            if keyword not in unique_keywords:
                unique_keywords.append(keyword)
        
        # æœ€å¤§3å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿”ã™
        return unique_keywords[:3] if unique_keywords else ["æ©Ÿèƒ½"]
    
    def _determine_login_context(self, keywords: List[str], query_lower: str) -> str:
        """ãƒ­ã‚°ã‚¤ãƒ³é–¢é€£ã‚¯ã‚¨ãƒªã®æ–‡è„ˆåˆ¤å®š"""
        
        # æ–‡è„ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¤å®š
        if any(word in query_lower for word in ["ç”»é¢", "ui", "ãƒ•ãƒ­ãƒ³ãƒˆ"]):
            return "ui"
        elif any(word in query_lower for word in ["api", "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰", "ã‚µãƒ¼ãƒãƒ¼"]):
            return "api"
        elif any(word in query_lower for word in ["ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "èªè¨¼", "æš—å·åŒ–"]):
            return "security"
        elif any(word in query_lower for word in ["ä»•æ§˜", "è¨­è¨ˆ", "è©³ç´°"]):
            return "spec"
        elif any(word in query_lower for word in ["ãƒã‚°", "ä¸å…·åˆ", "ã‚¨ãƒ©ãƒ¼"]):
            return "bug"
        elif any(word in query_lower for word in ["ãƒ†ã‚¹ãƒˆ", "æ¤œè¨¼"]):
            return "test"
        else:
            return "general"
    
    def _generate_login_jira_templates(self, context: str, keywords: List[str]) -> List[str]:
        """ãƒ­ã‚°ã‚¤ãƒ³é–¢é€£ã®å‹•çš„Jiraã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ"""
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å‹•çš„ç”Ÿæˆ
        main_keyword = keywords[0] if keywords else "ãƒ­ã‚°ã‚¤ãƒ³"
        
        if context == "ui":
            return [
                f"{main_keyword}ç”»é¢ã®è¡¨ç¤ºæ”¹å–„",
                f"{main_keyword}UIã®ä¸å…·åˆä¿®æ­£",
                f"{main_keyword}ãƒ•ã‚©ãƒ¼ãƒ ã®æ“ä½œæ€§å‘ä¸Š",
                f"{main_keyword}ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–å¯¾å¿œ"
            ]
        elif context == "api":
            return [
                f"{main_keyword}APIã®å®Ÿè£…",
                f"{main_keyword}ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­è¨ˆ",
                f"{main_keyword}ãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†æ©Ÿèƒ½",
                f"{main_keyword}APIä»•æ§˜å¤‰æ›´"
            ]
        elif context == "security":
            return [
                f"{main_keyword}ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–",
                f"{main_keyword}äºŒæ®µéšèªè¨¼å¯¾å¿œ",
                f"{main_keyword}æš—å·åŒ–æ–¹å¼å¤‰æ›´",
                f"{main_keyword}è„†å¼±æ€§å¯¾å¿œ"
            ]
        elif context == "bug":
            return [
                f"{main_keyword}ã‚¨ãƒ©ãƒ¼ä¿®æ­£",
                f"{main_keyword}å¤±æ•—æ™‚ã®ä¸å…·åˆ",
                f"{main_keyword}ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå•é¡Œ",
                f"{main_keyword}ä¾‹å¤–å‡¦ç†æ”¹å–„"
            ]
        elif context == "test":
            return [
                f"{main_keyword}æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ",
                f"{main_keyword}ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹è¿½åŠ ",
                f"{main_keyword}è‡ªå‹•ãƒ†ã‚¹ãƒˆå°å…¥",
                f"{main_keyword}æ€§èƒ½ãƒ†ã‚¹ãƒˆ"
            ]
        else:  # general
            return [
                f"{main_keyword}æ©Ÿèƒ½ã®å®Ÿè£…",
                f"{main_keyword}ã«é–¢ã™ã‚‹èª²é¡Œ",
                f"{main_keyword}æ©Ÿèƒ½æ”¹å–„",
                f"{main_keyword}è¦ä»¶å¤‰æ›´"
            ]
    
    def _generate_login_confluence_templates(self, context: str, keywords: List[str]) -> List[str]:
        """ãƒ­ã‚°ã‚¤ãƒ³é–¢é€£ã®å‹•çš„Confluenceã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ"""
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å‹•çš„ç”Ÿæˆ
        main_keyword = keywords[0] if keywords else "ãƒ­ã‚°ã‚¤ãƒ³"
        
        if context == "ui":
            return [
                f"{main_keyword}ç”»é¢è¨­è¨ˆæ›¸",
                f"{main_keyword}UIä»•æ§˜æ›¸", 
                f"{main_keyword}ç”»é¢é·ç§»å›³",
                f"{main_keyword}ãƒ¯ã‚¤ãƒ¤ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ "
            ]
        elif context == "api":
            return [
                f"{main_keyword}APIä»•æ§˜æ›¸",
                f"{main_keyword}ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­è¨ˆ",
                f"{main_keyword}ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®šç¾©",
                f"{main_keyword}APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"
            ]
        elif context == "security":
            return [
                f"{main_keyword}ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼",
                f"{main_keyword}èªè¨¼è¨­è¨ˆæ›¸",
                f"{main_keyword}æš—å·åŒ–ä»•æ§˜",
                f"{main_keyword}ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³"
            ]
        elif context == "spec":
            return [
                f"{main_keyword}æ©Ÿèƒ½ä»•æ§˜æ›¸",
                f"{main_keyword}è©³ç´°è¨­è¨ˆæ›¸",
                f"{main_keyword}è¦ä»¶å®šç¾©æ›¸",
                f"{main_keyword}æ©Ÿèƒ½æ¦‚è¦"
            ]
        elif context == "test":
            return [
                f"{main_keyword}ãƒ†ã‚¹ãƒˆä»•æ§˜æ›¸",
                f"{main_keyword}ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹",
                f"{main_keyword}æ¤œè¨¼æ‰‹é †æ›¸",
                f"{main_keyword}ãƒ†ã‚¹ãƒˆè¨ˆç”»"
            ]
        else:  # general
            return [
                f"{main_keyword}æ©Ÿèƒ½è¨­è¨ˆæ›¸",
                f"{main_keyword}ã«é–¢ã™ã‚‹ä»•æ§˜",
                f"{main_keyword}ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦",
                f"{main_keyword}æ©Ÿèƒ½èª¬æ˜"
            ]
    
    def _determine_base_keyword_from_query(self, keywords: List[str], original_query: str) -> str:
        """ã‚¯ã‚¨ãƒªã‹ã‚‰é©åˆ‡ãªãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å‹•çš„ã«æ±ºå®š"""
        
        # å„ªå…ˆé †ä½ä»˜ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¸æŠ
        if keywords:
            # æœ€ã‚‚å…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é¸æŠ
            primary_keyword = keywords[0]
            
            # æ±ç”¨èªã®å ´åˆã¯ã€ã‚ˆã‚Šå…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„ã‹ç¢ºèª
            if primary_keyword in self.stop_words and len(keywords) > 1:
                for kw in keywords[1:]:
                    if kw not in self.stop_words:
                        return kw
            
            return primary_keyword
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŠ½å‡ºã§ããªã„å ´åˆã€ã‚¯ã‚¨ãƒªã‹ã‚‰æ–‡è„ˆæ¨æ¸¬
        query_lower = original_query.lower()
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if any(word in query_lower for word in ["ãƒ¦ãƒ¼ã‚¶ãƒ¼", "user", "åˆ©ç”¨è€…"]):
            return "ãƒ¦ãƒ¼ã‚¶ãƒ¼"
        elif any(word in query_lower for word in ["ãƒ‡ãƒ¼ã‚¿", "db", "database"]):
            return "ãƒ‡ãƒ¼ã‚¿"
        elif any(word in query_lower for word in ["api", "interface", "é€šä¿¡"]):
            return "API"
        elif any(word in query_lower for word in ["ç”»é¢", "ui", "è¡¨ç¤º"]):
            return "ç”»é¢"
        elif any(word in query_lower for word in ["å‡¦ç†", "process", "å®Ÿè¡Œ"]):
            return "å‡¦ç†"
        elif any(word in query_lower for word in ["è¨­å®š", "config", "ç’°å¢ƒ"]):
            return "è¨­å®š"
        else:
            # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"
    
    def _deduplicate_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """çµæœé‡è¤‡é™¤å»"""
        seen_ids = set()
        unique_results = []
        
        for result in results:
            result_id = result.get("id", "")
            if result_id not in seen_ids:
                seen_ids.add(result_id)
                unique_results.append(result)
        
        return unique_results
    
    def _filter_excluded_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆåŠ¹ç‡çš„ãƒ»æŸ”è»Ÿï¼‰"""
        
        if not results:
            return results
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±å‡ºåŠ›
        logger.info(f"ğŸ” é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é–‹å§‹: {len(results)}ä»¶ã®çµæœã‚’å‡¦ç†")
        logger.info(f"ğŸ” enable_exclusion_filter: {getattr(self, 'enable_exclusion_filter', 'NOT_SET')}")
        
        # UIã‹ã‚‰ã®é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šã‚’ç¢ºèª
        try:
            import streamlit as st
            if hasattr(st, 'session_state') and hasattr(st.session_state, 'include_deleted_pages'):
                include_deleted = st.session_state.include_deleted_pages
                logger.info(f"ğŸ” UIè¨­å®š include_deleted_pages: {include_deleted}")
                if include_deleted:
                    logger.info("ğŸŸ¢ UIè¨­å®š: å‰Šé™¤ãƒšãƒ¼ã‚¸ã‚’å«ã‚€ â†’ é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ç„¡åŠ¹åŒ–")
                    return results
            else:
                logger.info("ğŸ” Streamlit session_state ã¾ãŸã¯ include_deleted_pages ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        except Exception as e:
            logger.info(f"ğŸ” Streamlitç’°å¢ƒãƒã‚§ãƒƒã‚¯å¤±æ•—: {e}")
            pass  # Streamlitç’°å¢ƒå¤–ã§ã¯ç„¡è¦–
        
        import re
        
        # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åé›†
        all_keywords = []
        for category, keywords in self.exclusion_keywords.items():
            all_keywords.extend(keywords)
        
        logger.info(f"ğŸ” é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {all_keywords}")
        
        if not all_keywords:
            logger.info("ğŸ—‘ï¸ é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return results
        
        # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³æ§‹ç¯‰
        keywords_pattern = '|'.join(re.escape(keyword) for keyword in all_keywords)
        
        # ã€ã€‘ãƒ‘ã‚¿ãƒ¼ãƒ³: ã€ä»»æ„æ–‡å­—+é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰+ä»»æ„æ–‡å­—ã€‘
        bracket_pattern = rf'ã€.*(?:{keywords_pattern}).*ã€‘'
        
        # %%ãƒ‘ã‚¿ãƒ¼ãƒ³: %%ä»»æ„æ–‡å­—+é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰+ä»»æ„æ–‡å­—%%
        percent_pattern = rf'%%.*(?:{keywords_pattern}).*%%'
        
        # è¤‡åˆãƒ‘ã‚¿ãƒ¼ãƒ³
        combined_pattern = f'({bracket_pattern}|{percent_pattern})'
        
        logger.info(f"ğŸ—‘ï¸ é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³æ§‹ç¯‰å®Œäº†: {len(all_keywords)}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ­£è¦è¡¨ç¾ä½¿ç”¨ï¼‰")
        logger.info(f"ğŸ” ä½¿ç”¨ã™ã‚‹æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³: {combined_pattern}")
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        filtered_results = []
        excluded_count = 0
        
        for result in results:
            title = result.get("title", "")
            
            # æ­£è¦è¡¨ç¾ãƒãƒƒãƒãƒ³ã‚°
            match = re.search(combined_pattern, title, re.IGNORECASE)
            if match:
                excluded_count += 1
                logger.info(f"ğŸ—‘ï¸ é™¤å¤–: '{title}' (ãƒãƒƒãƒéƒ¨åˆ†: '{match.group()}')")
            else:
                logger.info(f"ğŸ” ä¿æŒ: '{title}'")
                filtered_results.append(result)
        
        logger.info(f"ğŸ—‘ï¸ é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å®Œäº†: {excluded_count}ä»¶é™¤å¤–, {len(filtered_results)}ä»¶æ®‹å­˜")
        
        return filtered_results
    
    def _generate_execution_summary(self, search_results: Dict[str, Any], 
                                  strategies: List[str], primary_datasource: str) -> str:
        """å®Ÿè¡Œã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        
        summary_parts = []
        
        # æˆ¦ç•¥å®Ÿè¡ŒçŠ¶æ³
        strategy_names = [self.strategies[s]["name"] for s in strategies]
        summary_parts.append(f"å®Ÿè¡Œæˆ¦ç•¥: {', '.join(strategy_names)}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥çµæœæ•°
        for datasource, results in search_results.items():
            count = len(results.get("combined_results", []))
            summary_parts.append(f"{datasource.title()}: {count}ä»¶")
        
        # ä¸»è¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
        summary_parts.append(f"ä¸»è¦: {primary_datasource.title()}")
        
        return " | ".join(summary_parts)
    
    def _get_enabled_datasources(self) -> List[str]:
        """UIã§é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’å–å¾—"""
        
        enabled_sources = []
        
        try:
            import streamlit as st
            if hasattr(st, 'session_state') and hasattr(st.session_state, 'data_sources'):
                data_sources = st.session_state.data_sources
                
                if data_sources.get('confluence', True):
                    enabled_sources.append('confluence')
                if data_sources.get('jira', True):
                    enabled_sources.append('jira')
                    
                logger.info(f"ğŸ–¥ï¸ UI ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠçŠ¶æ³: Confluence={data_sources.get('confluence', True)}, Jira={data_sources.get('jira', True)}")
            else:
                # Streamlitç’°å¢ƒå¤–ã¾ãŸã¯UIã§æœªè¨­å®šã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                enabled_sources = ['confluence', 'jira']
                logger.info("ğŸ–¥ï¸ UI ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆå…¨ã¦æœ‰åŠ¹ï¼‰")
                
        except Exception as e:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            enabled_sources = ['confluence', 'jira']
            logger.warning(f"ğŸ–¥ï¸ UI ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠå–å¾—å¤±æ•—: {e}")
            
        return enabled_sources
    
    def _determine_final_datasources(self, step2_priority: List[str], ui_enabled: List[str]) -> List[str]:
        """Step2ã®åˆ¤å®šçµæœã¨UIã®é¸æŠã‚’çµ„ã¿åˆã‚ã›ã¦æœ€çµ‚çš„ãªæ¤œç´¢å¯¾è±¡ã‚’æ±ºå®š"""
        
        # Step2ã®åˆ¤å®šçµæœã‚’å„ªå…ˆã—ã€UIã§æœ‰åŠ¹ãªã‚‚ã®ã®ã¿é¸æŠ
        # Step2ã§é™¤å¤–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼ˆç¢ºä¿¡åº¦30%æœªæº€ï¼‰ã¯ã€UIã§é¸æŠã•ã‚Œã¦ã„ã¦ã‚‚è¿½åŠ ã—ãªã„
        filtered_priority = [ds for ds in step2_priority if ds in ui_enabled]
        
        # çµæœæ¤œè¨¼
        if not filtered_priority:
            logger.warning("âš ï¸ æ¤œç´¢å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§Confluenceã‚’ä½¿ç”¨")
            return ['confluence']
        
        logger.info(f"ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯: Step2é¸æŠ={step2_priority}, UIæœ‰åŠ¹={ui_enabled}, æœ€çµ‚çµæœ={filtered_priority}")
        return filtered_priority
    
    def _build_title_exclusion_conditions(self) -> List[str]:
        """CQLç”¨ã‚¿ã‚¤ãƒˆãƒ«é™¤å¤–æ¡ä»¶æ§‹ç¯‰ï¼ˆAPIåŠ¹ç‡åŒ–ã®ãŸã‚ç„¡åŠ¹åŒ–ï¼‰"""
        
        # APIåŠ¹ç‡åŒ–ã®ãŸã‚ã€ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã®é™¤å¤–ã¯è¡Œã‚ãªã„
        # çµæœå–å¾—å¾Œã«æ­£è¦è¡¨ç¾ã§é™¤å¤–å‡¦ç†ã‚’å®Ÿè¡Œ
        logger.info("ğŸ—‘ï¸ CQLé™¤å¤–æ¡ä»¶: APIåŠ¹ç‡åŒ–ã®ãŸã‚ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«é™¤å¤–ã‚’ç„¡åŠ¹åŒ–")
        return []
    
    def _build_jql_exclusion_conditions(self) -> List[str]:
        """JQLç”¨ã‚¿ã‚¤ãƒˆãƒ«é™¤å¤–æ¡ä»¶æ§‹ç¯‰ï¼ˆAPIåŠ¹ç‡åŒ–ã®ãŸã‚ç„¡åŠ¹åŒ–ï¼‰"""
        
        # APIåŠ¹ç‡åŒ–ã®ãŸã‚ã€ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã®é™¤å¤–ã¯è¡Œã‚ãªã„
        # çµæœå–å¾—å¾Œã«æ­£è¦è¡¨ç¾ã§é™¤å¤–å‡¦ç†ã‚’å®Ÿè¡Œ
        logger.info("ğŸ—‘ï¸ JQLé™¤å¤–æ¡ä»¶: APIåŠ¹ç‡åŒ–ã®ãŸã‚ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«é™¤å¤–ã‚’ç„¡åŠ¹åŒ–")
        return []
    
    def _generate_progressive_summary(self, search_results: Dict[str, Any], primary_datasource: str) -> str:
        """æ®µéšçš„æ¤œç´¢ã®å®Ÿè¡Œã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        
        summary_parts = []
        
        # å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®æ®µéšçš„å®Ÿè¡ŒçŠ¶æ³
        for datasource, results in search_results.items():
            strategy_results = results.get("strategy_results", {})
            total_count = len(results.get("combined_results", []))
            
            # å®Ÿè¡Œã•ã‚ŒãŸæˆ¦ç•¥ã‚’ç¢ºèª
            executed_strategies = []
            title_count = len(strategy_results.get("strategy1", []))
            if title_count > 0:
                executed_strategies.append(f"ã‚¿ã‚¤ãƒˆãƒ«å³å¯†æ¤œç´¢:{title_count}ä»¶")
            
            near_count = len(strategy_results.get("strategy2", []))
            if near_count > 0:
                executed_strategies.append(f"ã‚¿ã‚¤ãƒˆãƒ«è¿‘æ¥æ¤œç´¢:{near_count}ä»¶")
            
            exact_count = len(strategy_results.get("strategy3", []))
            if exact_count > 0:
                executed_strategies.append(f"æœ¬æ–‡å³å¯†æ¤œç´¢:{exact_count}ä»¶")
            
            filtered_count = len(strategy_results.get("strategy4", []))
            if filtered_count > 0:
                executed_strategies.append(f"è£œå®ŒORæ¤œç´¢:{filtered_count}ä»¶")
            
            strategy_summary = " + ".join(executed_strategies) if executed_strategies else "ãªã—"
            summary_parts.append(f"{datasource.title()}: {total_count}ä»¶ ({strategy_summary})")
        
        # ä¸»è¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
        summary_parts.append(f"ä¸»è¦: {primary_datasource.title()}")
        
        # ç²¾åº¦å„ªå…ˆãƒ¢ãƒ¼ãƒ‰ã®è¡¨ç¤º
        summary_parts.append("ç²¾åº¦å„ªå…ˆãƒ»æ®µéšçš„å®Ÿè¡Œ")
        
        return " | ".join(summary_parts) 