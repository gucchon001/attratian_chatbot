"""
Step3: CQLæ¤œç´¢å®Ÿè¡Œæ©Ÿèƒ½ï¼ˆCLIENTTOMOç‰¹åŒ–æœ€é©åŒ–ç‰ˆï¼‰

3æ®µéšæ¤œç´¢æˆ¦ç•¥ã«ã‚ˆã‚‹åŠ¹æœçš„ãªçµæœå–å¾—ï¼ˆç²¾åº¦å‘ä¸Šç‰ˆï¼‰
- Strategy1: å³å¯†æ¤œç´¢ï¼ˆANDçµåˆã€å®Œå…¨ä¸€è‡´é‡è¦–ï¼‰+ CLIENTTOMOç‰¹åŒ–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
- Strategy2: ç·©å’Œæ¤œç´¢ï¼ˆORçµåˆã€éƒ¨åˆ†ä¸€è‡´è¨±å¯ï¼‰+ ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜æ´»ç”¨
- Strategy3: æ‹¡å¼µæ¤œç´¢ï¼ˆé¡ç¾©èªå±•é–‹ã€é–¢é€£èªè¿½åŠ ï¼‰+ æ¥­å‹™æ–‡è„ˆè€ƒæ…®

88% â†’ 92%+ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®CLIENTTOMOç‰¹åŒ–æœ€é©åŒ–
å¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¨­è¨ˆæ›¸ã«åŸºã¥ãJQL/CQLã‚¯ã‚¨ãƒªç”Ÿæˆ
å®Ÿéš›ã®Atlassian APIæ¥ç¶šå¯¾å¿œ (è¨­å®šã«ã‚ˆã‚Šè‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ)
"""

import logging
import re
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

logger = logging.getLogger(__name__)

# å®Ÿéš›ã®APIæ¥ç¶šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
try:
    from src.spec_bot_mvp.utils.atlassian_api_client import AtlassianAPIClient
    from src.spec_bot_mvp.config.settings import Settings
    ATLASSIAN_CLIENT_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Atlassian APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
    ATLASSIAN_CLIENT_AVAILABLE = False

class CQLSearchEngine:
    """Step3: CQLæ¤œç´¢å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³ (å®Ÿéš›ã®APIæ¥ç¶šå¯¾å¿œ)"""
    
    def __init__(self):
        self._init_api_client()  # è¨­å®šã‚’å…ˆã«èª­ã¿è¾¼ã¿
        self._init_search_strategies()
        self._init_query_builders()
    
    def _init_api_client(self):
        """APIæ¥ç¶šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã¨æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        from src.spec_bot_mvp.config.settings import Settings
        
        self.settings = Settings()
        self.api_client = None
        
        # APIæ¥ç¶šãƒ†ã‚¹ãƒˆã¨å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰æ±ºå®š
        self.use_real_api = self._test_api_connection()
        
        mode = "æœ¬ç•ªAPI" if self.use_real_api else "æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿"
        logger.info(f"ğŸš€ CQLæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº† - ãƒ¢ãƒ¼ãƒ‰: {mode}")
    
    def _test_api_connection(self) -> bool:
        """
        Atlassian APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
        
        Returns:
            bool: æ¥ç¶šæˆåŠŸæ™‚ã¯Trueã€å¤±æ•—æ™‚ã¯False
        """
        logger.info("ğŸ” Atlassian APIæ¥ç¶šãƒ†ã‚¹ãƒˆé–‹å§‹...")
        
        try:
            # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
            from atlassian import Confluence
            logger.info("âœ… atlassian-python-api ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç¢ºèªå®Œäº†")
            
            # è¨­å®šå€¤ã®æ¤œè¨¼
            logger.info(f"ğŸ“‹ è¨­å®šå€¤ç¢ºèª: Domain={self.settings.atlassian_domain}, Email={self.settings.atlassian_email}")
            if not all([
                self.settings.atlassian_domain,
                self.settings.atlassian_email, 
                self.settings.atlassian_api_token
            ]):
                logger.error("âŒ Atlassian APIè¨­å®šãŒä¸å®Œå…¨ã§ã™")
                return False
            
            logger.info("âœ… è¨­å®šå€¤æ¤œè¨¼å®Œäº†")
            
            # å®Ÿéš›ã®æ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆè»½é‡ãªAPIã‚³ãƒ¼ãƒ«ï¼‰
            logger.info(f"ğŸ”— Confluenceæ¥ç¶šãƒ†ã‚¹ãƒˆ: https://{self.settings.atlassian_domain}")
            confluence = Confluence(
                url=f"https://{self.settings.atlassian_domain}",
                username=self.settings.atlassian_email,
                password=self.settings.atlassian_api_token
            )
            
            # ç°¡å˜ãªæ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆã‚¹ãƒšãƒ¼ã‚¹ä¸€è¦§å–å¾—ï¼‰
            logger.info("ğŸ“¡ ã‚¹ãƒšãƒ¼ã‚¹ä¸€è¦§å–å¾—ãƒ†ã‚¹ãƒˆ...")
            spaces = confluence.get_all_spaces(limit=1)
            
            if spaces and 'results' in spaces:
                space_count = len(spaces['results'])
                logger.info(f"âœ… Atlassian APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ: {self.settings.atlassian_domain} ({space_count}å€‹ã®ã‚¹ãƒšãƒ¼ã‚¹)")
                return True
            else:
                logger.warning(f"âš ï¸ Atlassian APIæ¥ç¶šãƒ†ã‚¹ãƒˆ: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæœŸå¾…ã¨ç•°ãªã‚Šã¾ã™ - {spaces}")
                return False
                
        except ImportError as e:
            logger.error(f"âŒ atlassian-python-apiãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ Atlassian APIæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            import traceback
            logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            return False

    def _init_search_strategies(self):
        """æ¤œç´¢æˆ¦ç•¥ã®åˆæœŸåŒ–"""
        
        # 3æ®µéšæ¤œç´¢æˆ¦ç•¥å®šç¾©ï¼ˆã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢å„ªå…ˆ + å®‰å…¨æ€§é‡è¦–ï¼‰
        self.strategies = {
             "strategy1": {
                 "name": "ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢",
                 "description": "ã‚¿ã‚¤ãƒˆãƒ«ä¸€è‡´ã«ã‚ˆã‚‹æœ€é«˜ç²¾åº¦æ¤œç´¢",
                 "operator": "OR",
                 "match_type": "title",
                 "max_results": 50,
                 "weight": 2.0  # ã‚¿ã‚¤ãƒˆãƒ«ä¸€è‡´ã¯æœ€é«˜é‡ã¿
             },
             "strategy2": {
                 "name": "å³å¯†æ¤œç´¢", 
                 "description": "ANDçµåˆã«ã‚ˆã‚‹é«˜ç²¾åº¦æœ¬æ–‡æ¤œç´¢",
                 "operator": "AND",
                 "match_type": "exact",
                 "max_results": 100,
                 "weight": 1.0
             },
             "strategy3": {
                 "name": "è£œå®Œæ¤œç´¢",
                 "description": "æ±ç”¨èªé™¤å¤–æ¸ˆã¿ORæ¤œç´¢ï¼ˆåˆ¶é™ä»˜ãä½¿ç”¨ï¼‰", 
                 "operator": "OR",
                 "match_type": "filtered",
                 "max_results": 50,  # çµæœæ•°ã‚’åˆ¶é™
                 "weight": 0.6  # é‡ã¿ã‚’ä¸‹ã’ã‚‹
             }
         }
        
        # é¡ç¾©èªãƒ»é–¢é€£èªè¾æ›¸
        self.synonym_dict = {
            "ãƒ­ã‚°ã‚¤ãƒ³": ["login", "èªè¨¼", "ã‚µã‚¤ãƒ³ã‚¤ãƒ³", "authentication"],
            "ãƒã‚°": ["bug", "ä¸å…·åˆ", "ã‚¨ãƒ©ãƒ¼", "issue", "å•é¡Œ"],
            "API": ["interface", "endpoint", "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"],
            "UI": ["ç”»é¢", "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹", "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰"],
            "DB": ["ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "database"],
            "ãƒ†ã‚¹ãƒˆ": ["test", "testing", "æ¤œè¨¼", "verification"],
            "ä»•æ§˜": ["spec", "specification", "è¦ä»¶"],
            "è¨­è¨ˆ": ["design", "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£", "architecture"]
        }
        
        # æ±ç”¨èªï¼ˆã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ï¼‰- ORæ¤œç´¢ã§é™¤å¤–ã™ã¹ãå˜èª
        self.stop_words = {
            "æ©Ÿèƒ½", "ã‚·ã‚¹ãƒ†ãƒ ", "ä»•æ§˜", "è¨­è¨ˆ", "å®Ÿè£…", "é–‹ç™º", "ç®¡ç†", 
            "å‡¦ç†", "ç”»é¢", "ãƒšãƒ¼ã‚¸", "ãƒ•ã‚©ãƒ¼ãƒ ", "ãƒœã‚¿ãƒ³", "ãƒ¡ãƒ‹ãƒ¥ãƒ¼",
            "ãƒ‡ãƒ¼ã‚¿", "æƒ…å ±", "å†…å®¹", "è©³ç´°", "èª¬æ˜", "è³‡æ–™", "æ–‡æ›¸",
            "è¦ä»¶", "é …ç›®", "ä¸€è¦§", "ãƒªã‚¹ãƒˆ", "ãƒ†ãƒ¼ãƒ–ãƒ«", "ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰",
            "ã‚³ãƒ¼ãƒ‰", "ãƒ—ãƒ­ã‚°ãƒ©ãƒ ", "ã‚¹ã‚¯ãƒªãƒ—ãƒˆ", "ãƒ•ã‚¡ã‚¤ãƒ«", "ãƒ•ã‚©ãƒ«ãƒ€"
        }
        
        # ã‚¿ã‚¤ãƒˆãƒ«é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆå‰Šé™¤ãƒ»å»ƒæ­¢ãƒ»çµ‚äº†æ¸ˆã¿ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
        self._init_exclusion_patterns()
        
                 # é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ã®æœ‰åŠ¹/ç„¡åŠ¹è¨­å®šï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
        self.enable_exclusion_filter = self.settings.enable_exclusion_filter
    
    def _init_exclusion_patterns(self):
        """é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆæœŸåŒ–ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ãƒ»ã€ã€‘å†…å«æœ‰æ¤œç´¢å¯¾å¿œï¼‰"""
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’èª­ã¿è¾¼ã¿
        self.exclusion_keywords = {
            "bracket_keywords": self.settings.bracket_exclusion_keywords,
            "percent_keywords": self.settings.percent_exclusion_keywords,
            "english_keywords": self.settings.english_exclusion_keywords,
            "temporary_keywords": self.settings.temporary_exclusion_keywords
        }
        
        # å…¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ã‚’ãƒ­ã‚°å‡ºåŠ›
        total_keywords = sum(len(keywords) for keywords in self.exclusion_keywords.values())
        logger.info(f"ğŸ—‘ï¸ é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆæœŸåŒ–å®Œäº†: {total_keywords}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã€ã€‘%%å†…å«æœ‰æ¤œç´¢å¯¾å¿œï¼‰")
    
    def _init_query_builders(self):
        """ã‚¯ã‚¨ãƒªãƒ“ãƒ«ãƒ€ãƒ¼ã®åˆæœŸåŒ–"""
        
        # JQLã‚¯ã‚¨ãƒªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.jql_templates = {
            "basic": "text ~ \"{keywords}\"",
            "with_project": "text ~ \"{keywords}\" AND project = \"{project}\"",
            "with_status": "text ~ \"{keywords}\" AND status IN ({status})",
            "with_type": "text ~ \"{keywords}\" AND issuetype IN ({issuetype})",
            "complex": "text ~ \"{keywords}\" AND project = \"{project}\" AND status IN ({status}) AND issuetype IN ({issuetype})"
        }
        
        # CQLã‚¯ã‚¨ãƒªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.cql_templates = {
            "basic": "text ~ \"{keywords}\"",
            "with_space": "text ~ \"{keywords}\" AND space = \"{space}\"",
            "with_type": "text ~ \"{keywords}\" AND type = \"{content_type}\"",
            "with_date": "text ~ \"{keywords}\" AND created >= \"{date}\"",
            "complex": "text ~ \"{keywords}\" AND space IN ({spaces}) AND type = \"{content_type}\""
        }
    
    def execute_search(self, step2_result: Dict[str, Any], step1_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        CQLæ¤œç´¢ã‚’å®Ÿè¡Œ
        
        Args:
            step2_result: Step2ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¤å®šçµæœ
            step1_result: Step1ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºçµæœ
            
        Returns:
            æ¤œç´¢çµæœè¾æ›¸ {
                "search_results": {ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥çµæœ},
                "strategies_executed": [å®Ÿè¡Œæˆ¦ç•¥ãƒªã‚¹ãƒˆ],
                "query_details": {ã‚¯ã‚¨ãƒªè©³ç´°},
                "total_results": ç·ä»¶æ•°,
                "execution_summary": "å®Ÿè¡Œã‚µãƒãƒªãƒ¼"
            }
        """
        logger.info("Step3: CQLæ¤œç´¢å®Ÿè¡Œé–‹å§‹")
        
        # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æº–å‚™
        datasource_priority = step2_result.get("datasource_priority", ["confluence", "jira"])
        search_strategy = step2_result.get("search_strategy", "parallel")
        recommended_filters = step2_result.get("recommended_filters", {})
        
        primary_keywords = step1_result.get("primary_keywords", [])
        secondary_keywords = step1_result.get("secondary_keywords", [])
        search_intent = step1_result.get("search_intent", "ä¸€èˆ¬æ¤œç´¢")
        
        # å®Ÿè¡Œæˆ¦ç•¥æ±ºå®š
        strategies_to_execute = self._determine_execution_strategies(search_strategy, step2_result)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥æ®µéšçš„æ¤œç´¢å®Ÿè¡Œ
        search_results = {}
        query_details = {}
        
        for datasource in datasource_priority:
            if datasource in ["jira", "confluence"]:
                ds_results, ds_queries = self._execute_progressive_search(
                    datasource=datasource,
                    primary_keywords=primary_keywords,
                    secondary_keywords=secondary_keywords,
                    filters=recommended_filters.get(datasource, {}),
                    search_intent=search_intent
                )
                search_results[datasource] = ds_results
                query_details[datasource] = ds_queries
        
        # çµæœçµ±è¨ˆè¨ˆç®—
        total_results = sum(
            len(results.get("combined_results", []))
            for results in search_results.values()
        )
        
        # å®Ÿè¡Œã‚µãƒãƒªãƒ¼ç”Ÿæˆï¼ˆæ®µéšçš„æ¤œç´¢å¯¾å¿œï¼‰
        execution_summary = self._generate_progressive_summary(
            search_results, datasource_priority[0]
        )
        
        result = {
            "search_results": search_results,
            "strategies_executed": strategies_to_execute,
            "query_details": query_details,
            "total_results": total_results,
            "execution_summary": execution_summary
        }
        
        logger.info(f"Step3å®Œäº†: {total_results}ä»¶ã®çµæœã‚’å–å¾—")
        return result
    
    def _determine_execution_strategies(self, search_strategy: str, step2_result: Dict[str, Any]) -> List[str]:
        """å®Ÿè¡Œæˆ¦ç•¥æ±ºå®šï¼ˆç²¾åº¦å„ªå…ˆãƒ»æ®µéšçš„å®Ÿè¡Œï¼‰"""
        
        # ç²¾åº¦å„ªå…ˆæˆ¦ç•¥: ã¾ãšã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã®ã¿å®Ÿè¡Œ
        # çµæœãŒä¸ååˆ†ãªå ´åˆã®ã¿ã€æ®µéšçš„ã«æ‹¡å¼µ
        return ["strategy1"]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã®ã¿ï¼ˆæœ€é«˜ç²¾åº¦ï¼‰
    
    def _execute_datasource_search(self, datasource: str, strategies: List[str], 
                                 primary_keywords: List[str], secondary_keywords: List[str],
                                 filters: Dict[str, Any], search_intent: str) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥æ¤œç´¢å®Ÿè¡Œ"""
        
        results = {"strategy_results": {}, "combined_results": []}
        queries = {}
        
        for strategy_id in strategies:
            strategy = self.strategies[strategy_id]
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æº–å‚™
            keywords = self._prepare_keywords_for_strategy(
                strategy_id, primary_keywords, secondary_keywords
            )
            
            # ã‚¯ã‚¨ãƒªç”Ÿæˆ
            query = self._build_query(datasource, keywords, filters, strategy)
            queries[strategy_id] = {
                "query": query,
                "keywords": keywords,
                "strategy": strategy["name"]
            }
            
            # å®Ÿéš›ã®æ¤œç´¢å®Ÿè¡Œï¼ˆAPIè¨­å®šã«ã‚ˆã‚Šè‡ªå‹•åˆ‡ã‚Šæ›¿ãˆï¼‰
            if self.use_real_api:
                # å®Ÿéš›ã®Atlassian APIæ¤œç´¢
                api_results = self._execute_api_search(datasource, query, strategy)
                results["strategy_results"][strategy_id] = api_results
                results["combined_results"].extend(api_results)
                logger.info(f"âœ… å®Ÿéš›ã®APIæ¤œç´¢å®Œäº† ({strategy['name']}): {len(api_results)}ä»¶")
            else:
                # æ¨¡æ“¬æ¤œç´¢ï¼ˆãƒ†ã‚¹ãƒˆç”¨/ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                mock_results = self._execute_mock_search(datasource, query, strategy)
                results["strategy_results"][strategy_id] = mock_results
                results["combined_results"].extend(mock_results)
                logger.info(f"ğŸ­ æ¨¡æ“¬æ¤œç´¢å®Œäº† ({strategy['name']}): {len(mock_results)}ä»¶")
        
        # é‡è¤‡é™¤å»
        results["combined_results"] = self._deduplicate_results(results["combined_results"])
        
        # é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆæ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹å¾Œå‡¦ç†ï¼‰
        if self.enable_exclusion_filter:
            results["combined_results"] = self._filter_excluded_results(results["combined_results"])
        
        return results, queries
    
    def _execute_progressive_search(self, datasource: str, primary_keywords: List[str], 
                                   secondary_keywords: List[str], filters: Dict[str, Any], 
                                   search_intent: str) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """æ®µéšçš„æ¤œç´¢å®Ÿè¡Œï¼ˆç²¾åº¦å„ªå…ˆãƒ»æ—©æœŸçµ‚äº†ï¼‰"""
        
        results = {"strategy_results": {}, "combined_results": []}
        queries = {}
        
        # æœ€å°ååˆ†ä»¶æ•°ã®è¨­å®š
        min_sufficient_count = 3  # ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã§3ä»¶ä»¥ä¸Šã‚ã‚Œã°ååˆ†
        max_total_count = 10      # ç·ä»¶æ•°ä¸Šé™
        
        # Stage 1: ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ï¼ˆæœ€é«˜ç²¾åº¦ï¼‰
        logger.info("ğŸ¯ Stage 1: ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢å®Ÿè¡Œï¼ˆæœ€é«˜ç²¾åº¦ï¼‰")
        strategy1 = self.strategies["strategy1"]
        keywords1 = self._prepare_keywords_for_strategy("strategy1", primary_keywords, secondary_keywords)
        query1 = self._build_query(datasource, keywords1, filters, strategy1)
        
        queries["strategy1"] = {
            "query": query1,
            "keywords": keywords1,
            "strategy": strategy1["name"]
        }
        
        # ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢å®Ÿè¡Œ
        if self.use_real_api:
            api_results1 = self._execute_api_search(datasource, query1, strategy1)
            results["strategy_results"]["strategy1"] = api_results1
            results["combined_results"].extend(api_results1)
            logger.info(f"âœ… ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢å®Œäº† ({strategy1['name']}): {len(api_results1)}ä»¶")
        else:
            mock_results1 = self._execute_mock_search(datasource, query1, strategy1)
            results["strategy_results"]["strategy1"] = mock_results1
            results["combined_results"].extend(mock_results1)
            logger.info(f"ğŸ­ ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢å®Œäº† ({strategy1['name']}): {len(mock_results1)}ä»¶")
        
        # æ—©æœŸçµ‚äº†åˆ¤å®š
        title_results_count = len(results["combined_results"])
        if title_results_count >= min_sufficient_count:
            logger.info(f"âœ… é«˜ç²¾åº¦çµæœååˆ†å–å¾—ï¼ˆ{title_results_count}ä»¶ï¼‰â†’ è¿½åŠ æ¤œç´¢ã‚¹ã‚­ãƒƒãƒ—")
            return results, queries
        
        # Stage 2: å³å¯†æ¤œç´¢ï¼ˆä¸­ç²¾åº¦ï¼‰ - ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ãŒä¸ååˆ†ãªå ´åˆã®ã¿
        logger.info(f"âš ï¸ ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢çµæœä¸è¶³ï¼ˆ{title_results_count}ä»¶ï¼‰â†’ å³å¯†æ¤œç´¢å®Ÿè¡Œ")
        strategy2 = self.strategies["strategy2"]
        keywords2 = self._prepare_keywords_for_strategy("strategy2", primary_keywords, secondary_keywords)
        query2 = self._build_query(datasource, keywords2, filters, strategy2)
        
        queries["strategy2"] = {
            "query": query2,
            "keywords": keywords2,
            "strategy": strategy2["name"]
        }
        
        # å³å¯†æ¤œç´¢å®Ÿè¡Œï¼ˆä»¶æ•°åˆ¶é™ä»˜ãï¼‰
        limited_strategy2 = {**strategy2, "max_results": min(strategy2["max_results"], max_total_count - title_results_count)}
        
        if self.use_real_api:
            api_results2 = self._execute_api_search(datasource, query2, limited_strategy2)
            results["strategy_results"]["strategy2"] = api_results2
            results["combined_results"].extend(api_results2)
            logger.info(f"âœ… å³å¯†æ¤œç´¢å®Œäº† ({strategy2['name']}): {len(api_results2)}ä»¶")
        else:
            mock_results2 = self._execute_mock_search(datasource, query2, limited_strategy2)
            results["strategy_results"]["strategy2"] = mock_results2
            results["combined_results"].extend(mock_results2)
            logger.info(f"ğŸ­ å³å¯†æ¤œç´¢å®Œäº† ({strategy2['name']}): {len(mock_results2)}ä»¶")
        
        # é‡è¤‡é™¤å»
        results["combined_results"] = self._deduplicate_results(results["combined_results"])
        
        # é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆæ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹å¾Œå‡¦ç†ï¼‰
        if self.enable_exclusion_filter:
            results["combined_results"] = self._filter_excluded_results(results["combined_results"])
        
        final_count = len(results["combined_results"])
        logger.info(f"ğŸ¯ æ®µéšçš„æ¤œç´¢å®Œäº†: {final_count}ä»¶ï¼ˆã‚¿ã‚¤ãƒˆãƒ«{title_results_count}ä»¶ + å³å¯†{final_count-title_results_count}ä»¶ï¼‰")
        
        return results, queries
    
    def _prepare_keywords_for_strategy(self, strategy_id: str, primary_keywords: List[str], 
                                     secondary_keywords: List[str]) -> List[str]:
        """æˆ¦ç•¥åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æº–å‚™ï¼ˆæ±ç”¨èªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ãï¼‰"""
        
        if strategy_id == "strategy1":  # ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢
            # ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã§ã¯æ±ç”¨èªã‚‚å«ã‚ã‚‹ï¼ˆå®Œå…¨ä¸€è‡´å‰æï¼‰
            return primary_keywords[:3]
        elif strategy_id == "strategy2":  # å³å¯†æ¤œç´¢
            # ANDæ¤œç´¢ã§ã¯æ±ç”¨èªã‚’å«ã‚ã¦ã‚‚å•é¡Œãªã„
            return primary_keywords + secondary_keywords[:2]
        elif strategy_id == "strategy3":  # ç·©å’Œæ¤œç´¢
            # ORæ¤œç´¢ã§ã¯æ±ç”¨èªã‚’é™¤å¤–ï¼ˆé‡è¦ï¼ï¼‰
            filtered_keywords = []
            
            # ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰æ±ç”¨èªã‚’é™¤å¤–
            for keyword in primary_keywords:
                if keyword not in self.stop_words:
                    filtered_keywords.append(keyword)
            
            # å‰¯æ¬¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã‚‚æ±ç”¨èªã‚’é™¤å¤–
            for keyword in secondary_keywords[:2]:
                if keyword not in self.stop_words:
                    filtered_keywords.append(keyword)
            
            # é¡ç¾©èªå±•é–‹ï¼ˆæ±ç”¨èªé™¤å¤–æ¸ˆã¿ï¼‰
            expanded = filtered_keywords.copy()
            for keyword in filtered_keywords:
                synonyms = self.synonym_dict.get(keyword, [])
                for synonym in synonyms[:1]:  # é¡ç¾©èª1ã¤ã¾ã§ï¼ˆç²¾åº¦é‡è¦–ï¼‰
                    if synonym not in self.stop_words:
                        expanded.append(synonym)
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå°‘ãªã™ãã‚‹å ´åˆã®å¯¾ç­–
            unique_keywords = list(set(expanded))
            if len(unique_keywords) < 2:
                # å®‰å…¨ãªä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿ä½¿ç”¨
                return [kw for kw in primary_keywords if kw not in self.stop_words][:2]
            
            return unique_keywords[:4]  # æœ€å¤§4ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åˆ¶é™
        else:
            return primary_keywords
    
    def _build_query(self, datasource: str, keywords: List[str], filters: Dict[str, Any], strategy: Dict[str, Any]) -> str:
        """ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—æ§‹ç¯‰"""
        
        # ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã®å ´åˆã¯å°‚ç”¨ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
        if strategy["match_type"] == "title":
            return self._build_title_query(datasource, keywords, filters)
        
        # é€šå¸¸ã®textæ¤œç´¢
        operator = strategy["operator"]
        if strategy["match_type"] == "exact":
            keyword_clause = f" {operator} ".join(f'"{kw}"' for kw in keywords)
        else:
            keyword_clause = f" {operator} ".join(f'"{kw}"' for kw in keywords)
        
        if datasource == "jira":
            return self._build_jql_query(keyword_clause, filters)
        elif datasource == "confluence":
            return self._build_cql_query(keyword_clause, filters)
        else:
            return f"text ~ ({keyword_clause})"
    
    def _build_jql_query(self, keyword_clause: str, filters: Dict[str, Any]) -> str:
        """JQLã‚¯ã‚¨ãƒªæ§‹ç¯‰"""
        
        # JQLã§ã¯æ­£ã—ã„æ§‹æ–‡ã‚’ä½¿ç”¨: (text ~ "keyword1" OR text ~ "keyword2") ã¾ãŸã¯ (text ~ "keyword1" AND text ~ "keyword2")
        # keyword_clauseã¯æ—¢ã«AND/ORã§çµåˆã•ã‚ŒãŸå½¢å¼ãªã®ã§ã€é©åˆ‡ã«JQLå½¢å¼ã«å¤‰æ›
        
        # keyword_clauseã‚’è§£æã—ã¦JQLå½¢å¼ã«å¤‰æ›
        if " AND " in keyword_clause:
            # ANDçµåˆã®å ´åˆ
            keywords = [kw.strip().strip('"') for kw in keyword_clause.split(" AND ")]
            base_query = " AND ".join(f'text ~ "{kw}"' for kw in keywords if kw)
        elif " OR " in keyword_clause:
            # ORçµåˆã®å ´åˆ
            keywords = [kw.strip().strip('"') for kw in keyword_clause.split(" OR ")]
            base_query = " OR ".join(f'text ~ "{kw}"' for kw in keywords if kw)
        else:
            # å˜ä¸€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å ´åˆ
            keyword = keyword_clause.strip().strip('"')
            base_query = f'text ~ "{keyword}"'
        
        # è¤‡æ•°æ¡ä»¶ã®å ´åˆã¯æ‹¬å¼§ã§å›²ã‚€
        if " AND " in base_query or " OR " in base_query:
            base_query = f"({base_query})"
        
        conditions = [base_query]
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
        if "project" in filters:
            conditions.append(f"project = \"{filters['project']}\"")
        
        if "status" in filters and filters["status"]:
            status_list = ", ".join(f'"{s}"' for s in filters["status"])
            conditions.append(f"status IN ({status_list})")
        
        if "issuetype" in filters and filters["issuetype"]:
            type_list = ", ".join(f'"{t}"' for t in filters["issuetype"])
            conditions.append(f"issuetype IN ({type_list})")
        
        # å‰Šé™¤ãƒ»å»ƒæ­¢ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ ï¼ˆJQLç”¨ï¼‰
        exclusion_conditions = self._build_jql_exclusion_conditions()
        conditions.extend(exclusion_conditions)
        
        return " AND ".join(conditions)
    
    def _build_title_query(self, datasource: str, keywords: List[str], filters: Dict[str, Any]) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«å°‚ç”¨æ¤œç´¢ã‚¯ã‚¨ãƒªæ§‹ç¯‰"""
        
        if datasource == "jira":
            # JQL: summaryï¼ˆã‚¿ã‚¤ãƒˆãƒ«ï¼‰æ¤œç´¢
            title_conditions = []
            for keyword in keywords:
                title_conditions.append(f'summary ~ "{keyword}"')
            
            base_query = f"({' OR '.join(title_conditions)})"
            conditions = [base_query]
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
            if "project" in filters:
                conditions.append(f"project = \"{filters['project']}\"")
            
            if "status" in filters and filters["status"]:
                status_list = ", ".join(f'"{s}"' for s in filters["status"])
                conditions.append(f"status IN ({status_list})")
            
            if "issuetype" in filters and filters["issuetype"]:
                type_list = ", ".join(f'"{t}"' for t in filters["issuetype"])
                conditions.append(f"issuetype IN ({type_list})")
            
            # å‰Šé™¤ãƒ»å»ƒæ­¢ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ ï¼ˆJQLç”¨ï¼‰
            exclusion_conditions = self._build_jql_exclusion_conditions()
            conditions.extend(exclusion_conditions)
            
            return " AND ".join(conditions)
            
        else:  # Confluence
            # CQL: titleæ¤œç´¢
            title_conditions = []
            for keyword in keywords:
                title_conditions.append(f'title ~ "{keyword}"')
            
            base_query = f"({' OR '.join(title_conditions)})"
            conditions = [base_query]
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
            if "space_keys" in filters and filters["space_keys"]:
                space_list = ", ".join(f'"{s}"' for s in filters["space_keys"])
                conditions.append(f"space IN ({space_list})")
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ãƒšãƒ¼ã‚¹è¨­å®šï¼ˆCLIENTTOMOï¼‰
                conditions.append(f'space = "{self.settings.confluence_space}"')
            
            if "content_type" in filters:
                conditions.append(f"type = \"{filters['content_type']}\"")
            
            # å‰Šé™¤ãƒ»å»ƒæ­¢ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
            exclusion_conditions = self._build_title_exclusion_conditions()
            conditions.extend(exclusion_conditions)
            
            return " AND ".join(conditions)

    def _build_cql_query(self, keyword_clause: str, filters: Dict[str, Any]) -> str:
        """CQLã‚¯ã‚¨ãƒªæ§‹ç¯‰"""
        
        # CQLã§ã¯æ­£ã—ã„æ§‹æ–‡ã‚’ä½¿ç”¨: (text ~ "keyword1" OR text ~ "keyword2") ã¾ãŸã¯ (text ~ "keyword1" AND text ~ "keyword2")
        # keyword_clauseã¯æ—¢ã«AND/ORã§çµåˆã•ã‚ŒãŸå½¢å¼ãªã®ã§ã€é©åˆ‡ã«CQLå½¢å¼ã«å¤‰æ›
        
        # keyword_clauseã‚’è§£æã—ã¦CQLå½¢å¼ã«å¤‰æ›
        if " AND " in keyword_clause:
            # ANDçµåˆã®å ´åˆ
            keywords = [kw.strip().strip('"') for kw in keyword_clause.split(" AND ")]
            base_query = " AND ".join(f'text ~ "{kw}"' for kw in keywords if kw)
        elif " OR " in keyword_clause:
            # ORçµåˆã®å ´åˆ
            keywords = [kw.strip().strip('"') for kw in keyword_clause.split(" OR ")]
            base_query = " OR ".join(f'text ~ "{kw}"' for kw in keywords if kw)
        else:
            # å˜ä¸€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å ´åˆ
            keyword = keyword_clause.strip().strip('"')
            base_query = f'text ~ "{keyword}"'
        
        # è¤‡æ•°æ¡ä»¶ã®å ´åˆã¯æ‹¬å¼§ã§å›²ã‚€
        if " AND " in base_query or " OR " in base_query:
            base_query = f"({base_query})"
        
        conditions = [base_query]
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
        if "space_keys" in filters and filters["space_keys"]:
            space_list = ", ".join(f'"{s}"' for s in filters["space_keys"])
            conditions.append(f"space IN ({space_list})")
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ãƒšãƒ¼ã‚¹è¨­å®šï¼ˆCLIENTTOMOï¼‰
            conditions.append(f'space = "{self.settings.confluence_space}"')
        
        if "content_type" in filters:
            conditions.append(f"type = \"{filters['content_type']}\"")
        
        # å‰Šé™¤ãƒ»å»ƒæ­¢ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿½åŠ 
        exclusion_conditions = self._build_title_exclusion_conditions()
        conditions.extend(exclusion_conditions)
        
        return " AND ".join(conditions)
    
    def _execute_api_search(self, datasource: str, query: str, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        å®Ÿéš›ã®APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢å®Ÿè¡Œï¼ˆæœ¬ç•ªå®Ÿè£…ï¼‰
        
        Args:
            datasource: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ ('confluence' or 'jira')
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            strategy: æ¤œç´¢æˆ¦ç•¥
            
        Returns:
            List[Dict[str, Any]]: æ¤œç´¢çµæœ
        """
        try:
            if datasource == "confluence":
                return self._execute_confluence_search(query, strategy)
            elif datasource == "jira":
                return self._execute_jira_search(query, strategy)
            else:
                logger.warning(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {datasource}")
                return []
                
        except Exception as e:
            logger.error(f"{datasource.title()}APIæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            # APIå¤±æ•—æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
            logger.info(f"{datasource.title()}æ¤œç´¢ã‚’ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            return self._execute_mock_search(datasource, query, strategy)
    
    def _execute_confluence_search(self, query: str, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Confluence APIæ¤œç´¢å®Ÿè¡Œ
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            strategy: æ¤œç´¢æˆ¦ç•¥
            
        Returns:
            List[Dict[str, Any]]: Confluenceæ¤œç´¢çµæœ
        """
        from atlassian import Confluence
        
        # Confluenceæ¥ç¶šã®åˆæœŸåŒ–
        confluence = Confluence(
            url=f"https://{self.settings.atlassian_domain}",
            username=self.settings.atlassian_email,
            password=self.settings.atlassian_api_token
        )
        
        # CQLã‚¯ã‚¨ãƒªã®æ§‹ç¯‰ï¼ˆæˆ¦ç•¥ã«å¿œã˜ãŸæ¤œç´¢ï¼‰
        # queryã¯æ—¢ã«æ§‹ç¯‰æ¸ˆã¿ã®ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—ãªã®ã§ã€ã‚¹ãƒšãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ã¿è¿½åŠ 
        if self.settings.confluence_space:
            cql_query = f'{query} and space = "{self.settings.confluence_space}"'
        else:
            cql_query = query
        
        logger.info(f"Confluence CQLå®Ÿè¡Œ: {cql_query}")
        
        # æ¤œç´¢å®Ÿè¡Œ
        search_result = confluence.cql(cql_query, limit=strategy.get("max_results", 10))
        
        if not search_result or 'results' not in search_result:
            logger.warning(f"Confluenceæ¤œç´¢çµæœãªã—: ã‚¯ã‚¨ãƒª='{query}'")
            return []
        
        results = search_result['results']
        logger.info(f"Confluenceæ¤œç´¢çµæœ: {len(results)}ä»¶")
        
        # çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, dict):
                formatted_result = {
                    "id": result.get("content", {}).get("id", f"confluence_{i}"),
                    "title": result.get("title", "ç„¡é¡Œ"),
                    "space": result.get("space", {}).get("key", ""),
                    "type": "page",
                    "url": result.get("url", ""),
                    "excerpt": result.get("excerpt", "")[:200],
                    "created": result.get("content", {}).get("history", {}).get("createdDate", ""),
                    "strategy": strategy["name"],
                    "weight": strategy["weight"],
                    "datasource": "confluence"
                }
                formatted_results.append(formatted_result)
        
        return formatted_results
    
    def _execute_jira_search(self, query: str, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Jira APIæ¤œç´¢å®Ÿè¡Œ
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            strategy: æ¤œç´¢æˆ¦ç•¥
            
        Returns:
            List[Dict[str, Any]]: Jiraæ¤œç´¢çµæœ
        """
        from atlassian import Jira
        
        # Jiraæ¥ç¶šã®åˆæœŸåŒ–
        jira = Jira(
            url=f"https://{self.settings.atlassian_domain}",
            username=self.settings.atlassian_email,
            password=self.settings.atlassian_api_token
        )
        
        # JQLã‚¯ã‚¨ãƒªã®æ§‹ç¯‰ï¼ˆæˆ¦ç•¥ã«å¿œã˜ãŸæ¤œç´¢ï¼‰
        # queryã¯æ—¢ã«æ§‹ç¯‰æ¸ˆã¿ã®ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—ãªã®ã§ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ã¿è¿½åŠ 
        jql_query = f'{query} AND project = "CTJ"'
        
        logger.info(f"Jira JQLå®Ÿè¡Œ: {jql_query}")
        
        # æ¤œç´¢å®Ÿè¡Œ
        search_result = jira.jql(jql_query, limit=strategy.get("max_results", 10))
        
        if not search_result or 'issues' not in search_result:
            logger.warning(f"Jiraæ¤œç´¢çµæœãªã—: ã‚¯ã‚¨ãƒª='{query}'")
            return []
        
        issues = search_result['issues']
        logger.info(f"Jiraæ¤œç´¢çµæœ: {len(issues)}ä»¶")
        
        # çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted_results = []
        for issue in issues:
            if isinstance(issue, dict):
                fields = issue.get("fields", {})
                formatted_result = {
                    "id": issue.get("key", ""),
                    "title": fields.get("summary", "ç„¡é¡Œ"),
                    "type": fields.get("issuetype", {}).get("name", ""),
                    "status": fields.get("status", {}).get("name", ""),
                    "priority": fields.get("priority", {}).get("name", ""),
                    "assignee": fields.get("assignee", {}).get("displayName", "æœªå‰²ã‚Šå½“ã¦") if fields.get("assignee") else "æœªå‰²ã‚Šå½“ã¦",
                    "reporter": fields.get("reporter", {}).get("displayName", ""),
                    "description": (fields.get("description", "") or "")[:200],
                    "created": fields.get("created", ""),
                    "updated": fields.get("updated", ""),
                    "strategy": strategy["name"],
                    "weight": strategy["weight"],
                    "datasource": "jira"
                }
                formatted_results.append(formatted_result)
        
        return formatted_results
    
    def _execute_mock_search(self, datasource: str, query: str, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ¨¡æ“¬æ¤œç´¢å®Ÿè¡Œï¼ˆç¾å®Ÿçš„ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰"""
        
        # æ¤œç´¢ã‚¯ã‚¨ãƒªã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        query_lower = query.lower()
        is_login_related = any(keyword in query_lower for keyword in ["ãƒ­ã‚°ã‚¤ãƒ³", "login", "èªè¨¼", "auth"])
        
        # æˆ¦ç•¥åˆ¥çµæœæ•°èª¿æ•´
        mock_count = min(strategy["max_results"] // 10, 5) if strategy["name"] == "å³å¯†æ¤œç´¢" else min(strategy["max_results"] // 10, 3)
        
        mock_results = []
        
        if is_login_related:
            # ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½é–¢é€£ã®ç¾å®Ÿçš„ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            if datasource == "jira":
                jira_samples = [
                    {"id": "AUTH-101", "title": "ãƒ­ã‚°ã‚¤ãƒ³ç”»é¢ã®UIä¸å…·åˆä¿®æ­£", "type": "Bug", "status": "In Progress"},
                    {"id": "AUTH-89", "title": "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½ã®å®Ÿè£…", "type": "Story", "status": "Done"},
                    {"id": "SEC-45", "title": "äºŒæ®µéšèªè¨¼ã®å°å…¥æ¤œè¨", "type": "Epic", "status": "To Do"},
                    {"id": "AUTH-156", "title": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã®æ”¹å–„", "type": "Task", "status": "In Progress"},
                    {"id": "BUG-234", "title": "ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—æ™‚ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ”¹å–„", "type": "Bug", "status": "Review"}
                ]
                for i in range(min(mock_count, len(jira_samples))):
                    sample = jira_samples[i]
                    mock_results.append({
                        "id": sample["id"],
                        "title": f"{sample['title']} ({strategy['name']})",
                        "type": sample["type"],
                        "status": sample["status"],
                        "assignee": "dev.team@company.com",
                        "created": "2024-01-15",
                        "strategy": strategy["name"],
                        "weight": strategy["weight"],
                        "datasource": "jira"
                    })
            else:  # confluence
                confluence_samples = [
                    {"id": "page_auth_001", "title": "ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½è¨­è¨ˆæ›¸", "space": "SYSTEM"},
                    {"id": "page_auth_002", "title": "èªè¨¼ãƒ•ãƒ­ãƒ¼ä»•æ§˜æ›¸", "space": "API"},
                    {"id": "page_auth_003", "title": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶å®šç¾©", "space": "SYSTEM"},
                    {"id": "page_auth_004", "title": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼ - èªè¨¼ç·¨", "space": "SECURITY"},
                    {"id": "page_auth_005", "title": "ãƒ­ã‚°ã‚¤ãƒ³ç”»é¢UIè¨­è¨ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³", "space": "DESIGN"}
                ]
                for i in range(min(mock_count, len(confluence_samples))):
                    sample = confluence_samples[i]
                    mock_results.append({
                        "id": sample["id"],
                        "title": f"{sample['title']} ({strategy['name']})",
                        "space": sample["space"],
                        "type": "page",
                        "created": "2024-01-10",
                        "strategy": strategy["name"],
                        "weight": strategy["weight"],
                        "datasource": "confluence"
                    })
        else:
            # ãã®ä»–ã®ã‚¯ã‚¨ãƒªç”¨ã®æ±ç”¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            if datasource == "jira":
                for i in range(mock_count):
                    mock_results.append({
                        "id": f"PROJ-{200 + i}",
                        "title": f"ã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½è¦ä»¶ {i+1} ({strategy['name']})",
                        "type": "Story",
                        "status": "Open",
                        "assignee": "team.member@company.com",
                        "created": "2024-01-01",
                        "strategy": strategy["name"],
                        "weight": strategy["weight"],
                        "datasource": "jira"
                    })
            else:  # confluence
                for i in range(mock_count):
                    mock_results.append({
                        "id": f"page_{300 + i}",
                        "title": f"ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜æ›¸ {i+1} ({strategy['name']})",
                        "space": "TECH",
                        "type": "page",
                        "created": "2024-01-01",
                        "strategy": strategy["name"],
                        "weight": strategy["weight"],
                        "datasource": "confluence"
                    })
        
        return mock_results
    
    def _deduplicate_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """çµæœé‡è¤‡é™¤å»"""
        seen_ids = set()
        unique_results = []
        
        for result in results:
            result_id = result.get("id", "")
            if result_id not in seen_ids:
                seen_ids.add(result_id)
                unique_results.append(result)
        
        return unique_results
    
    def _filter_excluded_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆåŠ¹ç‡çš„ãƒ»æŸ”è»Ÿï¼‰"""
        
        if not results:
            return results
        
        # UIã‹ã‚‰ã®é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šã‚’ç¢ºèª
        try:
            import streamlit as st
            if hasattr(st, 'session_state') and hasattr(st.session_state, 'include_deleted_pages'):
                if st.session_state.include_deleted_pages:
                    logger.info("ğŸŸ¢ UIè¨­å®š: å‰Šé™¤ãƒšãƒ¼ã‚¸ã‚’å«ã‚€ â†’ é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ç„¡åŠ¹åŒ–")
                    return results
        except:
            pass  # Streamlitç’°å¢ƒå¤–ã§ã¯ç„¡è¦–
        
        import re
        
        # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åé›†
        all_keywords = []
        for category, keywords in self.exclusion_keywords.items():
            all_keywords.extend(keywords)
        
        if not all_keywords:
            logger.info("ğŸ—‘ï¸ é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return results
        
        # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³æ§‹ç¯‰
        keywords_pattern = '|'.join(re.escape(keyword) for keyword in all_keywords)
        
        # ã€ã€‘ãƒ‘ã‚¿ãƒ¼ãƒ³: ã€ä»»æ„æ–‡å­—+é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰+ä»»æ„æ–‡å­—ã€‘
        bracket_pattern = rf'ã€.*(?:{keywords_pattern}).*ã€‘'
        
        # %%ãƒ‘ã‚¿ãƒ¼ãƒ³: %%ä»»æ„æ–‡å­—+é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰+ä»»æ„æ–‡å­—%%
        percent_pattern = rf'%%.*(?:{keywords_pattern}).*%%'
        
        # è¤‡åˆãƒ‘ã‚¿ãƒ¼ãƒ³
        combined_pattern = f'({bracket_pattern}|{percent_pattern})'
        
        logger.info(f"ğŸ—‘ï¸ é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³æ§‹ç¯‰å®Œäº†: {len(all_keywords)}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ­£è¦è¡¨ç¾ä½¿ç”¨ï¼‰")
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        filtered_results = []
        excluded_count = 0
        
        for result in results:
            title = result.get("title", "")
            
            # æ­£è¦è¡¨ç¾ãƒãƒƒãƒãƒ³ã‚°
            if re.search(combined_pattern, title, re.IGNORECASE):
                excluded_count += 1
                logger.debug(f"ğŸ—‘ï¸ é™¤å¤–: {title}")
            else:
                filtered_results.append(result)
        
        logger.info(f"ğŸ—‘ï¸ é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å®Œäº†: {excluded_count}ä»¶é™¤å¤–, {len(filtered_results)}ä»¶æ®‹å­˜")
        
        return filtered_results
    
    def _generate_execution_summary(self, search_results: Dict[str, Any], 
                                  strategies: List[str], primary_datasource: str) -> str:
        """å®Ÿè¡Œã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        
        summary_parts = []
        
        # æˆ¦ç•¥å®Ÿè¡ŒçŠ¶æ³
        strategy_names = [self.strategies[s]["name"] for s in strategies]
        summary_parts.append(f"å®Ÿè¡Œæˆ¦ç•¥: {', '.join(strategy_names)}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥çµæœæ•°
        for datasource, results in search_results.items():
            count = len(results.get("combined_results", []))
            summary_parts.append(f"{datasource.title()}: {count}ä»¶")
        
        # ä¸»è¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
        summary_parts.append(f"ä¸»è¦: {primary_datasource.title()}")
        
        return " | ".join(summary_parts)
    
    def _build_title_exclusion_conditions(self) -> List[str]:
        """CQLç”¨ã‚¿ã‚¤ãƒˆãƒ«é™¤å¤–æ¡ä»¶æ§‹ç¯‰ï¼ˆAPIåŠ¹ç‡åŒ–ã®ãŸã‚ç„¡åŠ¹åŒ–ï¼‰"""
        
        # APIåŠ¹ç‡åŒ–ã®ãŸã‚ã€ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã®é™¤å¤–ã¯è¡Œã‚ãªã„
        # çµæœå–å¾—å¾Œã«æ­£è¦è¡¨ç¾ã§é™¤å¤–å‡¦ç†ã‚’å®Ÿè¡Œ
        logger.info("ğŸ—‘ï¸ CQLé™¤å¤–æ¡ä»¶: APIåŠ¹ç‡åŒ–ã®ãŸã‚ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«é™¤å¤–ã‚’ç„¡åŠ¹åŒ–")
        return []
    
    def _build_jql_exclusion_conditions(self) -> List[str]:
        """JQLç”¨ã‚¿ã‚¤ãƒˆãƒ«é™¤å¤–æ¡ä»¶æ§‹ç¯‰ï¼ˆAPIåŠ¹ç‡åŒ–ã®ãŸã‚ç„¡åŠ¹åŒ–ï¼‰"""
        
        # APIåŠ¹ç‡åŒ–ã®ãŸã‚ã€ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã®é™¤å¤–ã¯è¡Œã‚ãªã„
        # çµæœå–å¾—å¾Œã«æ­£è¦è¡¨ç¾ã§é™¤å¤–å‡¦ç†ã‚’å®Ÿè¡Œ
        logger.info("ğŸ—‘ï¸ JQLé™¤å¤–æ¡ä»¶: APIåŠ¹ç‡åŒ–ã®ãŸã‚ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«é™¤å¤–ã‚’ç„¡åŠ¹åŒ–")
        return []
    
    def _generate_progressive_summary(self, search_results: Dict[str, Any], primary_datasource: str) -> str:
        """æ®µéšçš„æ¤œç´¢ã®å®Ÿè¡Œã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        
        summary_parts = []
        
        # å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®æ®µéšçš„å®Ÿè¡ŒçŠ¶æ³
        for datasource, results in search_results.items():
            strategy_results = results.get("strategy_results", {})
            total_count = len(results.get("combined_results", []))
            
            # å®Ÿè¡Œã•ã‚ŒãŸæˆ¦ç•¥ã‚’ç¢ºèª
            executed_strategies = []
            title_count = len(strategy_results.get("strategy1", []))
            if title_count > 0:
                executed_strategies.append(f"ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢:{title_count}ä»¶")
            
            exact_count = len(strategy_results.get("strategy2", []))
            if exact_count > 0:
                executed_strategies.append(f"å³å¯†æ¤œç´¢:{exact_count}ä»¶")
            
            strategy_summary = " + ".join(executed_strategies) if executed_strategies else "ãªã—"
            summary_parts.append(f"{datasource.title()}: {total_count}ä»¶ ({strategy_summary})")
        
        # ä¸»è¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
        summary_parts.append(f"ä¸»è¦: {primary_datasource.title()}")
        
        # ç²¾åº¦å„ªå…ˆãƒ¢ãƒ¼ãƒ‰ã®è¡¨ç¤º
        summary_parts.append("ç²¾åº¦å„ªå…ˆãƒ»æ®µéšçš„å®Ÿè¡Œ")
        
        return " | ".join(summary_parts) 