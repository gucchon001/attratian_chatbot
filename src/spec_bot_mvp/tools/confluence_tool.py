"""
Confluenceæ¤œç´¢ãƒ„ãƒ¼ãƒ«

CQLã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ã—ã¦Confluenceãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢ã—ã€LangChainã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½ãª
æ§‹é€ åŒ–ã•ã‚ŒãŸçµæœã‚’è¿”ã™ãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import logging
import time
from typing import Optional, List, Dict, Any
from atlassian import Confluence

from ..config.settings import settings
from ..utils.cache_manager import CacheManager
from ..utils.log_config import get_logger, log_search_results

# ãƒ­ã‚°è¨­å®š
logger = get_logger(__name__)

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
cache_manager = CacheManager()


def search_confluence_tool(query: str, analyze_content: bool = True, api_logger=None) -> str:
    """
    CQLã‚¯ã‚¨ãƒªã§Confluenceãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢ã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸçµæœã‚’è¿”ã™
    
    Args:
        query (str): æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        analyze_content (bool): ãƒšãƒ¼ã‚¸å†…å®¹ã‚’è©³ç´°åˆ†æã™ã‚‹ã‹ã©ã†ã‹
        
    Returns:
        str: æ¤œç´¢çµæœã®ã‚µãƒãƒªãƒ¼ï¼ˆãƒšãƒ¼ã‚¸æƒ…å ±ã‚’æ•´å½¢ã—ãŸã‚‚ã®ï¼‰
    """
    if not query or not query.strip():
        return "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    
    try:
        # Confluenceæ¥ç¶šã®åˆæœŸåŒ–
        confluence = Confluence(
            url=f"https://{settings.atlassian_domain}",
            username=settings.atlassian_email,
            password=settings.atlassian_api_token
        )
        
        # CQLã‚¯ã‚¨ãƒªã®æ§‹ç¯‰ - ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã¨ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ã‚’ä½µç”¨ï¼ˆæ€¥å‹Ÿæ©Ÿèƒ½å¯¾å¿œï¼‰
        # ç‰¹å®šã®ã‚¹ãƒšãƒ¼ã‚¹ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚‚æ¡ä»¶ã«å«ã‚ã‚‹
        if settings.confluence_space:
            cql_query = f'(text ~ "{query.strip()}" OR title ~ "{query.strip()}") and space = "{settings.confluence_space}"'
        else:
            cql_query = f'(text ~ "{query.strip()}" OR title ~ "{query.strip()}")'
        
        logger.info(f"Confluenceæ¤œç´¢å®Ÿè¡Œ: {cql_query}")
        start_time = time.time()
        
        # APIãƒ­ã‚°: ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨˜éŒ²
        if api_logger and api_logger.is_logging_enabled():
            api_logger.log_confluence_request(
                cql_query=cql_query,
                space_key=settings.confluence_space,
                limit=10
            )
        
        # Confluenceæ¤œç´¢ã®å®Ÿè¡Œ
        search_result = confluence.cql(cql_query, limit=10)
        search_time = time.time() - start_time
        
        # APIãƒ­ã‚°: ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¨˜éŒ²
        if api_logger and api_logger.is_logging_enabled():
            results = search_result.get('results', [])
            total_size = search_result.get('totalSize', 0)
            api_logger.log_confluence_response(
                pages=results,
                total_size=total_size,
                execution_time=search_time
            )
        
        if not search_result or 'results' not in search_result:
            logger.warning(f"Confluenceæ¤œç´¢çµæœãªã—: ã‚¯ã‚¨ãƒª='{query}' | å®Ÿè¡Œæ™‚é–“: {search_time:.2f}ç§’")
            return f"Confluenceã§ã€Œ{query}ã€ã«é–¢ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        results = search_result['results']
        total_count = search_result.get('totalSize', 0)
        
        # çµæœã®å‹ãƒã‚§ãƒƒã‚¯ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚¨ãƒ©ãƒ¼å‡¦ç†æ”¹å–„ï¼‰
        valid_results = []
        for i, result in enumerate(results):
            if isinstance(result, dict):
                valid_results.append(result)
            else:
                logger.warning(f"çµæœ {i+1} ã¯è¾æ›¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“ (type: {type(result).__name__}): {str(result)[:100]}...")
        
        results = valid_results
        
        if total_count == 0 or not results:
            logger.warning(f"Confluenceæ¤œç´¢çµæœ0ä»¶: ã‚¯ã‚¨ãƒª='{query}' | å®Ÿè¡Œæ™‚é–“: {search_time:.2f}ç§’")
            return f"Confluenceã§ã€Œ{query}ã€ã«é–¢ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        # æ¤œç´¢çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        log_search_results(logger, "Confluence", query, results, total_count, search_time)
        
        # è©³ç´°åˆ†æãŒå¿…è¦ãªå ´åˆã€ä¸Šä½çµæœã®ãƒšãƒ¼ã‚¸å†…å®¹ã‚’å–å¾—
        enhanced_results = results
        if analyze_content and results:
            logger.info(f"è©³ç´°åˆ†æé–‹å§‹: ä¸Šä½{min(3, len(results))}ä»¶ã®ãƒšãƒ¼ã‚¸å†…å®¹ã‚’å–å¾—")
            analysis_start_time = time.time()
            enhanced_results = _enhance_results_with_content(confluence, results[:3])  # ä¸Šä½3ä»¶ã®ã¿è©³ç´°åˆ†æ
            analysis_time = time.time() - analysis_start_time
            logger.info(f"è©³ç´°åˆ†æå®Œäº†: å®Ÿè¡Œæ™‚é–“ {analysis_time:.2f}ç§’")
        
        # çµæœã®æ•´å½¢
        result_summary = _format_confluence_results(enhanced_results, query, total_count, analyze_content)
        
        total_time = time.time() - start_time
        logger.info(f"Confluenceæ¤œç´¢å‡¦ç†å®Œäº†: {len(results)}ä»¶å–å¾— | ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
        return result_summary
        
    except Exception as e:
        logger.error(f"Confluenceæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return f"Confluenceã®æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"


def _enhance_results_with_content(confluence: Confluence, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    æ¤œç´¢çµæœã«ãƒšãƒ¼ã‚¸ã®è©³ç´°å†…å®¹ã‚’è¿½åŠ ã™ã‚‹
    
    Args:
        confluence: Confluence APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        results: æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ
        
    Returns:
        List[Dict[str, Any]]: è©³ç´°å†…å®¹ã‚’å«ã‚€æ¤œç´¢çµæœ
    """
    enhanced_results = []
    
    for result in results:
        try:
            # ãƒšãƒ¼ã‚¸IDã‚’å–å¾—
            page_id = None
            if 'id' in result:
                page_id = result['id']
            elif 'content' in result and isinstance(result['content'], dict) and 'id' in result['content']:
                page_id = result['content']['id']
            
            if page_id:
                # ãƒšãƒ¼ã‚¸ã®è©³ç´°å†…å®¹ã‚’å–å¾—
                page_content = confluence.get_page_by_id(
                    page_id, 
                    expand='body.storage,version,space'
                )
                
                if page_content and 'body' in page_content:
                    # æœ¬æ–‡ã‚’æŠ½å‡ºã—ã¦åˆ†æï¼ˆå®‰å…¨ãªå‹ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
                    body_obj = page_content.get('body', {})
                    if isinstance(body_obj, dict):
                        storage_obj = body_obj.get('storage', {})
                        if isinstance(storage_obj, dict):
                            body_content = storage_obj.get('value', '')
                            if body_content:
                                # HTMLã‚¿ã‚°ã‚’é™¤å»ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                                text_content = _extract_text_from_html(body_content)
                                # é‡è¦ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
                                key_sections = _extract_key_sections(text_content)
                                
                                # å…ƒã®çµæœã«è©³ç´°å†…å®¹ã‚’è¿½åŠ 
                                result['detailed_content'] = text_content[:1000]  # æœ€åˆã®1000æ–‡å­—
                                result['key_sections'] = key_sections
                                result['full_page_data'] = page_content
                
            enhanced_results.append(result)
            
        except Exception as e:
            logger.warning(f"ãƒšãƒ¼ã‚¸è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            enhanced_results.append(result)  # å…ƒã®çµæœã‚’ãã®ã¾ã¾è¿½åŠ 
    
    return enhanced_results


def _extract_key_sections(text_content: str) -> Dict[str, str]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰é‡è¦ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºã™ã‚‹
    
    Args:
        text_content: ãƒšãƒ¼ã‚¸ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹
        
    Returns:
        Dict[str, str]: æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    """
    sections = {}
    
    # ä»•æ§˜ã€è¨­è¨ˆã€å®Ÿè£…ã€è¦ä»¶ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
    keywords = {
        'requirements': ['è¦ä»¶', 'è¦æ±‚', 'requirement'],
        'specifications': ['ä»•æ§˜', 'ä»•æ§˜æ›¸', 'specification', 'spec'],
        'design': ['è¨­è¨ˆ', 'è¨­è¨ˆæ›¸', 'design'],
        'implementation': ['å®Ÿè£…', 'å®Ÿè£…æ–¹æ³•', 'implementation'],
        'best_practices': ['ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹', 'æ¨å¥¨', 'best practice', 'æœ€é©'],
        'security': ['ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'security', 'èªè¨¼', 'authentication'],
        'architecture': ['ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£', 'architecture', 'æ§‹æˆ', 'æ§‹é€ ']
    }
    
    lines = text_content.split('\n')
    current_section = None
    current_content = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¤œå‡º
        found_section = None
        for section_key, section_keywords in keywords.items():
            if any(keyword in line.lower() for keyword in section_keywords):
                found_section = section_key
                break
        
        if found_section:
            # å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
            if current_section and current_content:
                sections[current_section] = ' '.join(current_content)[:300]  # æœ€åˆã®300æ–‡å­—
            
            current_section = found_section
            current_content = [line]
        elif current_section and len(current_content) < 10:  # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹ã‚’åé›†ï¼ˆæœ€å¤§10è¡Œï¼‰
            current_content.append(line)
    
    # æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
    if current_section and current_content:
        sections[current_section] = ' '.join(current_content)[:300]
    
    return sections


def _extract_text_from_html(html_content: str) -> str:
    """
    HTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹
    
    Args:
        html_content: HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        
    Returns:
        str: æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    import re
    
    # HTMLã‚¿ã‚°ã‚’é™¤å»
    text = re.sub(r'<[^>]+>', ' ', html_content)
    # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«
    text = re.sub(r'\s+', ' ', text)
    # æ”¹è¡Œã‚’æ­£è¦åŒ–
    text = text.replace('\n', ' ').strip()
    
    return text


def _format_confluence_results(results: List[Dict[str, Any]], query: str, total_count: int, analyze_content: bool = False) -> str:
    """
    Confluenceæ¤œç´¢çµæœã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«æ•´å½¢ã™ã‚‹
    
    Args:
        results: Confluenceæ¤œç´¢çµæœã®resultsé…åˆ—
        query: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        total_count: ç·ä»¶æ•°
        analyze_content: è©³ç´°åˆ†æçµæœã‚’å«ã‚€ã‹ã©ã†ã‹
        
    Returns:
        str: æ•´å½¢ã•ã‚ŒãŸæ¤œç´¢çµæœ
    """
    if not results:
        return f"Confluenceã§ã€Œ{query}ã€ã«é–¢ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†
    analysis_note = " (è©³ç´°åˆ†æä»˜ã)" if analyze_content else ""
    result_lines = [
        f"ğŸ“š **Confluenceãƒšãƒ¼ã‚¸æ¤œç´¢çµæœ{analysis_note}**",
        f"ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ã€Œ{query}ã€",
        f"ğŸ“Œ è¦‹ã¤ã‹ã£ãŸãƒšãƒ¼ã‚¸: {len(results)}ä»¶ï¼ˆç·æ•°: {total_count}ä»¶ï¼‰",
        ""
    ]
    
    # å„ãƒšãƒ¼ã‚¸ã®è©³ç´°
    for i, result in enumerate(results[:5], 1):  # æœ€å¤§5ä»¶è¡¨ç¤º
        try:
            # resultãŒè¾æ›¸ã§ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if not isinstance(result, dict):
                logger.warning(f"çµæœ {i} ã¯è¾æ›¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(result)}")
                continue
            
            # CQLæ¤œç´¢ã®å ´åˆã€ãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒç•°ãªã‚‹ã“ã¨ãŒã‚ã‚‹
            # result ç›´ä¸‹ã«title, typeãªã©ãŒã‚ã‚‹å ´åˆã¨contentä¸‹ã«ã‚ã‚‹å ´åˆã‚’ä¸¡æ–¹ãƒã‚§ãƒƒã‚¯
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã®å–å¾—
            title = 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—'
            if 'title' in result:
                title = result['title']
            elif 'content' in result and isinstance(result['content'], dict) and 'title' in result['content']:
                title = result['content']['title']
            
            # ID ã¨ã‚¿ã‚¤ãƒ—ã®å–å¾—ï¼ˆæ¤œç´¢çµæœã®æ§‹é€ ã‚’è€ƒæ…®ï¼‰
            page_id = 'N/A'
            if 'content' in result and isinstance(result['content'], dict) and 'id' in result['content']:
                page_id = result['content']['id']
            elif 'id' in result:
                page_id = result['id']
            
            page_type = 'page'
            if 'content' in result and isinstance(result['content'], dict) and 'type' in result['content']:
                page_type = result['content']['type']
            elif 'type' in result:
                page_type = result['type']
            
            # ã‚¹ãƒšãƒ¼ã‚¹æƒ…å ±ã®å–å¾—ï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œï¼‰
            space_name = 'CLIENTTOMO'
            space_key = 'CLIENTTOMO'
            
            space_info = None
            if 'content' in result and isinstance(result['content'], dict) and 'space' in result['content']:
                space_info = result['content']['space']
            elif 'space' in result:
                space_info = result['space']
            
            if isinstance(space_info, dict):
                space_name = space_info.get('name', 'CLIENTTOMO')
                space_key = space_info.get('key', 'CLIENTTOMO')
            elif space_info:
                space_name = str(space_info)
                space_key = str(space_info)
            
            # æ¤œç´¢çµæœã®æŠœç²‹
            excerpt = result.get('excerpt', '') or result.get('bodyExcerpt', '')
            if excerpt:
                # HTMLã‚¿ã‚°ã‚’ç°¡å˜ã«é™¤å»
                excerpt = _clean_html_tags(excerpt)
            
            # ä½œæˆè€…æƒ…å ±ï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œï¼‰
            created_by = 'ã‚·ã‚¹ãƒ†ãƒ '  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
            # æ§˜ã€…ãªãƒ‘ã‚¹ã§ä½œæˆè€…æƒ…å ±ã‚’å–å¾—è©¦è¡Œï¼ˆå®‰å…¨ãªå‹ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
            creator_paths = []
            
            # createdBy.displayName
            created_by_obj = result.get('createdBy', {})
            if isinstance(created_by_obj, dict):
                creator_paths.append(created_by_obj.get('displayName'))
            
            # content.history.createdBy.displayName
            content_obj = result.get('content', {})
            if isinstance(content_obj, dict):
                history_obj = content_obj.get('history', {})
                if isinstance(history_obj, dict):
                    created_by_nested = history_obj.get('createdBy', {})
                    if isinstance(created_by_nested, dict):
                        creator_paths.append(created_by_nested.get('displayName'))
            
            # lastModified.by.displayName
            last_modified_obj = result.get('lastModified', {})
            if isinstance(last_modified_obj, dict):
                by_obj = last_modified_obj.get('by', {})
                if isinstance(by_obj, dict):
                    creator_paths.append(by_obj.get('displayName'))
            
            # version.by.displayName
            version_obj = result.get('version', {})
            if isinstance(version_obj, dict):
                by_obj = version_obj.get('by', {})
                if isinstance(by_obj, dict):
                    creator_paths.append(by_obj.get('displayName'))
            
            for creator in creator_paths:
                if creator:
                    created_by = creator
                    break
            
            # WebUIä¸Šã§ã®ãƒšãƒ¼ã‚¸URL
            base_url = f"https://{settings.atlassian_domain}"
            
            # URLæ§‹ç¯‰ï¼ˆIDãŒå–å¾—ã§ãã¦ã„ã‚‹å ´åˆï¼‰
            if page_id and page_id != 'N/A':
                page_url = f"{base_url}/wiki/spaces/{space_key}/pages/{page_id}"
            else:
                # IDãŒå–å¾—ã§ããªã„å ´åˆã¯æ¤œç´¢çµæœã®URLã‚’ä½¿ç”¨
                page_url = result.get('url', f"{base_url}/wiki/search?text={query}")
            
            result_lines.extend([
                f"ğŸ“„ **{i}. {title}**",
                f"   ğŸ“ ã‚¹ãƒšãƒ¼ã‚¹: {space_name} ({space_key}) | ã‚¿ã‚¤ãƒ—: {page_type}",
                f"   ğŸ‘¤ ä½œæˆè€…: {created_by}",
            ])
            
            # è©³ç´°åˆ†æçµæœãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’å„ªå…ˆè¡¨ç¤º
            if analyze_content and 'key_sections' in result and result['key_sections']:
                result_lines.append("   ğŸ“‹ **é‡è¦ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³:**")
                key_sections = result['key_sections']
                
                # æ—¥æœ¬èªã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³åã«å¤‰æ›
                section_names = {
                    'requirements': 'è¦ä»¶ãƒ»è¦æ±‚',
                    'specifications': 'ä»•æ§˜ãƒ»ä»•æ§˜æ›¸', 
                    'design': 'è¨­è¨ˆãƒ»è¨­è¨ˆæ›¸',
                    'implementation': 'å®Ÿè£…ãƒ»å®Ÿè£…æ–¹æ³•',
                    'best_practices': 'ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãƒ»æ¨å¥¨äº‹é …',
                    'security': 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»èªè¨¼',
                    'architecture': 'ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ»æ§‹æˆ'
                }
                
                for section_key, content in key_sections.items():
                    if content.strip():
                        section_name = section_names.get(section_key, section_key)
                        result_lines.append(f"     â€¢ {section_name}: {content[:200]}...")
                
                # è©³ç´°å†…å®¹ãŒã‚ã‚‹å ´åˆã¯ãã®ä¸€éƒ¨ã‚‚è¡¨ç¤º
                if 'detailed_content' in result and result['detailed_content']:
                    detailed_preview = result['detailed_content'][:300] + "..."
                    result_lines.append(f"   ğŸ“– **è©³ç´°å†…å®¹æŠœç²‹**: {detailed_preview}")
            
            elif excerpt:
                # è©³ç´°åˆ†æãŒãªã„å ´åˆã¯å¾“æ¥ã®æŠœç²‹ã‚’è¡¨ç¤º
                excerpt_preview = excerpt[:150] + "..." if len(excerpt) > 150 else excerpt
                result_lines.append(f"   ğŸ“ å†…å®¹æŠœç²‹: {excerpt_preview}")
            
            # ãƒšãƒ¼ã‚¸ã¸ã®ãƒªãƒ³ã‚¯
            result_lines.append(f"   ğŸ”— ãƒªãƒ³ã‚¯: {page_url}")
            result_lines.append("")
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼å‡¦ç†ã®æ”¹å–„: resultã®å‹ãƒã‚§ãƒƒã‚¯
            if isinstance(result, dict):
                page_id = result.get('id', 'Unknown')
                if page_id == 'Unknown':
                    # contentã‹ã‚‰å–å¾—ã‚’è©¦è¡Œï¼ˆå®‰å…¨ãªå‹ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
                    content = result.get('content', {})
                    if isinstance(content, dict):
                        page_id = content.get('id', 'Unknown')
            else:
                page_id = f"Unknown (type: {type(result).__name__})"
            
            logger.warning(f"ãƒšãƒ¼ã‚¸ {page_id} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            # ãƒ‡ãƒãƒƒã‚°ç”¨: å®Ÿéš›ã®çµæœæ§‹é€ ã‚’ãƒ­ã‚°å‡ºåŠ›
            logger.debug(f"çµæœæ§‹é€  (type: {type(result).__name__}): {str(result)[:200]}...")
            continue
    
    # æ®‹ã‚Šã®ä»¶æ•°è¡¨ç¤º
    if total_count > 5:
        result_lines.append(f"ğŸ“Š ã•ã‚‰ã« {total_count - 5} ä»¶ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã™ã€‚")
        result_lines.append("")
    
    # è©³ç´°åˆ†æçµæœãŒã‚ã‚‹å ´åˆã¯ç·åˆåˆ†æã‚’è¿½åŠ 
    if analyze_content:
        result_lines.extend([
            "ğŸ¯ **åˆ†æçµæœã‚µãƒãƒªãƒ¼:**",
            _generate_analysis_summary(results, query),
            "",
            "ğŸ’¡ **æ¨å¥¨äº‹é …:**",
            _generate_recommendations(results, query),
            ""
        ])
    
    result_lines.append("ğŸ’¬ ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ãŒå¿…è¦ãªå ´åˆã¯ã€ä¸Šè¨˜ãƒªãƒ³ã‚¯ã‹ã‚‰å„ãƒšãƒ¼ã‚¸ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
    
    return "\n".join(result_lines)


def _generate_analysis_summary(results: List[Dict[str, Any]], query: str) -> str:
    """
    æ¤œç´¢çµæœã‹ã‚‰åˆ†æã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã™ã‚‹
    
    Args:
        results: æ¤œç´¢çµæœ
        query: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        
    Returns:
        str: åˆ†æã‚µãƒãƒªãƒ¼
    """
    sections_found = set()
    common_topics = []
    
    for result in results:
        if 'key_sections' in result:
            sections_found.update(result['key_sections'].keys())
            
    if 'specifications' in sections_found or 'requirements' in sections_found:
        common_topics.append("ä»•æ§˜ãƒ»è¦ä»¶ã«é–¢ã™ã‚‹æƒ…å ±")
    if 'security' in sections_found:
        common_topics.append("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»èªè¨¼ã«é–¢ã™ã‚‹è¨­è¨ˆ")
    if 'implementation' in sections_found:
        common_topics.append("å®Ÿè£…æ–¹æ³•ãƒ»æ‰‹é †")
    if 'best_practices' in sections_found:
        common_topics.append("ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãƒ»æ¨å¥¨äº‹é …")
    if 'architecture' in sections_found:
        common_topics.append("ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ»ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ")
    
    if common_topics:
        topics_text = "ã€".join(common_topics)
        return f"ã€Œ{query}ã€ã«é–¢é€£ã—ã¦ã€{topics_text}ãŒå«ã¾ã‚Œã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚"
    else:
        return f"ã€Œ{query}ã€ã«é–¢é€£ã™ã‚‹åŸºæœ¬çš„ãªæƒ…å ±ãŒå«ã¾ã‚Œã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚"


def _generate_recommendations(results: List[Dict[str, Any]], query: str) -> str:
    """
    æ¤œç´¢çµæœã‹ã‚‰æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆã™ã‚‹
    
    Args:
        results: æ¤œç´¢çµæœ
        query: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        
    Returns:
        str: æ¨å¥¨äº‹é …
    """
    recommendations = []
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ã®è³ªå•ã®å ´åˆ
    if any(keyword in query.lower() for keyword in ['ãƒ­ã‚°ã‚¤ãƒ³', 'login', 'èªè¨¼', 'auth', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£']):
        has_security_docs = any(
            'key_sections' in result and ('security' in result['key_sections'] or 'best_practices' in result['key_sections'])
            for result in results
        )
        if has_security_docs:
            recommendations.append("â€¢ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»èªè¨¼ã«é–¢ã™ã‚‹è¨­è¨ˆæ›¸ã‚’å„ªå…ˆçš„ã«ç¢ºèªã—ã¦ãã ã•ã„")
            recommendations.append("â€¢ ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®é …ç›®ãŒã‚ã‚Œã°å‚è€ƒã«ã—ã¦ãã ã•ã„")
        
        recommendations.append("â€¢ å®Ÿè£…å‰ã«è¦ä»¶å®šç¾©æ›¸ã§å¿…è¦ãªæ©Ÿèƒ½ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        recommendations.append("â€¢ æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æºæ–¹æ³•ã«ã¤ã„ã¦è¨­è¨ˆæ›¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
    
    # ä¸€èˆ¬çš„ãªæ¨å¥¨äº‹é …
    if not recommendations:
        recommendations.append("â€¢ æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰é †ã«ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™")
        recommendations.append("â€¢ å®Ÿè£…æ–¹æ³•ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ãã¡ã‚‰ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„")
    
    recommendations.append("â€¢ ä¸æ˜ãªç‚¹ãŒã‚ã‚Œã°ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆè€…ã«ç›´æ¥ãŠå•ã„åˆã‚ã›ãã ã•ã„")
    
    return "\n".join(recommendations)


def _clean_html_tags(text: str) -> str:
    """
    HTMLã‚¿ã‚°ã‚’é™¤å»ã—ã¦ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ã™ã‚‹ç°¡æ˜“é–¢æ•°
    
    Args:
        text: HTMLã‚’å«ã‚€å¯èƒ½æ€§ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        str: HTMLã‚¿ã‚°ã‚’é™¤å»ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    if not text:
        return ""
    
    import re
    
    # HTMLã‚¿ã‚°ã‚’é™¤å»
    text = re.sub(r'<[^>]+>', '', text)
    
    # HTMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
    html_entities = {
        '&lt;': '<',
        '&gt;': '>',
        '&amp;': '&',
        '&quot;': '"',
        '&#39;': "'",
        '&nbsp;': ' ',
    }
    
    for entity, char in html_entities.items():
        text = text.replace(entity, char)
    
    # ä½™åˆ†ãªç©ºç™½ã‚’æ•´ç†
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def search_confluence_with_filters(
    query: str,
    space_keys: Optional[List[str]] = None,
    content_type: Optional[str] = None,
    created_after: Optional[str] = None,
    created_before: Optional[str] = None
) -> str:
    """
    ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ä»˜ãã§Confluenceãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢ã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸçµæœã‚’è¿”ã™
    
    Args:
        query (str): æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        space_keys (Optional[List[str]]): ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã®ãƒªã‚¹ãƒˆ
        content_type (Optional[str]): ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ï¼ˆpage ã¾ãŸã¯ blogpostï¼‰
        created_after (Optional[str]): ä½œæˆæ—¥ä»¥é™ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
        created_before (Optional[str]): ä½œæˆæ—¥ä»¥å‰ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
        
    Returns:
        str: æ¤œç´¢çµæœã®ã‚µãƒãƒªãƒ¼ï¼ˆãƒšãƒ¼ã‚¸æƒ…å ±ã‚’æ•´å½¢ã—ãŸã‚‚ã®ï¼‰
    """
    if not query or not query.strip():
        return "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    
    try:
        # Confluenceæ¥ç¶šã®åˆæœŸåŒ–
        confluence = Confluence(
            url=f"https://{settings.atlassian_domain}",
            username=settings.atlassian_email,
            password=settings.atlassian_api_token
        )
        
        # CQLã‚¯ã‚¨ãƒªã®æ§‹ç¯‰
        # ã‚¯ã‚¨ãƒªã‹ã‚‰ä½™åˆ†ãªæ¼”ç®—å­ã‚„å¼•ç”¨ç¬¦ã‚’é™¤å»ã—ã¦åŸºæœ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿æŠ½å‡º
        clean_query = query.strip()
        if ' AND ' in clean_query or ' OR ' in clean_query:
            clean_query = clean_query.split(' AND ')[0].split(' OR ')[0]
        clean_query = clean_query.replace('"', '').strip()
        
        cql_parts = [f'text ~ "{clean_query}"']
        
        # ã‚¹ãƒšãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if space_keys:
            space_filter = " OR ".join([f'space = "{space_key}"' for space_key in space_keys])
            cql_parts.append(f"({space_filter})")
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if content_type and content_type in ['page', 'blogpost']:
            cql_parts.append(f'type = "{content_type}"')
        
        # ä½œæˆæ—¥ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if created_after:
            cql_parts.append(f'created >= "{created_after}"')
        if created_before:
            cql_parts.append(f'created <= "{created_before}"')
        
        cql_query = " AND ".join(cql_parts)
        
        logger.info(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ãConfluenceæ¤œç´¢å®Ÿè¡Œ: {cql_query}")
        
        # Confluenceæ¤œç´¢ã®å®Ÿè¡Œ
        search_result = confluence.cql(cql_query, limit=10)
        
        if not search_result or 'results' not in search_result:
            return f"Confluenceã§ã€Œ{query}ã€ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ä»˜ãï¼‰ã«é–¢ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        results = search_result['results']
        total_count = search_result.get('totalSize', 0)
        
        if total_count == 0:
            return f"Confluenceã§ã€Œ{query}ã€ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ä»˜ãï¼‰ã«é–¢ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        # çµæœã®æ•´å½¢ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‚‚å«ã‚ã‚‹ï¼‰
        result_summary = _format_confluence_results_with_filters(
            results, query, total_count,
            space_keys=space_keys,
            content_type=content_type,
            created_after=created_after,
            created_before=created_before
        )
        
        logger.info(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ãConfluenceæ¤œç´¢å®Œäº†: {len(results)}ä»¶ã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—")
        return result_summary
        
    except Exception as e:
        error_msg = f"Confluenceã®æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        logger.error(error_msg)
        return error_msg


def _format_confluence_results_with_filters(
    results: List[Dict[str, Any]], 
    query: str, 
    total_count: int,
    space_keys: Optional[List[str]] = None,
    content_type: Optional[str] = None,
    created_after: Optional[str] = None,
    created_before: Optional[str] = None
) -> str:
    """
    Confluenceãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¤œç´¢çµæœã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«æ•´å½¢ã™ã‚‹
    
    Args:
        results: Confluenceæ¤œç´¢çµæœã®resultsé…åˆ—
        query: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        total_count: ç·ä»¶æ•°
        space_keys: ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        content_type: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        created_after: ä½œæˆæ—¥ä»¥é™ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        created_before: ä½œæˆæ—¥ä»¥å‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        
    Returns:
        str: æ•´å½¢ã•ã‚ŒãŸæ¤œç´¢çµæœ
    """
    if not results:
        return f"Confluenceã§ã€Œ{query}ã€ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ä»˜ãï¼‰ã«é–¢ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†
    result_lines = [
        f"ã€Confluenceæ¤œç´¢çµæœï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ãï¼‰ã€‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ã€Œ{query}ã€",
        f"è¦‹ã¤ã‹ã£ãŸãƒšãƒ¼ã‚¸: {len(results)}ä»¶ï¼ˆç·æ•°: {total_count}ä»¶ï¼‰"
    ]
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã®è¡¨ç¤º
    filter_conditions = []
    if space_keys:
        filter_conditions.append(f"ã‚¹ãƒšãƒ¼ã‚¹: {', '.join(space_keys)}")
    if content_type:
        filter_conditions.append(f"ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—: {content_type}")
    if created_after or created_before:
        date_range = []
        if created_after:
            date_range.append(f"{created_after}ä»¥é™")
        if created_before:
            date_range.append(f"{created_before}ä»¥å‰")
        filter_conditions.append(f"ä½œæˆæ—¥: {', '.join(date_range)}")
    
    if filter_conditions:
        result_lines.append(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶: {' | '.join(filter_conditions)}")
    
    result_lines.append("")
    
    # å„ãƒšãƒ¼ã‚¸ã®è©³ç´°
    for i, result in enumerate(results[:5], 1):  # æœ€å¤§5ä»¶è¡¨ç¤º
        try:
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å¯¾å¿œã—ãŸå …ç‰¢ãªå–å¾—
            if isinstance(result, str):
                result_lines.append(f"{i}. ã€è§£æã‚¨ãƒ©ãƒ¼ã€‘çµæœã®æ§‹é€ ã‚’æ­£ã—ãå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                continue
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã®å–å¾—
            title = result.get('title') or result.get('content', {}).get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
            
            # ID ã¨ã‚¿ã‚¤ãƒ—ã®å–å¾—
            page_id = result.get('id') or result.get('content', {}).get('id', 'N/A')
            page_type = result.get('type') or result.get('content', {}).get('type', 'page')
            
            # ã‚¹ãƒšãƒ¼ã‚¹æƒ…å ±ã®å–å¾—
            space_info = result.get('space') or result.get('content', {}).get('space', {})
            if isinstance(space_info, dict):
                space_name = space_info.get('name', 'CLIENTTOMO')
                space_key = space_info.get('key', 'CLIENTTOMO')
            else:
                space_name = 'CLIENTTOMO'
                space_key = 'CLIENTTOMO'
            
            # ä½œæˆè€…ãƒ»ä½œæˆæ—¥æƒ…å ±ã®å–å¾—
            created_by = result.get('lastModified', {}).get('by', {}).get('displayName', 'ã‚·ã‚¹ãƒ†ãƒ ')
            created_date = result.get('lastModified', {}).get('when', 'ä¸æ˜')
            
            # URLã®ç”Ÿæˆ
            if page_id and page_id != 'N/A':
                page_url = f"https://{settings.atlassian_domain}/wiki/spaces/{space_key}/pages/{page_id}"
            else:
                page_url = f"https://{settings.atlassian_domain}/wiki/spaces/{space_key}"
            
            # æŠœç²‹ã‚„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—
            excerpt = result.get('excerpt', 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æŠœç²‹ã¯ã‚ã‚Šã¾ã›ã‚“')
            excerpt_cleaned = _clean_html_tags(excerpt)[:200]  # 200æ–‡å­—ã¾ã§
            
            result_lines.append(f"{i}. **{title}**")
            result_lines.append(f"   ğŸ“ ã‚¹ãƒšãƒ¼ã‚¹: {space_name} ({space_key}) | ã‚¿ã‚¤ãƒ—: {page_type}")
            result_lines.append(f"   ğŸ‘¤ ä½œæˆè€…: {created_by} | ä½œæˆæ—¥: {created_date}")
            result_lines.append(f"   ğŸ”— URL: {page_url}")
            
            if excerpt_cleaned:
                result_lines.append(f"   ğŸ“ æ¦‚è¦: {excerpt_cleaned}...")
            
            result_lines.append("")
            
        except Exception as e:
            logger.warning(f"çµæœ{i}ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            result_lines.append(f"{i}. ã€å‡¦ç†ã‚¨ãƒ©ãƒ¼ã€‘ã“ã®ãƒšãƒ¼ã‚¸ã®æƒ…å ±ã‚’æ­£ã—ãå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            result_lines.append("")
    
    # æ®‹ã‚Šã®ãƒšãƒ¼ã‚¸æ•°ã‚’è¡¨ç¤º
    if total_count > 5:
        result_lines.append(f"ğŸ“‹ ãã®ä»– {total_count - 5} ä»¶ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã™ã€‚")
        result_lines.append("")
    
    # åˆ©ç”¨ã®ãƒ’ãƒ³ãƒˆ
    result_lines.extend([
        "ğŸ’¡ **åˆ©ç”¨ã®ãƒ’ãƒ³ãƒˆ:**",
        "- ã€Œãã®ãƒšãƒ¼ã‚¸ã«ã¤ã„ã¦è©³ã—ãã€ã¨èãã¨ã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’å–å¾—ã§ãã¾ã™",
        "- ç‰¹å®šã®ãƒšãƒ¼ã‚¸ã®å†…å®¹ã«ã¤ã„ã¦è³ªå•ã§ãã¾ã™",
        "- é–¢é€£ã™ã‚‹ãƒšãƒ¼ã‚¸ã‚„é¡ä¼¼ã®ä»•æ§˜ã«ã¤ã„ã¦èãã“ã¨ã‚‚å¯èƒ½ã§ã™"
    ])
    
    return '\n'.join(result_lines)


def get_confluence_space_structure(space_key: str = "CLIENTTOMO") -> str:
    """
    æŒ‡å®šã•ã‚ŒãŸConfluenceã‚¹ãƒšãƒ¼ã‚¹ã®ãƒšãƒ¼ã‚¸æ§‹é€ ã‚’å–å¾—ã™ã‚‹
    
    Args:
        space_key (str): å¯¾è±¡ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: CLIENTTOMOï¼‰
        
    Returns:
        str: ã‚¹ãƒšãƒ¼ã‚¹ã®ãƒšãƒ¼ã‚¸æ§‹é€ æƒ…å ±
    """
    try:
        # Confluenceæ¥ç¶šã®åˆæœŸåŒ–
        confluence = Confluence(
            url=f"https://{settings.atlassian_domain}",
            username=settings.atlassian_email,
            password=settings.atlassian_api_token
        )
        
        logger.info(f"Confluenceã‚¹ãƒšãƒ¼ã‚¹æ§‹é€ å–å¾—é–‹å§‹: {space_key}")
        
        # ã‚¹ãƒšãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—
        try:
            space_info = confluence.get_space(space_key, expand='description,homepage')
        except Exception as e:
            logger.error(f"ã‚¹ãƒšãƒ¼ã‚¹æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return f"ã‚¹ãƒšãƒ¼ã‚¹ '{space_key}' ã®æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {str(e)}"
        
        # ãƒšãƒ¼ã‚¸ä¸€è¦§ã‚’å–å¾—ï¼ˆéšå±¤æ§‹é€ ã‚‚å«ã‚€ï¼‰
        try:
            # ã™ã¹ã¦ã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
            all_pages = []
            start = 0
            limit = 50
            
            while True:
                pages_result = confluence.get_all_pages_from_space(
                    space_key, 
                    start=start, 
                    limit=limit,
                    expand='ancestors,children.page,history.lastUpdated,version,space'
                )
                
                if not pages_result:
                    break
                    
                all_pages.extend(pages_result)
                
                # å–å¾—ä»¶æ•°ãŒlimitã‚ˆã‚Šå°‘ãªã„å ´åˆã¯æœ€å¾Œã®ãƒšãƒ¼ã‚¸
                if len(pages_result) < limit:
                    break
                    
                start += limit
                
                # å®‰å…¨ã®ãŸã‚æœ€å¤§500ãƒšãƒ¼ã‚¸ã¾ã§
                if len(all_pages) >= 500:
                    logger.warning(f"ãƒšãƒ¼ã‚¸æ•°ãŒ500ä»¶ã‚’è¶…ãˆãŸãŸã‚å–å¾—ã‚’åˆ¶é™ã—ã¾ã—ãŸ")
                    break
        
        except Exception as e:
            logger.error(f"ãƒšãƒ¼ã‚¸ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return f"ã‚¹ãƒšãƒ¼ã‚¹ '{space_key}' ã®ãƒšãƒ¼ã‚¸ä¸€è¦§ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {str(e)}"
        
        # çµæœã®æ•´å½¢
        result_lines = [
            f"ã€Confluenceã‚¹ãƒšãƒ¼ã‚¹æ§‹é€ ã€‘ã‚¹ãƒšãƒ¼ã‚¹: {space_key}",
            f"ã‚¹ãƒšãƒ¼ã‚¹å: {space_info.get('name', 'N/A')}",
            f"ç·ãƒšãƒ¼ã‚¸æ•°: {len(all_pages)}ä»¶",
            ""
        ]
        
        # ã‚¹ãƒšãƒ¼ã‚¹ã®èª¬æ˜ãŒã‚ã‚Œã°è¡¨ç¤º
        if space_info.get('description'):
            description = space_info['description'].get('plain', {}).get('value', '')
            if description:
                cleaned_desc = _clean_html_tags(description)[:200]
                result_lines.append(f"ã‚¹ãƒšãƒ¼ã‚¹èª¬æ˜: {cleaned_desc}")
                result_lines.append("")
        
        # ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸æƒ…å ±
        homepage = space_info.get('homepage')
        if homepage:
            homepage_title = homepage.get('title', 'N/A')
            homepage_id = homepage.get('id', 'N/A')
            result_lines.append(f"ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸: {homepage_title} (ID: {homepage_id})")
            result_lines.append("")
        
        # ãƒšãƒ¼ã‚¸ã‚’éšå±¤æ§‹é€ ã§æ•´ç†
        page_hierarchy = _build_page_hierarchy(all_pages)
        
        # éšå±¤æ§‹é€ ã‚’è¡¨ç¤º
        result_lines.append("ğŸ“ **ãƒšãƒ¼ã‚¸éšå±¤æ§‹é€ :**")
        result_lines.append("")
        
        for root_page in page_hierarchy['roots']:
            _append_page_tree(result_lines, root_page, page_hierarchy['children'], 0)
        
        # è¦ªã‚’æŒãŸãªã„ãƒšãƒ¼ã‚¸ï¼ˆãƒ«ãƒ¼ãƒˆãƒšãƒ¼ã‚¸ä»¥å¤–ï¼‰ãŒã‚ã‚Œã°è¡¨ç¤º
        orphaned_pages = page_hierarchy['orphaned']
        if orphaned_pages:
            result_lines.append("")
            result_lines.append("ğŸ“„ **ãã®ä»–ã®ãƒšãƒ¼ã‚¸ï¼ˆè¦ªãƒšãƒ¼ã‚¸ãªã—ï¼‰:**")
            result_lines.append("")
            for page in orphaned_pages[:10]:  # æœ€å¤§10ä»¶
                title = page.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
                page_id = page.get('id', 'N/A')
                page_type = page.get('type', 'page')
                last_updated = _get_last_updated(page)
                result_lines.append(f"- {title} ({page_type}) | æ›´æ–°: {last_updated}")
            
            if len(orphaned_pages) > 10:
                result_lines.append(f"  ... ä»– {len(orphaned_pages) - 10} ä»¶")
        
        # çµ±è¨ˆæƒ…å ±
        result_lines.append("")
        result_lines.append("ğŸ“Š **çµ±è¨ˆæƒ…å ±:**")
        page_types = {}
        recent_updates = []
        
        for page in all_pages:
            page_type = page.get('type', 'page')
            page_types[page_type] = page_types.get(page_type, 0) + 1
            
            last_updated = _get_last_updated_date(page)
            if last_updated:
                recent_updates.append((page.get('title', 'N/A'), last_updated))
        
        # ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—åˆ¥ä»¶æ•°
        for page_type, count in sorted(page_types.items()):
            result_lines.append(f"- {page_type}: {count}ä»¶")
        
        # æœ€è¿‘æ›´æ–°ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ï¼ˆä¸Šä½5ä»¶ï¼‰
        if recent_updates:
            recent_updates.sort(key=lambda x: x[1], reverse=True)
            result_lines.append("")
            result_lines.append("ğŸ•’ **æœ€è¿‘æ›´æ–°ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ï¼ˆä¸Šä½5ä»¶ï¼‰:**")
            for title, update_date in recent_updates[:5]:
                result_lines.append(f"- {title} | {update_date}")
        
        logger.info(f"Confluenceã‚¹ãƒšãƒ¼ã‚¹æ§‹é€ å–å¾—å®Œäº†: {len(all_pages)}ãƒšãƒ¼ã‚¸")
        return '\n'.join(result_lines)
        
    except Exception as e:
        logger.error(f"Confluenceã‚¹ãƒšãƒ¼ã‚¹æ§‹é€ å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return f"ã‚¹ãƒšãƒ¼ã‚¹æ§‹é€ ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"


def _build_page_hierarchy(pages: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ãƒšãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‹ã‚‰éšå±¤æ§‹é€ ã‚’æ§‹ç¯‰ã™ã‚‹
    
    Args:
        pages: ãƒšãƒ¼ã‚¸æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        
    Returns:
        Dict: éšå±¤æ§‹é€ æƒ…å ±ï¼ˆroots, children, orphanedï¼‰
    """
    # ãƒšãƒ¼ã‚¸IDã‚’ã‚­ãƒ¼ã¨ã—ãŸè¾æ›¸ã‚’ä½œæˆ
    pages_by_id = {page['id']: page for page in pages}
    
    # å„ãƒšãƒ¼ã‚¸ã®å­ãƒšãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’åˆæœŸåŒ–
    children = {page_id: [] for page_id in pages_by_id.keys()}
    
    # ãƒ«ãƒ¼ãƒˆãƒšãƒ¼ã‚¸ã¨å­¤ç«‹ãƒšãƒ¼ã‚¸ã‚’åˆ†é¡
    roots = []
    orphaned = []
    
    for page in pages:
        page_id = page['id']
        ancestors = page.get('ancestors', [])
        
        if not ancestors:
            # ç¥–å…ˆãŒãªã„ = ãƒ«ãƒ¼ãƒˆãƒšãƒ¼ã‚¸
            roots.append(page)
        elif ancestors:
            # æœ€ã‚‚è¿‘ã„ç¥–å…ˆï¼ˆç›´æ¥ã®è¦ªï¼‰ã‚’å–å¾—
            direct_parent = ancestors[-1] if ancestors else None
            if direct_parent and direct_parent['id'] in pages_by_id:
                parent_id = direct_parent['id']
                children[parent_id].append(page)
            else:
                # è¦ªãƒšãƒ¼ã‚¸ãŒã‚¹ãƒšãƒ¼ã‚¹å†…ã«å­˜åœ¨ã—ãªã„
                orphaned.append(page)
    
    return {
        'roots': roots,
        'children': children,
        'orphaned': orphaned
    }


def _append_page_tree(result_lines: List[str], page: Dict[str, Any], children_dict: Dict[str, List], depth: int):
    """
    ãƒšãƒ¼ã‚¸ãƒ„ãƒªãƒ¼ã‚’å†å¸°çš„ã«æ–‡å­—åˆ—ãƒªã‚¹ãƒˆã«è¿½åŠ ã™ã‚‹
    
    Args:
        result_lines: çµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
        page: ç¾åœ¨ã®ãƒšãƒ¼ã‚¸æƒ…å ±
        children_dict: å­ãƒšãƒ¼ã‚¸è¾æ›¸
        depth: ç¾åœ¨ã®éšå±¤ã®æ·±ã•
    """
    # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ
    indent = "  " * depth
    icon = "ğŸ“" if children_dict.get(page['id']) else "ğŸ“„"
    
    title = page.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
    page_id = page.get('id', 'N/A')
    page_type = page.get('type', 'page')
    last_updated = _get_last_updated(page)
    
    result_lines.append(f"{indent}{icon} {title} ({page_type}) | æ›´æ–°: {last_updated}")
    
    # å­ãƒšãƒ¼ã‚¸ã‚’å†å¸°çš„ã«è¡¨ç¤ºï¼ˆæœ€å¤§æ·±åº¦5ã¾ã§ï¼‰
    if depth < 5:
        child_pages = children_dict.get(page['id'], [])
        for child_page in sorted(child_pages, key=lambda x: x.get('title', '')):
            _append_page_tree(result_lines, child_page, children_dict, depth + 1)
    elif children_dict.get(page['id']):
        # æ·±åº¦åˆ¶é™ã«ã‚ˆã‚Šçœç•¥
        result_lines.append(f"{indent}  ğŸ“ ... (å­ãƒšãƒ¼ã‚¸ {len(children_dict[page['id']])}ä»¶ - éšå±¤æ·±åº¦åˆ¶é™ã«ã‚ˆã‚Šçœç•¥)")


def _get_last_updated(page: Dict[str, Any]) -> str:
    """
    ãƒšãƒ¼ã‚¸ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’å–å¾—ã™ã‚‹
    
    Args:
        page: ãƒšãƒ¼ã‚¸æƒ…å ±
        
    Returns:
        str: æœ€çµ‚æ›´æ–°æ—¥æ™‚ã®æ–‡å­—åˆ—
    """
    try:
        # è¤‡æ•°ã®ãƒ‘ã‚¹ã‚’è©¦è¡Œ
        paths = [
            page.get('history', {}).get('lastUpdated', {}).get('when'),
            page.get('version', {}).get('when'),
            page.get('lastModified', {}).get('when')
        ]
        
        for date_str in paths:
            if date_str:
                # ISOå½¢å¼ã®æ—¥ä»˜ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
                from datetime import datetime
                try:
                    dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                    return dt.strftime('%Y-%m-%d %H:%M')
                except:
                    return date_str[:10]  # æ—¥ä»˜éƒ¨åˆ†ã®ã¿
        
        return 'ä¸æ˜'
    except:
        return 'ä¸æ˜'


def _get_last_updated_date(page: Dict[str, Any]) -> str:
    """
    ã‚½ãƒ¼ãƒˆç”¨ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’å–å¾—ã™ã‚‹
    
    Args:
        page: ãƒšãƒ¼ã‚¸æƒ…å ±
        
    Returns:
        str: ISOå½¢å¼ã®æ—¥æ™‚æ–‡å­—åˆ—ï¼ˆã‚½ãƒ¼ãƒˆå¯èƒ½ï¼‰
    """
    try:
        paths = [
            page.get('history', {}).get('lastUpdated', {}).get('when'),
            page.get('version', {}).get('when'),
            page.get('lastModified', {}).get('when')
        ]
        
        for date_str in paths:
            if date_str:
                return date_str
        
        return ''
    except:
        return ''


def get_confluence_page_hierarchy(space_key: str = "CLIENTTOMO") -> Dict[str, Any]:
    """
    Confluenceã‚¹ãƒšãƒ¼ã‚¹ã®éšå±¤æ§‹é€ ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å–å¾—ã™ã‚‹
    
    Args:
        space_key (str): å¯¾è±¡ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼
        
    Returns:
        Dict[str, Any]: éšå±¤æ§‹é€ ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç”¨ï¼‰
    """
    try:
        # Confluenceæ¥ç¶šã®åˆæœŸåŒ–
        confluence = Confluence(
            url=f"https://{settings.atlassian_domain}",
            username=settings.atlassian_email,
            password=settings.atlassian_api_token
        )
        
        logger.info(f"Confluenceãƒšãƒ¼ã‚¸éšå±¤å–å¾—é–‹å§‹: {space_key}")
        
        # æœ€åˆã®20ãƒšãƒ¼ã‚¸ç¨‹åº¦ã‚’å–å¾—ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç”¨ãªã®ã§è»½é‡åŒ–ï¼‰
        pages_result = confluence.get_all_pages_from_space(
            space_key, 
            start=0, 
            limit=20,
            expand='ancestors,space'  # children.pageã‚’é™¤å¤–ã—ã¦è»½é‡åŒ–
        )
        
        if not pages_result:
            return {'folders': [], 'error': 'ãƒšãƒ¼ã‚¸ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ'}
        
        # éšå±¤æ§‹é€ ã‚’åˆ†æ
        folders = set()
        parent_child_map = {}
        
        for page in pages_result:
            title = page.get('title', '')
            page_id = page.get('id', '')
            ancestors = page.get('ancestors', [])
            
            # ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç‰¹å®š
            if not ancestors:
                # ãƒ«ãƒ¼ãƒˆãƒšãƒ¼ã‚¸
                folders.add(title)
                parent_child_map[title] = {'id': page_id, 'children': set(), 'level': 0}
            elif len(ancestors) == 1:
                # ãƒ¬ãƒ™ãƒ«1ãƒ•ã‚©ãƒ«ãƒ€
                parent_title = ancestors[0].get('title', '')
                folders.add(parent_title)
                folders.add(title)
                
                if parent_title not in parent_child_map:
                    parent_child_map[parent_title] = {'id': ancestors[0].get('id', ''), 'children': set(), 'level': 0}
                if title not in parent_child_map:
                    parent_child_map[title] = {'id': page_id, 'children': set(), 'level': 1}
                
                parent_child_map[parent_title]['children'].add(title)
            elif len(ancestors) >= 2:
                # ãƒ¬ãƒ™ãƒ«2ä»¥ä¸Šã®ãƒ•ã‚©ãƒ«ãƒ€
                for i, ancestor in enumerate(ancestors):
                    ancestor_title = ancestor.get('title', '')
                    folders.add(ancestor_title)
                    
                    if ancestor_title not in parent_child_map:
                        parent_child_map[ancestor_title] = {
                            'id': ancestor.get('id', ''), 
                            'children': set(), 
                            'level': i
                        }
                
                # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã‚‚è¿½åŠ 
                folders.add(title)
                if title not in parent_child_map:
                    parent_child_map[title] = {'id': page_id, 'children': set(), 'level': len(ancestors)}
                
                # è¦ªå­é–¢ä¿‚ã‚’è¨­å®š
                if ancestors:
                    parent_title = ancestors[-1].get('title', '')
                    if parent_title in parent_child_map:
                        parent_child_map[parent_title]['children'].add(title)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç”¨ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        filter_hierarchy = []
        
        # ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç‰¹å®š
        root_folders = [folder for folder, data in parent_child_map.items() if data['level'] == 0]
        
        for root_folder in sorted(root_folders):
            if root_folder in parent_child_map:
                folder_data = {
                    'name': root_folder,
                    'id': parent_child_map[root_folder]['id'],
                    'level': 0,
                    'children': []
                }
                
                # å­ãƒ•ã‚©ãƒ«ãƒ€ã‚’è¿½åŠ ï¼ˆãƒ¬ãƒ™ãƒ«1ï¼‰
                level1_children = [child for child in parent_child_map[root_folder]['children']]
                for child in sorted(level1_children):
                    if child in parent_child_map:
                        child_data = {
                            'name': child,
                            'id': parent_child_map[child]['id'],
                            'level': 1,
                            'children': []
                        }
                        
                        # å­ã®å­ãƒ•ã‚©ãƒ«ãƒ€ã‚’è¿½åŠ ï¼ˆãƒ¬ãƒ™ãƒ«2ï¼‰
                        level2_children = [grandchild for grandchild in parent_child_map[child]['children']]
                        for grandchild in sorted(level2_children):
                            if grandchild in parent_child_map:
                                grandchild_data = {
                                    'name': grandchild,
                                    'id': parent_child_map[grandchild]['id'],
                                    'level': 2,
                                    'children': []
                                }
                                child_data['children'].append(grandchild_data)
                        
                        folder_data['children'].append(child_data)
                
                filter_hierarchy.append(folder_data)
        
        logger.info(f"Confluenceãƒšãƒ¼ã‚¸éšå±¤å–å¾—å®Œäº†: {len(filter_hierarchy)}å€‹ã®ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€")
        return {
            'folders': filter_hierarchy,
            'total_folders': len(folders),
            'space_key': space_key
        }
        
    except Exception as e:
        logger.error(f"Confluenceãƒšãƒ¼ã‚¸éšå±¤å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {
            'folders': [],
            'error': str(e),
            'space_key': space_key
        }


def get_confluence_filter_options() -> Dict[str, Any]:
    """
    Confluence APIã‹ã‚‰ç¾åœ¨åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é …ç›®ã‚’å–å¾—ã™ã‚‹
    
    Returns:
        Dict[str, Any]: ã‚¹ãƒšãƒ¼ã‚¹ä¸€è¦§ã€ä½œæˆè€…ä¸€è¦§ãªã©ã®æƒ…å ±
    """
    cache_key = "confluence_filter_options"
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã‚’è©¦è¡Œï¼ˆ1æ™‚é–“æœ‰åŠ¹ï¼‰
    try:
        cached_options = cache_manager.get(cache_key)
        if cached_options:
            logger.info("Confluenceãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é …ç›®ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—")
            return cached_options
    except Exception as e:
        logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼ (ã‚­ãƒ¼ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™): {str(e)}")
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒç ´æã—ã¦ã„ã‚‹å ´åˆã¯ã‚¯ãƒªã‚¢ã—ã¦ç¶™ç¶š
        try:
            cache_manager.delete(cache_key)
        except:
            pass
    
    try:
        # Confluenceæ¥ç¶šã®åˆæœŸåŒ–
        confluence = Confluence(
            url=f"https://{settings.atlassian_domain}",
            username=settings.atlassian_email,
            password=settings.atlassian_api_token
        )
        
        logger.info("Confluence APIã‹ã‚‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é …ç›®ã‚’å–å¾—ä¸­...")
        
        # å„ç¨®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é …ç›®ã‚’å–å¾—
        filter_options = {
            'spaces': _get_confluence_spaces(confluence),
            'content_types': ['page', 'blogpost'],  # å›ºå®šå€¤
            'authors': _get_confluence_authors(confluence)
        }
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ï¼ˆ1æ™‚é–“æœ‰åŠ¹ï¼‰
        try:
            cache_manager.set(cache_key, filter_options, duration_hours=1)
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        logger.info("Confluenceãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é …ç›®ã®å–å¾—å®Œäº†")
        return filter_options
        
    except Exception as e:
        logger.error(f"Confluenceãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é …ç›®å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
        return {
            'spaces': ['CLIENTTOMO'],  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ãƒšãƒ¼ã‚¹
            'content_types': ['page', 'blogpost'],
            'authors': []
        }


def _get_confluence_spaces(confluence: Confluence) -> List[str]:
    """
    Confluenceã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªã‚¹ãƒšãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ã™ã‚‹
    
    Args:
        confluence: Confluence APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        
    Returns:
        List[str]: ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã®ãƒªã‚¹ãƒˆ
    """
    try:
        spaces = confluence.get_all_spaces()
        space_keys = [space.get('key', '') for space in spaces.get('results', [])]
        # ç©ºæ–‡å­—åˆ—ã‚’é™¤å¤–
        space_keys = [key for key in space_keys if key]
        logger.info(f"Confluenceã‚¹ãƒšãƒ¼ã‚¹å–å¾—: {len(space_keys)}å€‹")
        return space_keys
    except Exception as e:
        logger.warning(f"Confluenceã‚¹ãƒšãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return ['CLIENTTOMO']  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ãƒšãƒ¼ã‚¹


def _get_confluence_authors(confluence: Confluence) -> List[str]:
    """
    Confluenceãƒšãƒ¼ã‚¸ã®ä½œæˆè€…ä¸€è¦§ã‚’å–å¾—ã™ã‚‹ï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒšãƒ¼ã‚¸ã‹ã‚‰ï¼‰
    
    Args:
        confluence: Confluence APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        
    Returns:
        List[str]: ä½œæˆè€…ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã®ãƒªã‚¹ãƒˆ
    """
    try:
        # æœ€è¿‘ã®ãƒšãƒ¼ã‚¸ã‹ã‚‰ä½œæˆè€…ã‚’åé›†ï¼ˆåˆ¶é™ã‚ã‚Šï¼‰
        cql_query = 'type = page order by created desc'
        search_result = confluence.cql(cql_query, limit=50)
        
        authors = set()
        if search_result and 'results' in search_result:
            for page in search_result['results']:
                creator = page.get('creator', {})
                if creator:
                    # displayNameã¾ãŸã¯accountIdã‚’ä½¿ç”¨
                    author_name = creator.get('displayName') or creator.get('accountId', '')
                    if author_name:
                        authors.add(author_name)
        
        author_list = list(authors)
        logger.info(f"Confluenceä½œæˆè€…å–å¾—: {len(author_list)}äºº")
        return author_list[:20]  # æœ€å¤§20äººã¾ã§
        
    except Exception as e:
        logger.warning(f"Confluenceä½œæˆè€…å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []