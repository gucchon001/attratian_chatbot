"""
Confluence é«˜ç²¾åº¦CQLæ¤œç´¢ãƒ„ãƒ¼ãƒ«

æ ¹æœ¬çš„ãªæ¤œç´¢ç²¾åº¦å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€è¤‡æ•°ã®CQLæˆ¦ç•¥ã‚’çµ„ã¿åˆã‚ã›ãŸæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã€‚
ã‚¿ã‚¤ãƒˆãƒ«å„ªå…ˆã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†å‰²ã€æ®µéšçš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ã‚’å®Ÿè£…ã€‚
"""

import logging
import time
import re
from typing import List, Dict, Any, Optional, Tuple
from atlassian import Confluence

from ..config.settings import settings
from ..utils.log_config import get_logger

logger = get_logger(__name__)


class ConfluenceEnhancedCQLSearch:
    """
    Confluenceé«˜ç²¾åº¦CQLæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
    
    æ¤œç´¢ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®è¤‡æ•°æˆ¦ç•¥:
    1. ã‚¿ã‚¤ãƒˆãƒ«å„ªå…ˆæ¤œç´¢ (title ~)
    2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†å‰²æ¤œç´¢ (AND/ORçµ„ã¿åˆã‚ã›)
    3. å®Œå…¨ãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œç´¢ (text ~)
    4. éƒ¨åˆ†ä¸€è‡´æ¤œç´¢ (å«ã‚€ã€é¡ä¼¼èª)
    5. æ®µéšçš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥
    """
    
    def __init__(self):
        """CQLæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        self.confluence = self._initialize_confluence()
        self.space_key = settings.confluence_space or "CLIENTTOMO"
        logger.info("ConfluenceEnhancedCQLSearchåˆæœŸåŒ–å®Œäº†")
    
    def _initialize_confluence(self) -> Confluence:
        """Confluenceæ¥ç¶šã®åˆæœŸåŒ–"""
        return Confluence(
            url=f"https://{settings.atlassian_domain}",
            username=settings.atlassian_email,
            password=settings.atlassian_api_token
        )
    
    def search_with_enhanced_cql(self, query: str, max_results: int = 20) -> Dict[str, Any]:
        """
        é«˜ç²¾åº¦CQLæ¤œç´¢ã®å®Ÿè¡Œ
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            max_results: æœ€å¤§çµæœæ•°
            
        Returns:
            æ¤œç´¢çµæœã¨è©³ç´°ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        logger.info(f"é«˜ç²¾åº¦CQLæ¤œç´¢é–‹å§‹: '{query}'")
        start_time = time.time()
        
        try:
            # æ®µéšçš„æ¤œç´¢æˆ¦ç•¥ã®å®Ÿè¡Œ
            all_results = []
            search_strategies = [
                self._strategy_1_title_priority,
                self._strategy_2_keyword_split,
                self._strategy_3_phrase_search,
                self._strategy_4_partial_match,
                self._strategy_5_fallback_broad
            ]
            
            unique_page_ids = set()
            strategy_results = {}
            
            for i, strategy in enumerate(search_strategies, 1):
                strategy_name = strategy.__name__.replace('_strategy_', 'Strategy').replace('_', '')
                logger.info(f"å®Ÿè¡Œä¸­: {strategy_name}")
                
                try:
                    results = strategy(query, max_results // len(search_strategies))
                    if results:
                        new_results = []
                        for result in results:
                            page_id = result.get('content', {}).get('id') or result.get('id')
                            if page_id and page_id not in unique_page_ids:
                                unique_page_ids.add(page_id)
                                result['search_strategy'] = strategy_name
                                new_results.append(result)
                        
                        all_results.extend(new_results)
                        strategy_results[strategy_name] = len(new_results)
                        logger.info(f"{strategy_name}: {len(new_results)}ä»¶ã®æ–°è¦çµæœ")
                    
                    # ååˆ†ãªçµæœãŒå¾—ã‚‰ã‚ŒãŸã‚‰æ—©æœŸçµ‚äº†
                    if len(all_results) >= max_results:
                        logger.info(f"ååˆ†ãªçµæœæ•°({len(all_results)})ã«é”ã—ãŸãŸã‚æ¤œç´¢çµ‚äº†")
                        break
                        
                except Exception as e:
                    logger.warning(f"{strategy_name}ã§ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            # çµæœã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨é †ä½ä»˜ã‘
            scored_results = self._score_and_rank_results(all_results, query)
            
            execution_time = time.time() - start_time
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
            metadata = {
                'total_results': len(scored_results),
                'unique_pages': len(unique_page_ids),
                'execution_time': execution_time,
                'strategies_used': strategy_results,
                'query': query
            }
            
            logger.info(f"é«˜ç²¾åº¦CQLæ¤œç´¢å®Œäº†: {len(scored_results)}ä»¶ | å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
            
            return {
                'results': scored_results[:max_results],
                'metadata': metadata
            }
            
        except Exception as e:
            logger.error(f"é«˜ç²¾åº¦CQLæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'results': [], 'metadata': {'error': str(e)}}
    
    def _strategy_1_title_priority(self, query: str, limit: int) -> List[Dict[str, Any]]:
        """æˆ¦ç•¥1: ã‚¿ã‚¤ãƒˆãƒ«å„ªå…ˆæ¤œç´¢"""
        try:
            # ã‚¿ã‚¤ãƒˆãƒ«ã§ã®å®Œå…¨ä¸€è‡´æ¤œç´¢
            cql = f'title ~ "{query}" and space = "{self.space_key}"'
            results = self._execute_cql(cql, limit)
            
            if not results:
                # ã‚¿ã‚¤ãƒˆãƒ«ã§ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†å‰²æ¤œç´¢
                keywords = self._extract_keywords(query)
                if len(keywords) > 1:
                    keyword_conditions = ' AND '.join([f'title ~ "{kw}"' for kw in keywords])
                    cql = f'({keyword_conditions}) and space = "{self.space_key}"'
                    results = self._execute_cql(cql, limit)
            
            return results
            
        except Exception as e:
            logger.warning(f"ã‚¿ã‚¤ãƒˆãƒ«å„ªå…ˆæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _strategy_2_keyword_split(self, query: str, limit: int) -> List[Dict[str, Any]]:
        """æˆ¦ç•¥2: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†å‰²æ¤œç´¢"""
        try:
            keywords = self._extract_keywords(query)
            if len(keywords) < 2:
                return []
            
            # ANDæ¤œç´¢ï¼ˆå³å¯†ï¼‰
            and_conditions = ' AND '.join([f'text ~ "{kw}"' for kw in keywords])
            cql = f'({and_conditions}) and space = "{self.space_key}"'
            results = self._execute_cql(cql, limit // 2)
            
            # ORæ¤œç´¢ï¼ˆåºƒç¯„å›²ï¼‰- æ®‹ã‚Šã®æ ã§å®Ÿè¡Œ
            if len(results) < limit:
                or_conditions = ' OR '.join([f'text ~ "{kw}"' for kw in keywords])
                cql = f'({or_conditions}) and space = "{self.space_key}"'
                or_results = self._execute_cql(cql, limit - len(results))
                
                # é‡è¤‡é™¤å»
                existing_ids = {r.get('content', {}).get('id') or r.get('id') for r in results}
                for result in or_results:
                    result_id = result.get('content', {}).get('id') or result.get('id')
                    if result_id not in existing_ids:
                        results.append(result)
            
            return results
            
        except Exception as e:
            logger.warning(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†å‰²æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _strategy_3_phrase_search(self, query: str, limit: int) -> List[Dict[str, Any]]:
        """æˆ¦ç•¥3: å®Œå…¨ãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œç´¢"""
        try:
            # å¾“æ¥ã®å®Œå…¨ãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œç´¢
            cql = f'text ~ "{query}" and space = "{self.space_key}"'
            return self._execute_cql(cql, limit)
            
        except Exception as e:
            logger.warning(f"å®Œå…¨ãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _strategy_4_partial_match(self, query: str, limit: int) -> List[Dict[str, Any]]:
        """æˆ¦ç•¥4: éƒ¨åˆ†ä¸€è‡´æ¤œç´¢"""
        try:
            keywords = self._extract_keywords(query)
            results = []
            
            # å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®éƒ¨åˆ†æ–‡å­—åˆ—æ¤œç´¢
            for keyword in keywords:
                if len(keyword) >= 3:  # 3æ–‡å­—ä»¥ä¸Šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿
                    # éƒ¨åˆ†æ–‡å­—åˆ—ã®ç”Ÿæˆ
                    substrings = self._generate_substrings(keyword)
                    for substring in substrings:
                        if len(substring) >= 2:
                            cql = f'text ~ "{substring}" and space = "{self.space_key}"'
                            partial_results = self._execute_cql(cql, max(1, limit // len(keywords) // len(substrings)))
                            results.extend(partial_results)
                            
                            if len(results) >= limit:
                                break
                    
                    if len(results) >= limit:
                        break
            
            return results[:limit]
            
        except Exception as e:
            logger.warning(f"éƒ¨åˆ†ä¸€è‡´æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _strategy_5_fallback_broad(self, query: str, limit: int) -> List[Dict[str, Any]]:
        """æˆ¦ç•¥5: å¹…åºƒã„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢"""
        try:
            results = []
            
            # é¡ä¼¼èªã®æ¤œç´¢
            related_terms = self._generate_related_terms(query)
            for term in related_terms:
                cql = f'text ~ "{term}" and space = "{self.space_key}"'
                term_results = self._execute_cql(cql, max(1, limit // len(related_terms)))
                results.extend(term_results)
                
                if len(results) >= limit:
                    break
            
            # æœ€å¾Œã®æ‰‹æ®µï¼šã‚¹ãƒšãƒ¼ã‚¹å†…ã®æœ€è¿‘æ›´æ–°ã•ã‚ŒãŸãƒšãƒ¼ã‚¸
            if not results:
                cql = f'space = "{self.space_key}" order by lastModified desc'
                results = self._execute_cql(cql, min(5, limit))
                logger.info("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€è¿‘æ›´æ–°ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‚’è¿”å´")
            
            return results[:limit]
            
        except Exception as e:
            logger.warning(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _execute_cql(self, cql: str, limit: int) -> List[Dict[str, Any]]:
        """CQLã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ"""
        try:
            logger.debug(f"CQLå®Ÿè¡Œ: {cql}")
            search_result = self.confluence.cql(cql, limit=limit)
            
            if search_result and 'results' in search_result:
                return search_result['results']
            return []
            
        except Exception as e:
            logger.warning(f"CQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼ ({cql[:50]}...): {e}")
            return []
    
    def _extract_keywords(self, query: str) -> List[str]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
        # åŸºæœ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
        # ãƒã‚¤ã‚ºãƒ¯ãƒ¼ãƒ‰ã®é™¤å»
        noise_words = {'ã®', 'ã«ã¤ã„ã¦', 'ã«é–¢ã—ã¦', 'ä»•æ§˜', 'è©³ç´°', 'æƒ…å ±', 'æ•™ãˆã¦', 'ã‚’', 'ãŒ', 'ã¯', 'ã§', 'ã‹ã‚‰', 'ã¾ã§'}
        
        # ã‚¹ãƒšãƒ¼ã‚¹ã¨å¥èª­ç‚¹ã§åˆ†å‰²
        words = re.split(r'[\sã€€ã€ã€‚ï¼Œï¼ãƒ»]+', query.strip())
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        keywords = []
        for word in words:
            word = word.strip()
            if word and len(word) >= 2 and word not in noise_words:
                keywords.append(word)
        
        return keywords[:5]  # æœ€å¤§5å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    
    def _generate_substrings(self, keyword: str) -> List[str]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®éƒ¨åˆ†æ–‡å­—åˆ—ç”Ÿæˆ"""
        substrings = []
        
        # é•·ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å ´åˆã€éƒ¨åˆ†æ–‡å­—åˆ—ã‚’ç”Ÿæˆ
        if len(keyword) >= 4:
            # å‰åŠã€å¾ŒåŠã®éƒ¨åˆ†æ–‡å­—åˆ—
            mid = len(keyword) // 2
            substrings.append(keyword[:mid+1])  # å‰åŠ+1æ–‡å­—
            substrings.append(keyword[mid-1:])  # å¾ŒåŠ+1æ–‡å­—
        
        # éƒ¨åˆ†èªå¹¹ã®æŠ½å‡ºï¼ˆæ—¥æœ¬èªã®èªå¹¹ï¼‰
        if len(keyword) >= 3:
            substrings.append(keyword[:-1])  # æœ€å¾Œã®1æ–‡å­—ã‚’é™¤å»
            if len(keyword) >= 4:
                substrings.append(keyword[1:])  # æœ€åˆã®1æ–‡å­—ã‚’é™¤å»
        
        return list(set(substrings))  # é‡è¤‡é™¤å»
    
    def _generate_related_terms(self, query: str) -> List[str]:
        """é–¢é€£èªã®ç”Ÿæˆ"""
        related_terms = []
        
        # å¼·åŒ–ã•ã‚ŒãŸé–¢é€£èªãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå›ºæœ‰åè©ãƒ»æ¥­å‹™ç‰¹åŒ–èªã‚’è¿½åŠ ï¼‰
        term_mapping = {
            'ãƒ­ã‚°ã‚¤ãƒ³': ['èªè¨¼', 'ã‚µã‚¤ãƒ³ã‚¤ãƒ³', 'login', 'auth', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ', 'AKIæ§˜', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç®¡ç†ç”»é¢', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼', 'äºŒæ®µéšèªè¨¼'],
            'æ©Ÿèƒ½': ['ä»•æ§˜', 'ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼', 'feature', 'è¨­è¨ˆ', 'å®Ÿè£…', 'è¦ä»¶', 'specification'],
            'ä»•æ§˜': ['æ©Ÿèƒ½', 'spec', 'specification', 'è¨­è¨ˆæ›¸', 'è¦ä»¶å®šç¾©', 'å®Ÿè£…'],
            'æ€¥å‹Ÿ': ['ç·Šæ€¥', 'è‡³æ€¥', 'æ€¥ã', 'urgent'],
            'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£': ['å®‰å…¨', 'security', 'èªè¨¼', 'ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡'],
            'API': ['ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹', 'ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ', 'REST', 'JSON'],
            'AKI': ['AKIæ§˜', 'aki', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç®¡ç†', 'ãƒ­ã‚°ã‚¤ãƒ³'],
            'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ': ['ãƒ­ã‚°ã‚¤ãƒ³', 'èªè¨¼', 'AKIæ§˜', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼', 'account'],
            'ç®¡ç†ç”»é¢': ['ç®¡ç†', 'admin', 'ã‚¢ãƒ‰ãƒŸãƒ³', 'ç®¡ç†è€…', 'ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ'],
            'èªè¨¼': ['ãƒ­ã‚°ã‚¤ãƒ³', 'auth', 'authentication', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'äºŒæ®µéšèªè¨¼'],
            'äºŒæ®µéšèªè¨¼': ['2FA', 'ãƒ­ã‚°ã‚¤ãƒ³', 'èªè¨¼', 'ãƒ‘ã‚¹ã‚³ãƒ¼ãƒ‰', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£'],
            'ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰': ['èªè¨¼', 'ãƒ­ã‚°ã‚¤ãƒ³', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'ãƒ‘ã‚¹ã‚³ãƒ¼ãƒ‰'],
            'ã‚»ãƒƒã‚·ãƒ§ãƒ³': ['ãƒ­ã‚°ã‚¤ãƒ³', 'èªè¨¼', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ'],
        }
        
        keywords = self._extract_keywords(query)
        for keyword in keywords:
            # å®Œå…¨ä¸€è‡´æ¤œç´¢
            if keyword in term_mapping:
                related_terms.extend(term_mapping[keyword])
            
            # éƒ¨åˆ†ä¸€è‡´æ¤œç´¢ï¼ˆã‚ˆã‚ŠæŸ”è»Ÿãªãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰
            for key, values in term_mapping.items():
                if keyword in key or key in keyword:
                    related_terms.extend(values)
        
        # é‡è¤‡é™¤å»ã¨å…ƒã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯é™¤å¤–
        unique_terms = []
        for term in related_terms:
            if term not in unique_terms and term not in keywords:
                unique_terms.append(term)
        
        return unique_terms[:5]  # æœ€å¤§5å€‹ã®é–¢é€£èªï¼ˆæ‹¡å¼µï¼‰
    
    def _score_and_rank_results(self, results: List[Dict[str, Any]], query: str) -> List[Dict[str, Any]]:
        """çµæœã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨é †ä½ä»˜ã‘"""
        keywords = self._extract_keywords(query)
        
        for result in results:
            score = 0
            content = result.get('content', result)
            title = content.get('title', '')
            
            # ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒƒãƒã‚¹ã‚³ã‚¢ï¼ˆé«˜å„ªå…ˆåº¦ï¼‰
            for keyword in keywords:
                if keyword.lower() in title.lower():
                    score += 10
                    
            # å®Œå…¨ä¸€è‡´ãƒœãƒ¼ãƒŠã‚¹
            if query.lower() in title.lower():
                score += 20
                
            # æˆ¦ç•¥ãƒœãƒ¼ãƒŠã‚¹
            strategy = result.get('search_strategy', '')
            if 'TitlePriority' in strategy:
                score += 15
            elif 'KeywordSplit' in strategy:
                score += 10
            elif 'PhraseSearch' in strategy:
                score += 5
                
            result['relevance_score'] = score
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        return sorted(results, key=lambda x: x.get('relevance_score', 0), reverse=True)
    
    def format_enhanced_results(self, search_data: Dict[str, Any], query: str) -> str:
        """æ¤œç´¢çµæœã®æ•´å½¢"""
        results = search_data.get('results', [])
        metadata = search_data.get('metadata', {})
        
        if not results:
            return f"ã€Œ{query}ã€ã«é–¢ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        # çµæœã®æ•´å½¢
        formatted_lines = []
        formatted_lines.append("ğŸ” **Confluenceé«˜ç²¾åº¦CQLæ¤œç´¢çµæœ**")
        formatted_lines.append(f"ğŸ“ æ¤œç´¢ã‚¯ã‚¨ãƒª: ã€Œ{query}ã€")
        formatted_lines.append(f"ğŸ“Š ç™ºè¦‹ãƒšãƒ¼ã‚¸: {metadata.get('total_results', 0)}ä»¶ | å®Ÿè¡Œæ™‚é–“: {metadata.get('execution_time', 0):.2f}ç§’")
        
        # æˆ¦ç•¥åˆ¥çµ±è¨ˆ
        strategies = metadata.get('strategies_used', {})
        if strategies:
            strategy_stats = " | ".join([f"{k}: {v}ä»¶" for k, v in strategies.items() if v > 0])
            formatted_lines.append(f"ğŸ¯ æˆ¦ç•¥åˆ¥çµæœ: {strategy_stats}")
        
        formatted_lines.append("â­ é–¢é€£åº¦é †ã«è¡¨ç¤º")
        formatted_lines.append("")
        
        # å„çµæœã®è¡¨ç¤º
        for i, result in enumerate(results[:10], 1):
            content = result.get('content', result)
            title = content.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')
            web_ui_url = content.get('_links', {}).get('webui')
            relevance = result.get('relevance_score', 0)
            strategy = result.get('search_strategy', 'ä¸æ˜')
            
            if web_ui_url and not web_ui_url.startswith('http'):
                web_ui_url = f"https://{settings.atlassian_domain}{web_ui_url}"
            
            formatted_lines.append(f"ğŸ“„ **{i}. {title}** (é–¢é€£åº¦: {relevance}ç‚¹)")
            if web_ui_url:
                formatted_lines.append(f"   ğŸ”— {web_ui_url}")
            formatted_lines.append(f"   ğŸ¯ æ¤œç´¢æˆ¦ç•¥: {strategy}")
            formatted_lines.append("")
        
        formatted_lines.append("ğŸ’¡ **æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:**")
        formatted_lines.append("â€¢ ä¸Šä½çµæœã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        formatted_lines.append("â€¢ ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ãŒå¿…è¦ãªå ´åˆã¯ã€å…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§å†æ¤œç´¢ã—ã¦ãã ã•ã„")
        
        return "\n".join(formatted_lines)


# ãƒ„ãƒ¼ãƒ«é–¢æ•°ï¼ˆLangChainã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰å‘¼ã³å‡ºã—å¯èƒ½ï¼‰
def search_confluence_with_enhanced_cql(query: str) -> str:
    """
    é«˜ç²¾åº¦CQLã«ã‚ˆã‚‹Confluenceæ¤œç´¢ãƒ„ãƒ¼ãƒ«
    
    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆ"ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ã®ä»•æ§˜ã«ã¤ã„ã¦"å½¢å¼ï¼‰
        
    Returns:
        é«˜ç²¾åº¦æ¤œç´¢ã«ã‚ˆã‚‹è©³ç´°ãªçµæœ
    """
    try:
        # Queryã‹ã‚‰ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã¨ã‚¯ã‚¨ãƒªãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹S
        parts = query.split(",")
        search_query = parts[0].replace("query:", "").strip()
        
        # é«˜ç²¾åº¦CQLæ¤œç´¢ã‚’å®Ÿè¡Œ
        enhanced_search = ConfluenceEnhancedCQLSearch()
        search_data = enhanced_search.search_with_enhanced_cql(search_query)
        
        return enhanced_search.format_enhanced_results(search_data, search_query)
        
    except Exception as e:
        logger.error(f"é«˜ç²¾åº¦CQLæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
        return f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}" 