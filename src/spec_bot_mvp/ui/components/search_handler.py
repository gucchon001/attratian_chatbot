import streamlit as st
import logging
from typing import Dict, Any

from src.spec_bot_mvp.tools.hybrid_search_tool import HybridSearchTool
from src.spec_bot_mvp.ui.components.thinking_process_ui import IntegratedThinkingProcessUI
from src.spec_bot_mvp.agents.response_generator import ResponseGenerationAgent  # å¤‰æ›´: å…¨æ–‡å–å¾—å¯¾å¿œç‰ˆã‚’ä½¿ç”¨

logger = logging.getLogger(__name__)

def format_search_results(search_data: Dict) -> str:
    """
    æ¤œç´¢çµæœãƒ‡ãƒ¼ã‚¿ï¼ˆè¾æ›¸ï¼‰ã‚’NotebookLMã‚¹ã‚¿ã‚¤ãƒ«ã®åŒ…æ‹¬çš„å›ç­”ã«å¤‰æ›
    ResponseGenerationAgentï¼ˆå…¨æ–‡å–å¾—å¯¾å¿œï¼‰ã‚’ä½¿ç”¨ã—ãŸé«˜å“è³ªå›ç­”ç”Ÿæˆ
    """
    
    if not search_data or "error" in search_data:
        return f"ğŸš¨ **æ¤œç´¢ã‚¨ãƒ©ãƒ¼**\n\n{search_data.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚')}"

    # æ¤œç´¢ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
    query = search_data.get("query", "N/A")
    step3_result = search_data.get("step3_result", {})
    step4_result = search_data.get("step4_result", {})
    
    # æ¤œç´¢çµæœã®å–å¾—
    ranked_results = step4_result.get("ranked_results", [])
    
    try:
        # ResponseGenerationAgentï¼ˆå…¨æ–‡å–å¾—å¯¾å¿œï¼‰ã®åˆæœŸåŒ–ã¨å®Ÿè¡Œ
        response_generator = ResponseGenerationAgent()
        
        # åŒ…æ‹¬çš„å›ç­”ç”Ÿæˆï¼ˆå…¨æ–‡å–å¾—æ©Ÿèƒ½ä»˜ãï¼‰
        comprehensive_response = response_generator.generate_response(
            search_results=ranked_results,
            user_query=query
        )
        
        logger.info(f"âœ… ResponseGenerationAgentå›ç­”ç”Ÿæˆå®Œäº†: {len(comprehensive_response)}æ–‡å­—")
        return comprehensive_response
        
    except Exception as e:
        logger.error(f"âŒ ResponseGenerationAgent ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®å½¢å¼
        search_metadata = {
            "total_results": step3_result.get("total_results", 0),
            "execution_summary": step3_result.get("execution_summary", ""),
            "strategies_executed": step3_result.get("strategies_executed", []),
            "query_details": step3_result.get("query_details", {})
        }
        return _generate_fallback_format(query, ranked_results, search_metadata)

def _generate_fallback_format(query: str, ranked_results: list, search_metadata: dict) -> str:
    """ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å½¢å¼ï¼ˆå¾“æ¥å‹ï¼‰"""
    
    output = [
        f"## ğŸ¯ ã€Œ{query}ã€ã®æ¤œç´¢çµæœ",
        "---",
        f"**{len(ranked_results)}ä»¶**ã®é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚",
        ""
    ]

    # çµæœã®ç°¡æ˜“è¡¨ç¤º
    for i, result in enumerate(ranked_results[:5], 1):
        title = result.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—")
        score = result.get("final_score", 0)
        datasource = result.get("datasource", "unknown").capitalize()
        excerpt = result.get("excerpt", "")[:150]
        
        output.extend([
            f"### {i}. {title}",
            f"**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: {datasource} | **å“è³ªã‚¹ã‚³ã‚¢**: {score:.3f}",
            "",
            excerpt + ("..." if len(result.get("excerpt", "")) > 150 else ""),
            ""
        ])

    output.extend([
        "---",
        "**âš ï¸ æ³¨æ„**: AIåˆ†ææ©Ÿèƒ½ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€åŸºæœ¬å½¢å¼ã§è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚"
    ])

    return "\n".join(output)

def execute_integrated_search_with_progress(prompt: str, thinking_ui: IntegratedThinkingProcessUI, process_placeholder) -> Dict[str, Any]:
    """ãƒ—ãƒ­ã‚»ã‚¹å¯è¦–åŒ–ä»˜ãçµ±åˆæ¤œç´¢å®Ÿè¡Œï¼ˆæœ¬ç•ªãƒ‡ãƒ¼ã‚¿æ¥ç¶šç‰ˆï¼‰"""
    try:
        # HybridSearchToolã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
        hybrid_tool = st.session_state.hybrid_tool

        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’æ­£ã—ãå®šç¾©ï¼ˆãƒ­ã‚°å‡ºåŠ›ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
        def update_callback(stage_id, details):
            try:
                logger.info(f"ğŸ”„ æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹æ›´æ–°: {stage_id} -> completed")
                thinking_ui.update_stage_status(stage_id, "completed", details)
                # Streamlitã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã®ãŸã‚ã€placeholderã‚’ç›´æ¥æ›¸ãæ›ãˆ
                process_placeholder.empty()  # æ—¢å­˜å†…å®¹ã‚’ã‚¯ãƒªã‚¢
                with process_placeholder.container():
                    thinking_ui.render_process_visualization()
                # è¡¨ç¤ºã®ç¢ºå®Ÿæ€§ã®ãŸã‚çŸ­æ™‚é–“å¾…æ©Ÿ
                import time
                time.sleep(0.1)
                logger.info(f"âœ… æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹æ›´æ–°å®Œäº†: {stage_id}")
            except Exception as e:
                logger.error(f"âŒ æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼({stage_id}): {e}")
        
        def in_progress_callback(stage_id):
            try:
                logger.info(f"ğŸš€ æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹: {stage_id} -> in_progress")
                thinking_ui.update_stage_status(stage_id, "in_progress")
                # Streamlitã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã®ãŸã‚ã€placeholderã‚’ç›´æ¥æ›¸ãæ›ãˆ
                process_placeholder.empty()  # æ—¢å­˜å†…å®¹ã‚’ã‚¯ãƒªã‚¢
                with process_placeholder.container():
                    thinking_ui.render_process_visualization()
                # è¡¨ç¤ºã®ç¢ºå®Ÿæ€§ã®ãŸã‚çŸ­æ™‚é–“å¾…æ©Ÿ
                import time
                time.sleep(0.1)
                logger.info(f"âœ… æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹å®Œäº†: {stage_id}")
            except Exception as e:
                logger.error(f"âŒ æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹ã‚¨ãƒ©ãƒ¼({stage_id}): {e}")

        # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ›´æ–°ã—ãªãŒã‚‰æ¤œç´¢å®Ÿè¡Œ
        logger.info("ğŸ” ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢é–‹å§‹...")
        search_result_data = hybrid_tool.search(
            query=prompt,
            update_callback=update_callback,
            in_progress_callback=in_progress_callback
        )

        # æœ€çµ‚çš„ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹è¡¨ç¤ºã‚’æ›´æ–°
        logger.info("ğŸ“Š æœ€çµ‚çš„ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹è¡¨ç¤ºæ›´æ–°ä¸­...")
        with process_placeholder.container():
            thinking_ui.render_process_visualization()
        
        # UIè¡¨ç¤ºç”¨ã«çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted_result = format_search_results(search_result_data)
        
        # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’UIã®çŠ¶æ…‹ã¨çµ±åˆ
        final_thinking_process_data = search_result_data.copy() # å…ƒã®è¾æ›¸ã‚’å¤‰æ›´ã—ãªã„ã‚ˆã†ã«ã‚³ãƒ”ãƒ¼
        if hasattr(thinking_ui, 'process_stages'):
            final_thinking_process_data["process_stages"] = thinking_ui.process_stages

        logger.info("âœ… çµ±åˆæ¤œç´¢å®Œäº†")
        return {
            "search_result": formatted_result,
            "thinking_process": final_thinking_process_data,
            "success": True
        }
        
    except Exception as e:
        logger.error(f"çµ±åˆæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚UIã§è¡¨ç¤ºã‚’çµ±ä¸€
        thinking_ui.update_stage_status("response_generation", "error", {"error_message": str(e)})
        with process_placeholder.container():
            thinking_ui.render_process_visualization()
            
        return {
            "search_result": f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚æ¤œç´¢å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "thinking_process": {"process_stages": thinking_ui.process_stages} if hasattr(thinking_ui, 'process_stages') else {},
            "success": False
        } 