"""
ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
JSONã€TXTã€Markdownã€YAMLã€ãã®ä»–ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚
"""

import json
import yaml
import pickle
import sqlite3
import time
import os
import gzip
import csv
from pathlib import Path
import pandas as pd
from typing import Dict, List, Any
import random
import string

class IndexFormatPerformanceTest:
    """
    ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, test_data_size: int = 1000):
        self.test_data_size = test_data_size
        self.test_dir = Path("test_index_formats")
        self.test_dir.mkdir(exist_ok=True)
        self.results = {}
        
    def generate_test_data(self) -> Dict[str, Any]:
        """
        ãƒ†ã‚¹ãƒˆç”¨ã®Confluenceã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        """
        print(f"ğŸ”§ {self.test_data_size}ãƒšãƒ¼ã‚¸åˆ†ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
        
        data = {
            'metadata': {
                'created_at': '2025-01-18T01:00:00Z',
                'space_key': 'TEST',
                'total_pages': self.test_data_size,
                'last_update': '2025-01-18T01:00:00Z',
                'version': '1.0'
            },
            'pages': {},
            'hierarchy': {},
            'content_map': {},
            'categories': {
                'specifications': [],
                'designs': [],
                'manuals': [],
                'apis': [],
                'security': [],
                'ui_ux': [],
                'workflows': []
            }
        }
        
        # ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        for i in range(self.test_data_size):
            page_id = f"page_{i}"
            title = f"Test Page {i}: {self._random_title()}"
            content = self._random_content()
            
            data['pages'][page_id] = {
                'id': page_id,
                'title': title,
                'type': 'page',
                'space': 'TEST',
                'url': f"https://test.atlassian.net/wiki/spaces/TEST/pages/{i}",
                'created': '2025-01-18T01:00:00Z',
                'updated': '2025-01-18T01:00:00Z',
                'content_preview': content[:200],
                'labels': [f"label_{j}" for j in range(random.randint(1, 5))]
            }
            
            # éšå±¤æ§‹é€ 
            parent_id = f"page_{i//10}" if i > 10 else None
            if parent_id and parent_id in data['pages']:
                data['hierarchy'][page_id] = {
                    'parent_id': parent_id,
                    'children': []
                }
                if parent_id not in data['hierarchy']:
                    data['hierarchy'][parent_id] = {'parent_id': None, 'children': []}
                data['hierarchy'][parent_id]['children'].append(page_id)
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒƒãƒ—
            keywords = content.split()[:10]  # æœ€åˆã®10å˜èªã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã—ã¦ä½¿ç”¨
            for keyword in keywords:
                if keyword not in data['content_map']:
                    data['content_map'][keyword] = []
                data['content_map'][keyword].append(page_id)
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
            category = random.choice(list(data['categories'].keys()))
            data['categories'][category].append(page_id)
        
        return data
    
    def _random_title(self) -> str:
        """ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ"""
        titles = [
            "APIè¨­è¨ˆä»•æ§˜æ›¸", "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ‹ãƒ¥ã‚¢ãƒ«", "ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶å®šç¾©",
            "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³", "UI/UXè¨­è¨ˆ",
            "ãƒ†ã‚¹ãƒˆä»•æ§˜æ›¸", "ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †", "é‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«", "éšœå®³å¯¾å¿œæ‰‹é †"
        ]
        return random.choice(titles)
    
    def _random_content(self) -> str:
        """ãƒ©ãƒ³ãƒ€ãƒ ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ"""
        words = ["ã‚·ã‚¹ãƒ†ãƒ ", "ãƒ¦ãƒ¼ã‚¶ãƒ¼", "ãƒ‡ãƒ¼ã‚¿", "æ©Ÿèƒ½", "è¨­è¨ˆ", "ä»•æ§˜", "è¦ä»¶", 
                "ãƒ†ã‚¹ãƒˆ", "é–‹ç™º", "é‹ç”¨", "ä¿å®ˆ", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹", "API", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "ã‚µãƒ¼ãƒãƒ¼", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"]
        return " ".join(random.choices(words, k=100))
    
    def test_json_format(self, data: Dict[str, Any]) -> Dict[str, float]:
        """JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ“ JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        # æ¨™æº–JSON
        json_file = self.test_dir / "index.json"
        
        # æ›¸ãè¾¼ã¿æ™‚é–“
        start_time = time.time()
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        write_time = time.time() - start_time
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        file_size = json_file.stat().st_size
        
        # èª­ã¿è¾¼ã¿æ™‚é–“
        start_time = time.time()
        with open(json_file, 'r', encoding='utf-8') as f:
            loaded_data = json.load(f)
        read_time = time.time() - start_time
        
        # æ¤œç´¢æ™‚é–“ï¼ˆãƒšãƒ¼ã‚¸æ¤œç´¢ï¼‰
        start_time = time.time()
        search_results = []
        for page_id, page_info in loaded_data['pages'].items():
            if 'API' in page_info['title']:
                search_results.append(page_id)
        search_time = time.time() - start_time
        
        return {
            'write_time': write_time,
            'read_time': read_time,
            'search_time': search_time,
            'file_size': file_size,
            'search_results': len(search_results)
        }
    
    def test_json_compressed(self, data: Dict[str, Any]) -> Dict[str, float]:
        """åœ§ç¸®JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ—œï¸ åœ§ç¸®JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        json_gz_file = self.test_dir / "index.json.gz"
        
        # æ›¸ãè¾¼ã¿æ™‚é–“
        start_time = time.time()
        with gzip.open(json_gz_file, 'wt', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False)
        write_time = time.time() - start_time
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        file_size = json_gz_file.stat().st_size
        
        # èª­ã¿è¾¼ã¿æ™‚é–“
        start_time = time.time()
        with gzip.open(json_gz_file, 'rt', encoding='utf-8') as f:
            loaded_data = json.load(f)
        read_time = time.time() - start_time
        
        # æ¤œç´¢æ™‚é–“
        start_time = time.time()
        search_results = []
        for page_id, page_info in loaded_data['pages'].items():
            if 'API' in page_info['title']:
                search_results.append(page_id)
        search_time = time.time() - start_time
        
        return {
            'write_time': write_time,
            'read_time': read_time,
            'search_time': search_time,
            'file_size': file_size,
            'search_results': len(search_results)
        }
    
    def test_yaml_format(self, data: Dict[str, Any]) -> Dict[str, float]:
        """YAMLãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ“„ YAMLãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        yaml_file = self.test_dir / "index.yaml"
        
        # æ›¸ãè¾¼ã¿æ™‚é–“
        start_time = time.time()
        with open(yaml_file, 'w', encoding='utf-8') as f:
            yaml.dump(data, f, default_flow_style=False, allow_unicode=True)
        write_time = time.time() - start_time
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        file_size = yaml_file.stat().st_size
        
        # èª­ã¿è¾¼ã¿æ™‚é–“
        start_time = time.time()
        with open(yaml_file, 'r', encoding='utf-8') as f:
            loaded_data = yaml.safe_load(f)
        read_time = time.time() - start_time
        
        # æ¤œç´¢æ™‚é–“
        start_time = time.time()
        search_results = []
        for page_id, page_info in loaded_data['pages'].items():
            if 'API' in page_info['title']:
                search_results.append(page_id)
        search_time = time.time() - start_time
        
        return {
            'write_time': write_time,
            'read_time': read_time,
            'search_time': search_time,
            'file_size': file_size,
            'search_results': len(search_results)
        }
    
    def test_pickle_format(self, data: Dict[str, Any]) -> Dict[str, float]:
        """Pickleãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆï¼ˆãƒã‚¤ãƒŠãƒªï¼‰"""
        print("ğŸ¥’ Pickleãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        pickle_file = self.test_dir / "index.pkl"
        
        # æ›¸ãè¾¼ã¿æ™‚é–“
        start_time = time.time()
        with open(pickle_file, 'wb') as f:
            pickle.dump(data, f)
        write_time = time.time() - start_time
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        file_size = pickle_file.stat().st_size
        
        # èª­ã¿è¾¼ã¿æ™‚é–“
        start_time = time.time()
        with open(pickle_file, 'rb') as f:
            loaded_data = pickle.load(f)
        read_time = time.time() - start_time
        
        # æ¤œç´¢æ™‚é–“
        start_time = time.time()
        search_results = []
        for page_id, page_info in loaded_data['pages'].items():
            if 'API' in page_info['title']:
                search_results.append(page_id)
        search_time = time.time() - start_time
        
        return {
            'write_time': write_time,
            'read_time': read_time,
            'search_time': search_time,
            'file_size': file_size,
            'search_results': len(search_results)
        }
    
    def test_sqlite_format(self, data: Dict[str, Any]) -> Dict[str, float]:
        """SQLiteãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ—„ï¸ SQLiteãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        sqlite_file = self.test_dir / "index.db"
        
        # æ›¸ãè¾¼ã¿æ™‚é–“
        start_time = time.time()
        conn = sqlite3.connect(sqlite_file)
        cursor = conn.cursor()
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS pages (
                id TEXT PRIMARY KEY,
                title TEXT,
                type TEXT,
                space TEXT,
                url TEXT,
                created TEXT,
                updated TEXT,
                content_preview TEXT,
                labels TEXT
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS content_map (
                keyword TEXT,
                page_id TEXT
            )
        ''')
        
        # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
        for page_id, page_info in data['pages'].items():
            cursor.execute('''
                INSERT INTO pages VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                page_id,
                page_info['title'],
                page_info['type'],
                page_info['space'],
                page_info['url'],
                page_info['created'],
                page_info['updated'],
                page_info['content_preview'],
                ','.join(page_info['labels'])
            ))
        
        for keyword, page_ids in data['content_map'].items():
            for page_id in page_ids:
                cursor.execute('INSERT INTO content_map VALUES (?, ?)', (keyword, page_id))
        
        conn.commit()
        write_time = time.time() - start_time
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        file_size = sqlite_file.stat().st_size
        
        # èª­ã¿è¾¼ã¿æ™‚é–“ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼‰
        start_time = time.time()
        cursor.execute('SELECT * FROM pages')
        all_pages = cursor.fetchall()
        read_time = time.time() - start_time
        
        # æ¤œç´¢æ™‚é–“ï¼ˆSQLæ¤œç´¢ï¼‰
        start_time = time.time()
        cursor.execute("SELECT id FROM pages WHERE title LIKE '%API%'")
        search_results = cursor.fetchall()
        search_time = time.time() - start_time
        
        conn.close()
        
        return {
            'write_time': write_time,
            'read_time': read_time,
            'search_time': search_time,
            'file_size': file_size,
            'search_results': len(search_results)
        }
    
    def test_csv_format(self, data: Dict[str, Any]) -> Dict[str, float]:
        """CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ“Š CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        csv_file = self.test_dir / "pages.csv"
        content_map_file = self.test_dir / "content_map.csv"
        
        # æ›¸ãè¾¼ã¿æ™‚é–“
        start_time = time.time()
        
        # ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚’CSVã«æ›¸ãè¾¼ã¿
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['id', 'title', 'type', 'space', 'url', 'created', 'updated', 'content_preview', 'labels'])
            for page_id, page_info in data['pages'].items():
                writer.writerow([
                    page_id,
                    page_info['title'],
                    page_info['type'],
                    page_info['space'],
                    page_info['url'],
                    page_info['created'],
                    page_info['updated'],
                    page_info['content_preview'],
                    ','.join(page_info['labels'])
                ])
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒƒãƒ—ã‚’CSVã«æ›¸ãè¾¼ã¿
        with open(content_map_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['keyword', 'page_id'])
            for keyword, page_ids in data['content_map'].items():
                for page_id in page_ids:
                    writer.writerow([keyword, page_id])
        
        write_time = time.time() - start_time
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        file_size = csv_file.stat().st_size + content_map_file.stat().st_size
        
        # èª­ã¿è¾¼ã¿æ™‚é–“
        start_time = time.time()
        df_pages = pd.read_csv(csv_file)
        df_content_map = pd.read_csv(content_map_file)
        read_time = time.time() - start_time
        
        # æ¤œç´¢æ™‚é–“
        start_time = time.time()
        search_results = df_pages[df_pages['title'].str.contains('API', na=False)]
        search_time = time.time() - start_time
        
        return {
            'write_time': write_time,
            'read_time': read_time,
            'search_time': search_time,
            'file_size': file_size,
            'search_results': len(search_results)
        }
    
    def run_all_tests(self):
        """ã™ã¹ã¦ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print("ğŸš€ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
        print("=" * 60)
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        test_data = self.generate_test_data()
        
        # å„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        tests = [
            ("JSON", self.test_json_format),
            ("JSONåœ§ç¸®", self.test_json_compressed),
            ("YAML", self.test_yaml_format),
            ("Pickle", self.test_pickle_format),
            ("SQLite", self.test_sqlite_format),
            ("CSV", self.test_csv_format),
        ]
        
        for format_name, test_func in tests:
            try:
                self.results[format_name] = test_func(test_data)
                print(f"âœ… {format_name}ãƒ†ã‚¹ãƒˆå®Œäº†")
            except Exception as e:
                print(f"âŒ {format_name}ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                self.results[format_name] = None
        
        self.generate_report()
    
    def generate_report(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 60)
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        print(f"{'ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ':<10} {'æ›¸è¾¼æ™‚é–“(s)':<12} {'èª­è¾¼æ™‚é–“(s)':<12} {'æ¤œç´¢æ™‚é–“(s)':<12} {'ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º(MB)':<15} {'æ¤œç´¢çµæœæ•°':<10}")
        print("-" * 80)
        
        # çµæœè¡¨ç¤º
        for format_name, result in self.results.items():
            if result:
                print(f"{format_name:<10} "
                      f"{result['write_time']:<12.4f} "
                      f"{result['read_time']:<12.4f} "
                      f"{result['search_time']:<12.4f} "
                      f"{result['file_size']/1024/1024:<15.2f} "
                      f"{result['search_results']:<10}")
        
        # æœ€é©ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ¨å¥¨
        self.recommend_best_format()
    
    def recommend_best_format(self):
        """æœ€é©ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ¨å¥¨"""
        print("\nğŸ¯ æ¨å¥¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ†æ:")
        print("-" * 40)
        
        valid_results = {k: v for k, v in self.results.items() if v is not None}
        
        if not valid_results:
            print("âŒ æœ‰åŠ¹ãªçµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # å„æŒ‡æ¨™ã§ã®æœ€å„ªç§€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        fastest_write = min(valid_results, key=lambda x: valid_results[x]['write_time'])
        fastest_read = min(valid_results, key=lambda x: valid_results[x]['read_time'])
        fastest_search = min(valid_results, key=lambda x: valid_results[x]['search_time'])
        smallest_size = min(valid_results, key=lambda x: valid_results[x]['file_size'])
        
        print(f"ğŸš€ æœ€é€Ÿæ›¸ãè¾¼ã¿: {fastest_write} ({valid_results[fastest_write]['write_time']:.4f}s)")
        print(f"ğŸ“– æœ€é€Ÿèª­ã¿è¾¼ã¿: {fastest_read} ({valid_results[fastest_read]['read_time']:.4f}s)")
        print(f"ğŸ” æœ€é€Ÿæ¤œç´¢: {fastest_search} ({valid_results[fastest_search]['search_time']:.4f}s)")
        print(f"ğŸ’¾ æœ€å°ã‚µã‚¤ã‚º: {smallest_size} ({valid_results[smallest_size]['file_size']/1024/1024:.2f}MB)")
        
        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆæ­£è¦åŒ–å¾Œã®é‡ã¿ä»˜ã‘å¹³å‡ï¼‰
        print(f"\nğŸ† ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢:")
        scores = {}
        for format_name, result in valid_results.items():
            # å„æŒ‡æ¨™ã‚’æ­£è¦åŒ–ï¼ˆ0-1ï¼‰ã—ã€é‡ã¿ä»˜ã‘
            write_score = 1 / (1 + result['write_time'])  # å°ã•ã„ã»ã©è‰¯ã„
            read_score = 1 / (1 + result['read_time'])    # å°ã•ã„ã»ã©è‰¯ã„
            search_score = 1 / (1 + result['search_time']) # å°ã•ã„ã»ã©è‰¯ã„
            size_score = 1 / (1 + result['file_size']/1024/1024)  # å°ã•ã„ã»ã©è‰¯ã„
            
            # é‡ã¿ä»˜ã‘ï¼ˆæ¤œç´¢é€Ÿåº¦ã‚’é‡è¦–ï¼‰
            total_score = (write_score * 0.2 + read_score * 0.3 + 
                          search_score * 0.4 + size_score * 0.1)
            scores[format_name] = total_score
        
        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        
        for i, (format_name, score) in enumerate(sorted_scores, 1):
            medal = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "  "
            print(f"{medal} {i}. {format_name}: {score:.4f}")
        
        # æ¨å¥¨äº‹é …
        best_format = sorted_scores[0][0]
        print(f"\nâœ¨ ç·åˆæ¨å¥¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {best_format}")
        
        # ç”¨é€”åˆ¥æ¨å¥¨
        print(f"\nğŸ“‹ ç”¨é€”åˆ¥æ¨å¥¨:")
        print(f"â€¢ é »ç¹ãªæ¤œç´¢ãŒå¿…è¦: {fastest_search}")
        print(f"â€¢ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡é‡è¦–: {smallest_size}")
        print(f"â€¢ é«˜é€Ÿèª­ã¿è¾¼ã¿é‡è¦–: {fastest_read}")
        print(f"â€¢ ãƒ‡ãƒ¼ã‚¿æ›´æ–°é »åº¦é«˜: {fastest_write}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”¬ Confluenceã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚ºã‚’é¸æŠ
    test_sizes = [100, 500, 1000, 2000]
    print("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’é¸æŠã—ã¦ãã ã•ã„:")
    for i, size in enumerate(test_sizes, 1):
        print(f"{i}. {size}ãƒšãƒ¼ã‚¸")
    
    try:
        choice = int(input("é¸æŠ (1-4): "))
        if 1 <= choice <= len(test_sizes):
            test_size = test_sizes[choice - 1]
        else:
            test_size = 1000
            print("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000ãƒšãƒ¼ã‚¸")
    except:
        test_size = 1000
        print("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000ãƒšãƒ¼ã‚¸")
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tester = IndexFormatPerformanceTest(test_size)
    tester.run_all_tests()
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®é¸æŠ
    cleanup = input("\nãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã‹? (y/N): ").lower()
    if cleanup == 'y':
        import shutil
        shutil.rmtree(tester.test_dir)
        print("ğŸ—‘ï¸ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main() 