#!/usr/bin/env python3
"""
Confluenceéšå±¤ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ—¢å­˜ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–°ã—ã„ConfluenceHierarchyManageræ§‹é€ ã«ç§»è¡Œã—ã€
å‰Šé™¤ãƒšãƒ¼ã‚¸ã®æ¤œå‡ºãƒ»ã‚«ã‚¦ãƒ³ãƒˆãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/migrate_hierarchy_data.py
"""

import sys
import json
import os
from pathlib import Path
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from src.spec_bot_mvp.utils.confluence_hierarchy_manager import ConfluenceHierarchyManager


def migrate_existing_json():
    """æ—¢å­˜ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–°æ§‹é€ ã«ç§»è¡Œ"""
    
    print("ğŸš€ Confluenceéšå±¤ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã‚’é–‹å§‹ã—ã¾ã™...")
    
    # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    old_json_files = [
        "confluence_hierarchy_20250717_162759.json",
        "confluence_structure_20250717_161346.txt"
    ]
    
    manager = ConfluenceHierarchyManager()
    
    # æ—¢å­˜JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    source_file = None
    for filename in old_json_files:
        if os.path.exists(filename):
            source_file = filename
            break
    
    if not source_file:
        print("âŒ æ—¢å­˜ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    print(f"ğŸ“„ æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»è¡Œ: {source_file}")
    
    try:
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        with open(source_file, 'r', encoding='utf-8') as f:
            old_data = json.load(f)
        
        print(f"âœ… æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
        print(f"   - ç·ãƒšãƒ¼ã‚¸æ•°: {old_data.get('total_pages', 'ä¸æ˜')}")
        print(f"   - ç”Ÿæˆæ—¥æ™‚: {old_data.get('generated_at', 'ä¸æ˜')}")
        
        # å‰Šé™¤ãƒšãƒ¼ã‚¸æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        folders = old_data.get('folders', [])
        deleted_count = manager.count_deleted_pages(folders)
        
        print(f"ğŸ—‘ï¸ å‰Šé™¤ãƒ»å»ƒæ­¢ãƒšãƒ¼ã‚¸æ¤œå‡º: {deleted_count}ä»¶")
        
        # æ–°ã—ã„æ§‹é€ ã§ãƒ‡ãƒ¼ã‚¿ã‚’å†æ§‹ç¯‰
        new_data = {
            "space_name": old_data.get('space_name', 'client-tomonokai-juku'),
            "space_key": old_data.get('space_key', 'CLIENTTOMO'),
            "generated_at": datetime.now().isoformat(),
            "total_pages": old_data.get('total_pages', len(manager._count_all_pages(folders))),
            "deleted_pages_count": deleted_count,
            "version": manager.version,
            "folders": folders
        }
        
        # æ–°æ§‹é€ ã§ä¿å­˜
        if manager.save_hierarchy_data(new_data):
            print(f"âœ… æ–°æ§‹é€ ã§ã®ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†")
            print(f"   - ä¿å­˜å…ˆ: {manager.hierarchy_file}")
            print(f"   - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {manager.backup_file}")
            print(f"   - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {manager.metadata_file}")
            
            # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
            stats = manager.get_hierarchy_stats()
            print(f"\nğŸ“Š ç§»è¡Œå¾Œçµ±è¨ˆ:")
            print(f"   - ç·ãƒšãƒ¼ã‚¸æ•°: {stats.get('total_pages', 0)}")
            print(f"   - å‰Šé™¤ãƒšãƒ¼ã‚¸æ•°: {stats.get('deleted_pages_count', 0)}")
            print(f"   - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {stats.get('file_size', 0):,} bytes")
            print(f"   - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å­˜åœ¨: {stats.get('backup_exists', False)}")
            
            return True
        else:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
            
    except Exception as e:
        print(f"âŒ ç§»è¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return False


def test_hierarchy_functions():
    """éšå±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    
    print("\nğŸ§ª éšå±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
    
    manager = ConfluenceHierarchyManager()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
    print("\n1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ")
    data_normal = manager.load_hierarchy_data(include_deleted=False)
    data_with_deleted = manager.load_hierarchy_data(include_deleted=True)
    
    if data_normal and data_with_deleted:
        print("âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ")
        
        # å‰Šé™¤ãƒšãƒ¼ã‚¸ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
        normal_count = len(manager._count_all_pages(data_normal.get('folders', [])))
        deleted_count = len(manager._count_all_pages(data_with_deleted.get('folders', [])))
        
        print(f"   - é€šå¸¸ãƒšãƒ¼ã‚¸æ•°: {normal_count}")
        print(f"   - å‰Šé™¤ãƒšãƒ¼ã‚¸å«ã‚€: {deleted_count}")
        print(f"   - å‰Šé™¤ãƒšãƒ¼ã‚¸æ•°: {deleted_count - normal_count}")
    else:
        print("âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—")
        return False
    
    # æ›´æ–°ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    print("\n2. æ›´æ–°ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")
    should_update, reason = manager.should_update()
    print(f"   - æ›´æ–°è¦å¦: {should_update}")
    print(f"   - ç†ç”±: {reason}")
    
    # çµ±è¨ˆæƒ…å ±ãƒ†ã‚¹ãƒˆ
    print("\n3. çµ±è¨ˆæƒ…å ±ãƒ†ã‚¹ãƒˆ")
    stats = manager.get_hierarchy_stats()
    for key, value in stats.items():
        print(f"   - {key}: {value}")
    
    print("\nâœ… å…¨ãƒ†ã‚¹ãƒˆå®Œäº†")
    return True


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 60)
    print("ğŸ—ï¸  Confluenceéšå±¤ãƒ‡ãƒ¼ã‚¿ç§»è¡Œ & ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # Step 1: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ç§»è¡Œ
    if migrate_existing_json():
        print("\nâœ… ç§»è¡Œå®Œäº†")
    else:
        print("\nâŒ ç§»è¡Œå¤±æ•—")
        return
    
    # Step 2: æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
    if test_hierarchy_functions():
        print("\nğŸ‰ ç§»è¡Œã¨ãƒ†ã‚¹ãƒˆãŒã™ã¹ã¦æ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
    else:
        print("\nâš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main() 