"""
ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¤œç´¢æ©Ÿèƒ½ ç›´æ¥ãƒ†ã‚¹ãƒˆ
"""

import sys
import time
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(str(project_root / "src"))

def main():
    try:
        from spec_bot_mvp.tools.confluence_indexer import ConfluenceIndexer
        
        print("ğŸ” ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¤œç´¢æ©Ÿèƒ½ ç›´æ¥ãƒ†ã‚¹ãƒˆ")
        print("=" * 40)
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚µãƒ¼åˆæœŸåŒ–
        indexer = ConfluenceIndexer()
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿
        print("ğŸ“‚ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿ä¸­...")
        if not indexer.load_index():
            print("âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿å¤±æ•—")
            return False
        
        print(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿æˆåŠŸ: {indexer.index['metadata']['total_pages']}ãƒšãƒ¼ã‚¸")
        
        # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
        test_queries = ["API", "è¨­è¨ˆ", "èªè¨¼", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ãƒ‡ãƒ—ãƒ­ã‚¤"]
        
        print("\nğŸ” æ¤œç´¢ãƒ†ã‚¹ãƒˆ:")
        for query in test_queries:
            start_time = time.time()
            
            # æ¤œç´¢å®Ÿè¡Œ
            results = indexer.search_by_keyword(query, max_results=3)
            
            search_time = time.time() - start_time
            
            print(f"\n'{query}': {len(results)}ä»¶ ({search_time*1000:.1f}ms)")
            
            for i, result in enumerate(results, 1):
                title = result.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
                score = result.get('relevance_score', 0)
                print(f"  {i}. {title} (é–¢é€£åº¦: {score:.3f})")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
        print(f"\nğŸ’¾ åœ§ç¸®åŠ¹æœ:")
        cache_dir = Path("cache")
        for file_pattern, description in [
            ("confluence_index.json.gz", "åœ§ç¸®JSON"),
            ("confluence_index.pkl", "ã‚­ãƒ£ãƒƒã‚·ãƒ¥Pickle"),
            ("confluence_index.json", "å¾“æ¥JSON")
        ]:
            file_path = cache_dir / file_pattern
            if file_path.exists():
                size_mb = file_path.stat().st_size / 1024 / 1024
                print(f"  â€¢ {description}: {size_mb:.3f}MB")
        
        print(f"\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    main() 