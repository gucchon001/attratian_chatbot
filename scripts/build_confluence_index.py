"""
Confluenceã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Confluenceã‚¹ãƒšãƒ¼ã‚¹å…¨ä½“ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’äº‹å‰æ§‹ç¯‰ã—ã€
é«˜é€Ÿæ¤œç´¢ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚
"""

import sys
import time
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.spec_bot_mvp.tools.confluence_indexer import ConfluenceIndexer
from src.spec_bot_mvp.config.settings import settings
from src.spec_bot_mvp.utils.log_config import get_logger

logger = get_logger(__name__)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Confluenceã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚’é–‹å§‹...")
    print("=" * 50)
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚µãƒ¼ã®åˆæœŸåŒ–
    indexer = ConfluenceIndexer()
    
    # è¨­å®šç¢ºèª
    if not settings.confluence_space:
        print("âŒ CONFLUENCE_SPACEãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("settings.iniã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        return False
    
    print(f"ğŸ“‹ å¯¾è±¡ã‚¹ãƒšãƒ¼ã‚¹: {settings.confluence_space}")
    print(f"ğŸ”— Confluence URL: https://{settings.atlassian_domain}")
    
    # æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç¢ºèª
    if indexer.is_index_fresh(max_age_hours=24):
        print("â„¹ï¸ æ–°ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™")
        choice = input("å†æ§‹ç¯‰ã—ã¾ã™ã‹? (y/N): ").strip().lower()
        if choice != 'y':
            print("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return True
    
    print("\nğŸ”§ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚’é–‹å§‹...")
    start_time = time.time()
    
    try:
        # ãƒ•ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
        success = indexer.build_full_index(settings.confluence_space)
        
        if success:
            build_time = time.time() - start_time
            
            # çµæœè¡¨ç¤º
            metadata = indexer.index.get('metadata', {})
            total_pages = metadata.get('total_pages', 0)
            compression_ratio = metadata.get('compression_ratio', 0)
            
            print(f"\nâœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰å®Œäº†!")
            print(f"ğŸ“Š æ§‹ç¯‰çµæœ:")
            print(f"  â€¢ å‡¦ç†ãƒšãƒ¼ã‚¸æ•°: {total_pages:,}ãƒšãƒ¼ã‚¸")
            print(f"  â€¢ æ§‹ç¯‰æ™‚é–“: {build_time:.2f}ç§’")
            print(f"  â€¢ åœ§ç¸®ç‡: {compression_ratio:.1f}%")
            print(f"  â€¢ å¹³å‡å‡¦ç†é€Ÿåº¦: {total_pages/build_time:.1f}ãƒšãƒ¼ã‚¸/ç§’")
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºè¡¨ç¤º
            cache_dir = Path("cache")
            for file_pattern, description in [
                ("confluence_index.json.gz", "åœ§ç¸®JSON"),
                ("confluence_index.pkl", "ã‚­ãƒ£ãƒƒã‚·ãƒ¥Pickle"),
                ("confluence_index.json", "å¾“æ¥JSON")
            ]:
                file_path = cache_dir / file_pattern
                if file_path.exists():
                    size_mb = file_path.stat().st_size / 1024 / 1024
                    print(f"  â€¢ {description}: {size_mb:.2f}MB")
            
            # ãƒ†ã‚¹ãƒˆæ¤œç´¢å®Ÿè¡Œ
            print(f"\nğŸ” ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¤œç´¢ãƒ†ã‚¹ãƒˆ:")
            test_queries = ["API", "è¨­è¨ˆ", "ä»•æ§˜æ›¸"]
            
            for query in test_queries:
                test_start = time.time()
                results = indexer.search_indexed_content(query, max_results=3)
                test_time = time.time() - test_start
                
                print(f"  â€¢ '{query}': {len(results)}ä»¶ ({test_time*1000:.1f}ms)")
            
            return True
            
        else:
            print("âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
            
    except Exception as e:
        print(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 