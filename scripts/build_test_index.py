"""
ãƒ†ã‚¹ãƒˆç”¨Confluenceã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æœ€è¿‘ã®æ¤œç´¢çµæœã‚’ä½¿ã£ã¦å°è¦æ¨¡ãªãƒ†ã‚¹ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
"""

import sys
import time
import json
from pathlib import Path
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.spec_bot_mvp.tools.confluence_indexer import ConfluenceIndexer
from src.spec_bot_mvp.tools.confluence_tool import search_confluence_tool
from src.spec_bot_mvp.config.settings import settings
from src.spec_bot_mvp.utils.log_config import get_logger

logger = get_logger(__name__)

def create_test_index():
    """ãƒ†ã‚¹ãƒˆç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ"""
    print("ğŸ§ª ãƒ†ã‚¹ãƒˆç”¨Confluenceã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ä¸­...")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    test_data = {
        'metadata': {
            'created_at': datetime.now().isoformat(),
            'space_key': 'TEST',
            'total_pages': 5,
            'last_update': datetime.now().isoformat(),
            'version': '2.0',
            'format': 'compressed_json',
            'compression_ratio': 0.0
        },
        'pages': {
            'page_1': {
                'id': 'page_1',
                'title': 'APIè¨­è¨ˆä»•æ§˜æ›¸ - èªè¨¼æ©Ÿèƒ½',
                'type': 'page',
                'space': 'TEST',
                'url': 'https://test.example.com/page_1',
                'created': '2025-01-18T01:00:00Z',
                'updated': '2025-01-18T01:00:00Z',
                'content_preview': 'ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ã®èªè¨¼æ©Ÿèƒ½ã«é–¢ã™ã‚‹APIè¨­è¨ˆä»•æ§˜ã‚’èª¬æ˜ã—ã¾ã™ã€‚ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã€ãƒˆãƒ¼ã‚¯ãƒ³èªè¨¼ã«ã¤ã„ã¦è©³ç´°ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚',
                'labels': ['API', 'èªè¨¼', 'è¨­è¨ˆæ›¸', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£']
            },
            'page_2': {
                'id': 'page_2',
                'title': 'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ',
                'type': 'page',
                'space': 'TEST',
                'url': 'https://test.example.com/page_2',
                'created': '2025-01-18T01:00:00Z',
                'updated': '2025-01-18T01:00:00Z',
                'content_preview': 'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒè¨­è¨ˆã¨ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã€æ¨©é™ãƒ†ãƒ¼ãƒ–ãƒ«ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã®è©³ç´°è¨­è¨ˆã‚’å«ã¿ã¾ã™ã€‚',
                'labels': ['ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹', 'è¨­è¨ˆ', 'ã‚¹ã‚­ãƒ¼ãƒ', 'ãƒ†ãƒ¼ãƒ–ãƒ«']
            },
            'page_3': {
                'id': 'page_3',
                'title': 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³',
                'type': 'page',
                'space': 'TEST',
                'url': 'https://test.example.com/page_3',
                'created': '2025-01-18T01:00:00Z',
                'updated': '2025-01-18T01:00:00Z',
                'content_preview': 'ã‚·ã‚¹ãƒ†ãƒ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã§ã™ã€‚ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒãƒªã‚·ãƒ¼ã€ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã€ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–ã®åŸºæº–ã‚’å®šç¾©ã—ã¦ã„ã¾ã™ã€‚',
                'labels': ['ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³', 'ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰', 'æš—å·åŒ–']
            },
            'page_4': {
                'id': 'page_4',
                'title': 'ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †æ›¸',
                'type': 'page',
                'space': 'TEST',
                'url': 'https://test.example.com/page_4',
                'created': '2025-01-18T01:00:00Z',
                'updated': '2025-01-18T01:00:00Z',
                'content_preview': 'ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚é–‹ç™ºç’°å¢ƒã€ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒã€æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ—ãƒ­ã‚»ã‚¹ã‚’å«ã¿ã¾ã™ã€‚',
                'labels': ['ãƒ‡ãƒ—ãƒ­ã‚¤', 'æ‰‹é †', 'ç’°å¢ƒ', 'ãƒ—ãƒ­ã‚»ã‚¹']
            },
            'page_5': {
                'id': 'page_5',
                'title': 'ãƒ†ã‚¹ãƒˆä»•æ§˜æ›¸ - çµ±åˆãƒ†ã‚¹ãƒˆ',
                'type': 'page',
                'space': 'TEST',
                'url': 'https://test.example.com/page_5',
                'created': '2025-01-18T01:00:00Z',
                'updated': '2025-01-18T01:00:00Z',
                'content_preview': 'çµ±åˆãƒ†ã‚¹ãƒˆã®ä»•æ§˜ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚APIãƒ†ã‚¹ãƒˆã€UIãƒ†ã‚¹ãƒˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®è©³ç´°ãªæ‰‹é †ã‚’è¨˜è¼‰ã—ã¦ã„ã¾ã™ã€‚',
                'labels': ['ãƒ†ã‚¹ãƒˆ', 'çµ±åˆãƒ†ã‚¹ãƒˆ', 'API', 'UI', 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹']
            }
        },
        'hierarchy': {},
        'content_map': {},
        'categories': {
            'specifications': ['page_1', 'page_5'],
            'designs': ['page_2'],
            'manuals': ['page_4'],
            'security': ['page_3'],
            'apis': ['page_1'],
            'ui_ux': [],
            'workflows': ['page_4']
        }
    }
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒƒãƒ—ã®ç”Ÿæˆ
    for page_id, page_info in test_data['pages'].items():
        # ã‚¿ã‚¤ãƒˆãƒ«ã¨å†…å®¹ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        text = f"{page_info['title']} {page_info['content_preview']}"
        words = text.lower().split()
        
        for word in words:
            if len(word) > 2:  # 2æ–‡å­—ä»¥ä¸Šã®ãƒ¯ãƒ¼ãƒ‰ã®ã¿
                if word not in test_data['content_map']:
                    test_data['content_map'][word] = []
                test_data['content_map'][word].append({
                    'page_id': page_id,
                    'score': 0.8
                })
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚µãƒ¼ã«ä¿å­˜
    indexer = ConfluenceIndexer()
    indexer.index = test_data
    indexer.save_index()
    
    print("âœ… ãƒ†ã‚¹ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†")
    
    # åœ§ç¸®åŠ¹æœã®ç¢ºèª
    cache_dir = Path("cache")
    for file_pattern, description in [
        ("confluence_index.json.gz", "åœ§ç¸®JSON"),
        ("confluence_index.pkl", "ã‚­ãƒ£ãƒƒã‚·ãƒ¥Pickle"),
        ("confluence_index.json", "å¾“æ¥JSON")
    ]:
        file_path = cache_dir / file_pattern
        if file_path.exists():
            size_mb = file_path.stat().st_size / 1024 / 1024
            print(f"  â€¢ {description}: {size_mb:.3f}MB")
    
    return True

def test_search_functionality():
    """æ¤œç´¢æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ” ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¤œç´¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("-" * 30)
    
    indexer = ConfluenceIndexer()
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿
    if not indexer.load_index():
        print("âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿å¤±æ•—")
        return False
    
    test_queries = ["API", "è¨­è¨ˆ", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ãƒ†ã‚¹ãƒˆ", "ãƒ‡ãƒ—ãƒ­ã‚¤"]
    
    for query in test_queries:
        start_time = time.time()
        results = indexer.search_indexed_content(query, max_results=3)
        search_time = time.time() - start_time
        
        print(f"ğŸ” '{query}': {len(results)}ä»¶ ({search_time*1000:.1f}ms)")
        
        for i, result in enumerate(results[:2], 1):
            title = result.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
            score = result.get('relevance_score', 0)
            print(f"  {i}. {title} (é–¢é€£åº¦: {score:.2f})")
    
    return True

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ ãƒ†ã‚¹ãƒˆç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ãƒ»ãƒ†ã‚¹ãƒˆ")
    print("=" * 40)
    
    try:
        # ãƒ†ã‚¹ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        if create_test_index():
            # æ¤œç´¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            test_search_functionality()
            
            print(f"\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
            print("ğŸ’¡ ã“ã‚Œã§ scripts/simple_search_evaluation.py ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¤œç´¢ã‚’ãƒ†ã‚¹ãƒˆã§ãã¾ã™")
            return True
        else:
            return False
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ãƒ†ã‚¹ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 